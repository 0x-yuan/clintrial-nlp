{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/luyuan/clintrial-nlp/blob/main/atomic_agents_baseline.ipynb)\n\n# Atomic Agents 框架基線 - 臨床試驗 NLP\n\n## 概述\n\n本notebook展示如何使用Atomic Agents框架建構一個輕量級、高效能的多代理系統，用於臨床試驗自然語言推理(NLI)。Atomic Agents專為生產環境設計，具有極快的啟動時間(~3μs)和模組化架構。\n\n## 📚 學習目標\n完成本教學後，您將學會：\n- 理解 Atomic Agents 框架的核心概念\n- 建立專門的醫療、數值和邏輯分析代理\n- 實作多代理協作pipeline\n- 評估和改進系統效能\n\n### 為什麼選擇 Atomic Agents？\n- **超輕量級**: 最小化開銷和快速執行\n- **高度模組化**: 易於組合和修改代理\n- **生產就緒**: 專為實際部署而設計\n- **簡單API**: 直觀的代理創建和協調\n- **記憶體管理**: 內建的上下文和記憶體處理\n\n### 🏗️ 代理架構\n遵循教學圖表，我們實作一個結構化的pipeline：\n1. **醫療專家代理**: 分析醫學術語和概念\n2. **數值分析代理**: 處理量化數據\n3. **邏輯檢查代理**: 驗證邏輯關係\n4. **聚合代理**: 結合見解做出最終決策\n5. **監督協調**: 管理整體工作流程\n\n> 💡 **重要概念**: Atomic Agents 的\"atomic\"指的是每個代理都是一個獨立、最小的功能單元，可以輕鬆組合成複雜系統。"
  },
  {
   "cell_type": "code",
   "id": "1p3qmrclzei",
   "source": "# 🔧 Colab 環境設置 - 一鍵安裝所需套件\n# 這個cell會靜默安裝所有必要的Python套件，讓您可以在Colab中直接運行此notebook\n!pip install -q atomic-agents instructor openai python-dotenv pandas tqdm\n!pip install -q google-generativeai gdown\n\nprint(\"✅ 所有套件安裝完成！可以開始使用 Atomic Agents 框架了\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "3fpaymxvzg",
   "source": "# 📥 從 Google Drive 下載訓練資料\n# 這個cell會自動下載所需的臨床試驗資料，確保在Colab中可以直接運行\nimport os\nimport gdown\n\n# Google Drive 資料夾 ID\nfolder_id = \"1IcRoCbH0Oxtia8N47dy9fTWl4dfq3RS3\"\n\n# 檢查是否已下載訓練資料\nif not os.path.exists(\"training_data\"):\n    print(\"📥 從 Google Drive 下載訓練資料...\")\n    try:\n        # 下載整個資料夾\n        gdown.download_folder(id=folder_id, output=\".\", quiet=False, use_cookies=False)\n        print(\"✅ 訓練資料下載完成！\")\n    except Exception as e:\n        print(f\"❌ 下載失敗: {e}\")\n        print(\"請確認 Google Drive 連結的權限設定\")\nelse:\n    print(\"✅ 訓練資料已存在，跳過下載\")\n\n# 檢查下載的資料結構\nif os.path.exists(\"training_data\"):\n    print(f\"📂 資料夾內容: {os.listdir('training_data')}\")\n    if os.path.exists(\"training_data/CT json\"):\n        ct_files = len(os.listdir(\"training_data/CT json\"))\n        print(f\"📄 找到 {ct_files} 個臨床試驗JSON檔案\")\nelse:\n    print(\"⚠️ 無法找到 training_data 資料夾\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": "## 環境設置和安裝\n\n首先，讓我們設置環境並匯入必要的函式庫：\n\n> 📝 **說明**: 在這個步驟中，我們會載入環境變數並確認所有必要的套件都已正確安裝。"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": "# 載入環境變數\n# 這個步驟會從 .env 檔案載入 API 金鑰等敏感資訊\nfrom dotenv import load_dotenv\nimport os\n\nload_dotenv()\nprint(\"✅ 環境變數載入完成\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependencies",
   "metadata": {},
   "outputs": [],
   "source": "# 匯入必要的函式庫\n# 這些函式庫提供了資料處理、AI模型和Atomic Agents框架的功能\nimport json\nimport pandas as pd\nfrom tqdm import tqdm  # 進度條顯示\nimport instructor  # 結構化輸出\nimport openai\nfrom typing import Dict, List, Any, Optional\nimport warnings\nwarnings.filterwarnings('ignore')  # 隱藏警告訊息\n\n# Atomic Agents 核心組件\nfrom atomic_agents.lib.components.agent_memory import AgentMemory  # 代理記憶體管理\nfrom atomic_agents.agents.base_agent import BaseAgent, BaseAgentConfig, BaseAgentInputSchema  # 基礎代理類別\nfrom atomic_agents.lib.components.system_prompt_generator import SystemPromptGenerator  # 系統提示生成器\n\nprint(\"✅ 所有函式庫匯入成功\")"
  },
  {
   "cell_type": "markdown",
   "id": "data_utils",
   "metadata": {},
   "source": "## 資料載入和工具函式\n\n讓我們建立用於載入和處理臨床試驗資料的工具函式：\n\n> 🔧 **功能說明**: 這些函式負責從JSON檔案中載入臨床試驗資料，並將其轉換為適合AI代理分析的格式。"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utils",
   "metadata": {},
   "outputs": [],
   "source": "def load_clinical_trial(trial_id: str) -> Dict[str, Any]:\n    \"\"\"載入臨床試驗資料從JSON檔案。\n    \n    Args:\n        trial_id: 臨床試驗的NCT識別碼\n        \n    Returns:\n        包含試驗資料的字典或錯誤資訊\n    \"\"\"\n    try:\n        file_path = os.path.join(\"training_data\", \"CT json\", f\"{trial_id}.json\")\n        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n            data = json.load(f)\n        return data\n    except FileNotFoundError:\n        return {\"error\": f\"找不到臨床試驗 {trial_id}\"}\n    except Exception as e:\n        return {\"error\": f\"載入 {trial_id} 時發生錯誤: {str(e)}\"}\n\ndef load_dataset(filepath: str) -> Dict[str, Any]:\n    \"\"\"載入訓練或測試資料集。\n    \n    Args:\n        filepath: JSON資料集檔案的路徑\n        \n    Returns:\n        包含資料集的字典\n    \"\"\"\n    try:\n        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n            return json.load(f)\n    except Exception as e:\n        print(f\"載入資料集時發生錯誤: {e}\")\n        return {}\n\ndef extract_relevant_sections(trial_data: Dict[str, Any], section_id: str) -> str:\n    \"\"\"根據section_id從試驗資料中提取相關部分。\n    \n    Args:\n        trial_data: 臨床試驗資料字典\n        section_id: 目標區段 (Eligibility, Intervention, Results, Adverse Events)\n        \n    Returns:\n        包含相關區段資料的格式化字串\n    \"\"\"\n    if \"error\" in trial_data:\n        return f\"錯誤: {trial_data['error']}\"\n    \n    sections = {\n        \"Eligibility\": trial_data.get(\"Eligibility\", []),\n        \"Intervention\": trial_data.get(\"Intervention\", []),\n        \"Results\": trial_data.get(\"Results\", []),\n        \"Adverse Events\": trial_data.get(\"Adverse_Events\", [])\n    }\n    \n    # 如果請求特定區段，則僅返回該區段\n    if section_id in sections:\n        section_data = sections[section_id]\n        if isinstance(section_data, list):\n            return \"\\n\".join(str(item) for item in section_data)\n        return str(section_data)\n    \n    # 否則返回所有區段\n    result = []\n    for section_name, section_data in sections.items():\n        if section_data:\n            result.append(f\"{section_name}:\")\n            if isinstance(section_data, list):\n                result.extend([f\"  {item}\" for item in section_data])\n            else:\n                result.append(f\"  {section_data}\")\n    \n    return \"\\n\".join(result)\n\n# 測試工具函式\nsample_trial = load_clinical_trial(\"NCT00066573\")\nprint(f\"✅ 資料工具函式準備就緒。範例試驗: {sample_trial.get('Clinical Trial ID', '錯誤')}\")\n\n# 📋 函式說明：\n# - load_clinical_trial(): 載入單一臨床試驗的完整資料\n# - load_dataset(): 載入包含多個試驗的訓練/測試資料集  \n# - extract_relevant_sections(): 提取試驗中特定區段的資料"
  },
  {
   "cell_type": "markdown",
   "id": "model_setup",
   "metadata": {},
   "source": "## 模型配置\n\n設置OpenAI客戶端配合instructor來產生結構化輸出：\n\n> 🤖 **技術說明**: Instructor套件可以確保AI模型產生符合特定格式的結構化回應，提高系統的可靠性。"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_config",
   "metadata": {},
   "outputs": [],
   "source": "# 初始化OpenAI客戶端配合instructor\n# instructor包裝器確保AI回應遵循結構化格式\nclient = instructor.from_openai(openai.OpenAI(\n    api_key=os.getenv(\"OPENAI_API_KEY\")  # 從環境變數取得API金鑰\n))\n\n# 模型配置\nMODEL_NAME = \"gpt-4o-mini\"  # 使用GPT-4o-mini模型（成本效益較高）\n\nprint(f\"✅ OpenAI客戶端配置完成，使用模型: {MODEL_NAME}\")\n\n# 💰 成本說明：GPT-4o-mini是OpenAI較新的模型，比GPT-4便宜但保持高品質"
  },
  {
   "cell_type": "markdown",
   "id": "agent_definitions",
   "metadata": {},
   "source": "## 代理定義\n\n現在讓我們使用Atomic Agents框架定義每個專門的代理。每個代理都有特定的角色和專業領域：\n\n> 🎯 **設計原則**: 每個代理都專注於特定領域的分析，透過分工合作來提高整體分析品質。這是多代理系統的核心優勢。"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical_expert",
   "metadata": {},
   "outputs": [],
   "source": "# 1. 醫療專家代理\n# 這個代理專門負責從醫學角度分析陳述的準確性\nmedical_expert_prompt = SystemPromptGenerator(\n    background=[\n        \"You are a Medical Expert Agent specializing in clinical trial analysis.\",\n        \"You have deep knowledge of medical terminology, clinical concepts, and trial procedures.\",\n        \"Your role is to analyze statements from a medical perspective and identify relevant clinical insights.\"\n    ],\n    steps=[\n        \"1. Analyze the medical terminology and concepts in the statement\",\n        \"2. Identify key clinical elements and their significance\", \n        \"3. Review the clinical trial data for medical accuracy\",\n        \"4. Assess whether the medical claims align with the trial evidence\",\n        \"5. Provide medical reasoning and clinical context\"\n    ],\n    output_instructions=[\n        \"Provide a clear medical analysis focusing on:\",\n        \"- Medical terminology accuracy\",\n        \"- Clinical relevance and significance\", \n        \"- Alignment with medical evidence in the trial\",\n        \"- Any medical concerns or considerations\",\n        \"End with: MEDICAL_ASSESSMENT: [SUPPORTS/CONTRADICTS/UNCLEAR] based on medical evidence\"\n    ]\n)\n\n# 為醫療專家代理建立記憶體組件\nmedical_expert_memory = AgentMemory()\n\n# 建立醫療專家代理實例\nmedical_expert_agent = BaseAgent(\n    config=BaseAgentConfig(\n        client=client,\n        model=MODEL_NAME,\n        system_prompt_generator=medical_expert_prompt,\n        memory=medical_expert_memory\n    )\n)\n\nprint(\"✅ 醫療專家代理建立完成\")\n\n# 🩺 代理說明：醫療專家代理專門分析醫學術語的準確性和臨床相關性"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical_analyzer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Numerical Analyzer Agent\n",
    "numerical_analyzer_prompt = SystemPromptGenerator(\n",
    "    background=[\n",
    "        \"You are a Numerical Analyzer Agent specializing in quantitative analysis of clinical trials.\",\n",
    "        \"You excel at processing numbers, statistics, percentages, and numerical relationships.\",\n",
    "        \"Your role is to verify numerical claims and perform statistical analysis.\"\n",
    "    ],\n",
    "    steps=[\n",
    "        \"1. Extract all numerical values, percentages, and statistics from the statement\",\n",
    "        \"2. Identify corresponding numbers in the clinical trial data\",\n",
    "        \"3. Perform calculations to verify numerical relationships\",\n",
    "        \"4. Check for statistical significance and clinical meaningfulness\",\n",
    "        \"5. Identify any numerical inconsistencies or errors\"\n",
    "    ],\n",
    "    output_instructions=[\n",
    "        \"Provide a detailed numerical analysis including:\",\n",
    "        \"- All numerical values extracted from the statement\",\n",
    "        \"- Corresponding values found in trial data\",\n",
    "        \"- Calculations performed to verify claims\",\n",
    "        \"- Assessment of numerical accuracy\",\n",
    "        \"End with: NUMERICAL_ASSESSMENT: [ACCURATE/INACCURATE/PARTIALLY_ACCURATE] with confidence level\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "numerical_analyzer_memory = AgentMemory()\n",
    "\n",
    "numerical_analyzer_agent = BaseAgent(\n",
    "    config=BaseAgentConfig(\n",
    "        client=client,\n",
    "        model=MODEL_NAME,\n",
    "        system_prompt_generator=numerical_analyzer_prompt,\n",
    "        memory=numerical_analyzer_memory\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"✅ Numerical Analyzer Agent created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logic_checker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Logic Checker Agent\n",
    "logic_checker_prompt = SystemPromptGenerator(\n",
    "    background=[\n",
    "        \"You are a Logic Checker Agent responsible for validating logical reasoning and consistency.\",\n",
    "        \"You specialize in identifying logical relationships, contradictions, and reasoning patterns.\",\n",
    "        \"Your role is to ensure logical soundness and coherence in claims and evidence.\"\n",
    "    ],\n",
    "    steps=[\n",
    "        \"1. Analyze the logical structure of the statement\",\n",
    "        \"2. Identify cause-and-effect relationships and implications\",\n",
    "        \"3. Check for internal consistency and coherence\",\n",
    "        \"4. Evaluate the validity of inferences and conclusions\",\n",
    "        \"5. Detect any logical fallacies or contradictions\"\n",
    "    ],\n",
    "    output_instructions=[\n",
    "        \"Provide a logical analysis focusing on:\",\n",
    "        \"- Logical structure and reasoning patterns\",\n",
    "        \"- Consistency between claims and evidence\",\n",
    "        \"- Validity of inferences and implications\",\n",
    "        \"- Any logical issues or contradictions found\",\n",
    "        \"End with: LOGICAL_ASSESSMENT: [VALID/INVALID/QUESTIONABLE] with reasoning\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "logic_checker_memory = AgentMemory()\n",
    "\n",
    "logic_checker_agent = BaseAgent(\n",
    "    config=BaseAgentConfig(\n",
    "        client=client,\n",
    "        model=MODEL_NAME,\n",
    "        system_prompt_generator=logic_checker_prompt,\n",
    "        memory=logic_checker_memory\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"✅ Logic Checker Agent created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Aggregator Agent\n",
    "aggregator_prompt = SystemPromptGenerator(\n",
    "    background=[\n",
    "        \"You are the Aggregator Agent responsible for making final entailment decisions.\",\n",
    "        \"You synthesize analyses from the Medical Expert, Numerical Analyzer, and Logic Checker.\",\n",
    "        \"Your role is to weigh different evidence types and make the final classification decision.\"\n",
    "    ],\n",
    "    steps=[\n",
    "        \"1. Review the medical assessment for clinical accuracy\",\n",
    "        \"2. Consider the numerical analysis for quantitative validity\",\n",
    "        \"3. Evaluate the logical assessment for reasoning soundness\",\n",
    "        \"4. Weigh all evidence types appropriately\",\n",
    "        \"5. Make the final Entailment vs Contradiction decision\"\n",
    "    ],\n",
    "    output_instructions=[\n",
    "        \"Based on all specialist analyses, determine if the statement is:\",\n",
    "        \"- ENTAILMENT: Statement is directly supported by the trial data\",\n",
    "        \"- CONTRADICTION: Statement is refuted by the trial data\",\n",
    "        \"\",\n",
    "        \"Provide brief reasoning and then output exactly one of:\",\n",
    "        \"FINAL_DECISION: Entailment\",\n",
    "        \"FINAL_DECISION: Contradiction\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "aggregator_memory = AgentMemory()\n",
    "\n",
    "aggregator_agent = BaseAgent(\n",
    "    config=BaseAgentConfig(\n",
    "        client=client,\n",
    "        model=MODEL_NAME,\n",
    "        system_prompt_generator=aggregator_prompt,\n",
    "        memory=aggregator_memory\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"✅ Aggregator Agent created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pipeline",
   "metadata": {},
   "source": "## 多代理分析管道\n\n現在讓我們創建遵循教學圖表架構、協調所有代理的結構化管道：\n\n> ⚙️ **工作流程說明**: 這個管道將按順序執行每個專業代理，最終由聚合代理做出決策。每個步驟都會產生專業的分析結果。"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analysis_pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atomic_agents_pipeline(statement: str, primary_id: str, secondary_id: Optional[str] = None, \n",
    "                          section_id: Optional[str] = None, verbose: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Run the complete Atomic Agents analysis pipeline.\n",
    "    \n",
    "    Args:\n",
    "        statement: The natural language statement to analyze\n",
    "        primary_id: Primary clinical trial ID\n",
    "        secondary_id: Secondary trial ID for comparison statements\n",
    "        section_id: Relevant section of the trial\n",
    "        verbose: Whether to print intermediate results\n",
    "        \n",
    "    Returns:\n",
    "        Final decision: 'Entailment' or 'Contradiction'\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Load clinical trial data\n",
    "        primary_data = load_clinical_trial(primary_id)\n",
    "        secondary_data = None\n",
    "        if secondary_id:\n",
    "            secondary_data = load_clinical_trial(secondary_id)\n",
    "        \n",
    "        # Step 2: Extract relevant sections\n",
    "        primary_sections = extract_relevant_sections(primary_data, section_id or \"All\")\n",
    "        secondary_sections = None\n",
    "        if secondary_data:\n",
    "            secondary_sections = extract_relevant_sections(secondary_data, section_id or \"All\")\n",
    "        \n",
    "        # Step 3: Prepare input for agents\n",
    "        input_context = f\"\"\"\n",
    "STATEMENT TO ANALYZE: \"{statement}\"\n",
    "\n",
    "PRIMARY TRIAL ({primary_id}):\n",
    "{primary_sections}\n",
    "\n",
    "{f'SECONDARY TRIAL ({secondary_id}):\\n{secondary_sections}' if secondary_sections else ''}\n",
    "\n",
    "TASK: Analyze this statement against the clinical trial evidence.\n",
    "        \"\"\".strip()\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"📄 Analyzing: {statement[:100]}...\")\n",
    "            print(f\"🏥 Primary Trial: {primary_id}\")\n",
    "            if secondary_id:\n",
    "                print(f\"🏥 Secondary Trial: {secondary_id}\")\n",
    "        \n",
    "        # Step 4: Medical Expert Analysis\n",
    "        medical_input = BaseAgentInputSchema(chat_message=input_context)\n",
    "        medical_result = medical_expert_agent.run(medical_input)\n",
    "        medical_analysis = medical_result.chat_message\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"🩺 Medical Expert: {medical_analysis.split('MEDICAL_ASSESSMENT:')[-1].strip() if 'MEDICAL_ASSESSMENT:' in medical_analysis else 'Analysis complete'}\")\n",
    "        \n",
    "        # Step 5: Numerical Analyzer Analysis\n",
    "        numerical_input = BaseAgentInputSchema(chat_message=input_context)\n",
    "        numerical_result = numerical_analyzer_agent.run(numerical_input)\n",
    "        numerical_analysis = numerical_result.chat_message\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"🔢 Numerical Analyzer: {numerical_analysis.split('NUMERICAL_ASSESSMENT:')[-1].strip() if 'NUMERICAL_ASSESSMENT:' in numerical_analysis else 'Analysis complete'}\")\n",
    "        \n",
    "        # Step 6: Logic Checker Analysis\n",
    "        logic_input = BaseAgentInputSchema(chat_message=input_context)\n",
    "        logic_result = logic_checker_agent.run(logic_input)\n",
    "        logic_analysis = logic_result.chat_message\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"🧠 Logic Checker: {logic_analysis.split('LOGICAL_ASSESSMENT:')[-1].strip() if 'LOGICAL_ASSESSMENT:' in logic_analysis else 'Analysis complete'}\")\n",
    "        \n",
    "        # Step 7: Aggregator Decision\n",
    "        aggregator_input_text = f\"\"\"\n",
    "ORIGINAL STATEMENT: \"{statement}\"\n",
    "\n",
    "SPECIALIST ANALYSES:\n",
    "\n",
    "MEDICAL EXPERT ANALYSIS:\n",
    "{medical_analysis}\n",
    "\n",
    "NUMERICAL ANALYZER ANALYSIS:\n",
    "{numerical_analysis}\n",
    "\n",
    "LOGIC CHECKER ANALYSIS:\n",
    "{logic_analysis}\n",
    "\n",
    "Based on these specialist analyses, make the final decision: Entailment or Contradiction?\n",
    "        \"\"\".strip()\n",
    "        \n",
    "        aggregator_input = BaseAgentInputSchema(chat_message=aggregator_input_text)\n",
    "        aggregator_result = aggregator_agent.run(aggregator_input)\n",
    "        final_analysis = aggregator_result.chat_message\n",
    "        \n",
    "        # Step 8: Extract final decision\n",
    "        if \"FINAL_DECISION: Entailment\" in final_analysis:\n",
    "            decision = \"Entailment\"\n",
    "        elif \"FINAL_DECISION: Contradiction\" in final_analysis:\n",
    "            decision = \"Contradiction\"\n",
    "        else:\n",
    "            # Fallback parsing\n",
    "            if \"entailment\" in final_analysis.lower() and \"contradiction\" not in final_analysis.lower():\n",
    "                decision = \"Entailment\"\n",
    "            else:\n",
    "                decision = \"Contradiction\"\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"⚖️ Final Decision: {decision}\")\n",
    "            print(\"-\" * 50)\n",
    "        \n",
    "        return decision\n",
    "        \n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"❌ Error in pipeline: {e}\")\n",
    "        return \"Contradiction\"  # Conservative fallback\n",
    "\n",
    "print(\"✅ Atomic Agents pipeline ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test_example",
   "metadata": {},
   "source": "## 測試範例\n\n讓我們測試改進的Atomic Agents系統：\n\n> 🧪 **測試說明**: 這個測試將展示完整的多代理分析流程，您可以看到每個代理如何協作處理臨床試驗陳述。"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a sample statement\n",
    "test_statement = \"there is a 13.2% difference between the results from the two the primary trial cohorts\"\n",
    "test_primary_id = \"NCT00066573\"\n",
    "\n",
    "print(f\"Testing Atomic Agents with statement:\")\n",
    "print(f\"'{test_statement}'\")\n",
    "print(f\"Primary trial: {test_primary_id}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Run the analysis with verbose output\n",
    "result = atomic_agents_pipeline(\n",
    "    statement=test_statement,\n",
    "    primary_id=test_primary_id,\n",
    "    section_id=\"Results\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\n🎯 ATOMIC AGENTS RESULT: {result}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation",
   "metadata": {},
   "source": "## 在訓練資料上的評估\n\n讓我們在訓練資料上評估改進的Atomic Agents系統：\n\n> 📊 **評估說明**: 這個部分將測試我們的多代理系統在實際資料上的表現，並計算準確率等關鍵指標。"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_data = load_dataset(\"training_data/train.json\")\n",
    "print(f\"Loaded {len(train_data)} training examples\")\n",
    "\n",
    "# Evaluate on a sample (adjust sample_size as needed)\n",
    "sample_size = 30\n",
    "examples = list(train_data.items())[:sample_size]\n",
    "\n",
    "print(f\"\\nEvaluating Atomic Agents on {len(examples)} examples...\")\n",
    "\n",
    "results = []\n",
    "correct = 0\n",
    "\n",
    "for i, (uuid, example) in enumerate(tqdm(examples, desc=\"Atomic Agents\")):\n",
    "    try:\n",
    "        statement = example.get(\"Statement\")\n",
    "        primary_id = example.get(\"Primary_id\")\n",
    "        secondary_id = example.get(\"Secondary_id\")\n",
    "        section_id = example.get(\"Section_id\")\n",
    "        expected = example.get(\"Label\")\n",
    "        \n",
    "        if not statement or not primary_id:\n",
    "            results.append({\n",
    "                \"uuid\": uuid,\n",
    "                \"expected\": expected,\n",
    "                \"predicted\": \"SKIPPED\",\n",
    "                \"correct\": False\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Get prediction from Atomic Agents pipeline\n",
    "        predicted = atomic_agents_pipeline(\n",
    "            statement=statement,\n",
    "            primary_id=primary_id,\n",
    "            secondary_id=secondary_id,\n",
    "            section_id=section_id,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Check if correct\n",
    "        is_correct = (predicted.strip() == expected.strip())\n",
    "        if is_correct:\n",
    "            correct += 1\n",
    "            \n",
    "        results.append({\n",
    "            \"uuid\": uuid,\n",
    "            \"statement\": statement[:100] + \"...\" if len(statement) > 100 else statement,\n",
    "            \"expected\": expected,\n",
    "            \"predicted\": predicted,\n",
    "            \"correct\": is_correct\n",
    "        })\n",
    "        \n",
    "        status = \"✅\" if is_correct else \"❌\"\n",
    "        print(f\"Example {i+1:2d}: {expected:12} -> {predicted:12} {status}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing example {i+1}: {e}\")\n",
    "        results.append({\n",
    "            \"uuid\": uuid,\n",
    "            \"expected\": expected,\n",
    "            \"predicted\": \"ERROR\",\n",
    "            \"correct\": False\n",
    "        })\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct / len(examples) if examples else 0\n",
    "print(f\"\\n📊 Atomic Agents Results:\")\n",
    "print(f\"Accuracy: {accuracy:.2%} ({correct}/{len(examples)})\")\n",
    "\n",
    "# Store results for later comparison\n",
    "atomic_agents_results = results.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "error_analysis",
   "metadata": {},
   "source": [
    "## Error Analysis\n",
    "\n",
    "Let's analyze the errors to understand areas for improvement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze_errors",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze incorrect predictions\n",
    "incorrect_results = [r for r in results if not r[\"correct\"] and r[\"predicted\"] not in [\"SKIPPED\", \"ERROR\"]]\n",
    "\n",
    "print(f\"\\n🔍 Error Analysis ({len(incorrect_results)} incorrect predictions):\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Group errors by type\n",
    "entailment_to_contradiction = [r for r in incorrect_results if r[\"expected\"] == \"Entailment\" and r[\"predicted\"] == \"Contradiction\"]\n",
    "contradiction_to_entailment = [r for r in incorrect_results if r[\"expected\"] == \"Contradiction\" and r[\"predicted\"] == \"Entailment\"]\n",
    "\n",
    "print(f\"Entailment -> Contradiction errors: {len(entailment_to_contradiction)}\")\n",
    "print(f\"Contradiction -> Entailment errors: {len(contradiction_to_entailment)}\")\n",
    "\n",
    "# Show some examples\n",
    "print(\"\\nSample errors:\")\n",
    "for i, result in enumerate(incorrect_results[:3]):\n",
    "    print(f\"\\nError #{i+1}:\")\n",
    "    print(f\"Statement: {result['statement']}\")\n",
    "    print(f\"Expected: {result['expected']} | Predicted: {result['predicted']}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "submission",
   "metadata": {},
   "source": [
    "## Generate Submission File\n",
    "\n",
    "Let's generate a submission file using our Atomic Agents system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate_submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_atomic_agents_submission(test_file=\"test.json\", output_file=\"atomic_agents_submission.json\", sample_size=None):\n",
    "    \"\"\"\n",
    "    Generate submission file using Atomic Agents system.\n",
    "    \n",
    "    Args:\n",
    "        test_file: Path to test data\n",
    "        output_file: Output submission file\n",
    "        sample_size: Number of examples to process (None for all)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load test data\n",
    "    test_data = load_dataset(test_file)\n",
    "    if not test_data:\n",
    "        print(f\"❌ Could not load test data from {test_file}\")\n",
    "        return\n",
    "    \n",
    "    examples = list(test_data.items())\n",
    "    if sample_size:\n",
    "        examples = examples[:sample_size]\n",
    "        \n",
    "    print(f\"🚀 Generating Atomic Agents predictions for {len(examples)} examples...\")\n",
    "    \n",
    "    submission = {}\n",
    "    \n",
    "    for i, (uuid, example) in enumerate(tqdm(examples, desc=\"Atomic Agents Processing\")):\n",
    "        try:\n",
    "            statement = example.get(\"Statement\")\n",
    "            primary_id = example.get(\"Primary_id\")\n",
    "            secondary_id = example.get(\"Secondary_id\")\n",
    "            section_id = example.get(\"Section_id\")\n",
    "            \n",
    "            if not statement or not primary_id:\n",
    "                submission[uuid] = {\"Prediction\": \"Contradiction\"}  # Default fallback\n",
    "                continue\n",
    "                \n",
    "            # Get prediction from Atomic Agents system\n",
    "            prediction = atomic_agents_pipeline(\n",
    "                statement=statement,\n",
    "                primary_id=primary_id,\n",
    "                secondary_id=secondary_id,\n",
    "                section_id=section_id,\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            submission[uuid] = {\"Prediction\": prediction}\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {uuid}: {e}\")\n",
    "            submission[uuid] = {\"Prediction\": \"Contradiction\"}  # Conservative fallback\n",
    "    \n",
    "    # Save submission file\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(submission, f, indent=2)\n",
    "    \n",
    "    print(f\"✅ Atomic Agents submission saved to {output_file}\")\n",
    "    return submission\n",
    "\n",
    "# Generate submission for a small sample\n",
    "atomic_submission = generate_atomic_agents_submission(\n",
    "    test_file=\"test.json\", \n",
    "    output_file=\"atomic_agents_submission.json\",\n",
    "    sample_size=10  # Adjust as needed\n",
    ")\n",
    "\n",
    "print(f\"Generated predictions for {len(atomic_submission)} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "performance_analysis",
   "metadata": {},
   "source": [
    "## Performance Analysis and Comparison\n",
    "\n",
    "Let's analyze the performance of our improved Atomic Agents implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "performance_metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "# Performance metrics\n",
    "def analyze_performance(results, framework_name):\n",
    "    \"\"\"\n",
    "    Analyze performance metrics for a framework.\n",
    "    \"\"\"\n",
    "    valid_results = [r for r in results if r[\"predicted\"] not in [\"SKIPPED\", \"ERROR\"]]\n",
    "    \n",
    "    if not valid_results:\n",
    "        print(f\"No valid results for {framework_name}\")\n",
    "        return\n",
    "    \n",
    "    # Basic metrics\n",
    "    total = len(valid_results)\n",
    "    correct = sum(1 for r in valid_results if r[\"correct\"])\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    \n",
    "    # Confusion matrix\n",
    "    true_pos = sum(1 for r in valid_results if r[\"expected\"] == \"Entailment\" and r[\"predicted\"] == \"Entailment\")\n",
    "    true_neg = sum(1 for r in valid_results if r[\"expected\"] == \"Contradiction\" and r[\"predicted\"] == \"Contradiction\")\n",
    "    false_pos = sum(1 for r in valid_results if r[\"expected\"] == \"Contradiction\" and r[\"predicted\"] == \"Entailment\")\n",
    "    false_neg = sum(1 for r in valid_results if r[\"expected\"] == \"Entailment\" and r[\"predicted\"] == \"Contradiction\")\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision = true_pos / (true_pos + false_pos) if (true_pos + false_pos) > 0 else 0\n",
    "    recall = true_pos / (true_pos + false_neg) if (true_pos + false_neg) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    print(f\"\\n📊 {framework_name} Performance Analysis:\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Total examples: {total}\")\n",
    "    print(f\"Accuracy: {accuracy:.2%} ({correct}/{total})\")\n",
    "    print(f\"Precision: {precision:.3f}\")\n",
    "    print(f\"Recall: {recall:.3f}\")\n",
    "    print(f\"F1-Score: {f1_score:.3f}\")\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"True Positives (Entailment): {true_pos}\")\n",
    "    print(f\"True Negatives (Contradiction): {true_neg}\")\n",
    "    print(f\"False Positives: {false_pos}\")\n",
    "    print(f\"False Negatives: {false_neg}\")\n",
    "    \n",
    "    # Label distribution\n",
    "    expected_dist = Counter(r[\"expected\"] for r in valid_results)\n",
    "    predicted_dist = Counter(r[\"predicted\"] for r in valid_results)\n",
    "    \n",
    "    print(f\"\\nLabel Distribution:\")\n",
    "    print(f\"Expected - Entailment: {expected_dist.get('Entailment', 0)}, Contradiction: {expected_dist.get('Contradiction', 0)}\")\n",
    "    print(f\"Predicted - Entailment: {predicted_dist.get('Entailment', 0)}, Contradiction: {predicted_dist.get('Contradiction', 0)}\")\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1_score\n",
    "    }\n",
    "\n",
    "# Analyze current results\n",
    "atomic_metrics = analyze_performance(atomic_agents_results, \"Atomic Agents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": "## 結論與洞察\n\n### Atomic Agents 框架優勢：\n1. **超輕量級**: 最小開銷和極快啟動時間（~3μs）\n2. **模組化架構**: 易於組合和修改代理\n3. **生產就緒**: 專為實際部署場景而建構\n4. **記憶體管理**: 內建的上下文和記憶體處理\n5. **簡單API**: 直觀的代理創建和協調\n\n### 關鍵改進：\n- **結構化管道**: 代理間職責清晰分工\n- **專業角色**: 醫療專家、數值分析員、邏輯檢查員、聚合員\n- **更好的協調**: 系統化的資訊流動\n- **錯誤處理**: 強健的回退機制\n- **區段提取**: 針對相關試驗區段的精準分析\n\n### 架構優勢：\n- **快速執行**: 高吞吐量場景的最小開銷\n- **易於除錯**: 清晰的代理邊界便於排錯\n- **可擴展設計**: 簡單添加新的專業代理\n- **記憶體效率**: 輕量級代理實例\n- **生產部署**: 實際應用準備就緒\n\n### 優化機會：\n1. **提示工程**: 微調個別代理提示\n2. **代理協調**: 改善代理間資訊傳遞\n3. **錯誤分析**: 利用失敗案例改進代理推理\n4. **效能調整**: 速度與準確性權衡最佳化\n5. **領域知識**: 增強代理的醫療專業知識\n\n### 何時使用 Atomic Agents：\n- 高效能生產環境\n- 需要快速啟動和執行的應用\n- 重視簡潔性和模組化的場景\n- 需要輕量級代理協調的系統\n- 優先考慮部署效率的專案\n\n## 🎓 學習重點總結\n- **原子性概念**: 每個代理都是獨立的最小功能單元\n- **分工合作**: 不同專業領域的代理協同工作\n- **管道設計**: 結構化的資料流和決策流程\n- **實際應用**: 臨床試驗NLP的實戰案例\n\nAtomic Agents 在效能、簡潔性和模組化之間提供了絕佳平衡，使其成為需要速度和可靠性的生產臨床NLP應用的理想選擇。"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}