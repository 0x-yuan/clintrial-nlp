#!/usr/bin/env python
# coding: utf-8

# [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/0x-yuan/clintrial-nlp/blob/main/autogen_baseline.ipynb)
# 
# # AutoGen æ¡†æ¶åŸºç·š - è‡¨åºŠè©¦é©— NLP
# 
# ## æ¦‚è¿°
# 
# æœ¬notebookå±•ç¤ºå¦‚ä½•ä½¿ç”¨Microsoft AutoGenå»ºæ§‹ä¸€å€‹å¤šä»£ç†ç³»çµ±ï¼Œç”¨æ–¼è‡¨åºŠè©¦é©—è‡ªç„¶èªè¨€æ¨ç†(NLI)ã€‚AutoGenåœ¨é€éå°è©±æ¨¡å¼é€²è¡Œå¤šä»£ç†å”ä½œæ–¹é¢è¡¨ç¾å“è¶Šã€‚
# 
# ## ğŸ“š å­¸ç¿’ç›®æ¨™
# å®Œæˆæœ¬æ•™å­¸å¾Œï¼Œæ‚¨å°‡å­¸æœƒï¼š
# - ç†è§£ AutoGen çš„å¤šä»£ç†å°è©±æ¡†æ¶
# - å»ºç«‹å°ˆæ¥­åŒ–çš„è§’è‰²ä»£ç†
# - å¯¦ä½œç¾¤çµ„èŠå¤©å”ä½œæ¨¡å¼
# - ç®¡ç†ä»£ç†é–“çš„ä»»å‹™åˆ†é…å’Œå”èª¿
# 
# ### ç‚ºä»€éº¼é¸æ“‡ AutoGenï¼Ÿ
# - **å¤šä»£ç†å°è©±**: ä»£ç†é–“çš„è‡ªç„¶å°è©±
# - **è§’è‰²å°ˆæ¥­åŒ–**: æ¯å€‹ä»£ç†éƒ½æœ‰ç‰¹å®šçš„å°ˆæ¥­çŸ¥è­˜
# - **å½ˆæ€§å”èª¿**: ç›£ç£è€…ç®¡ç†ä»»å‹™åˆ†é…
# - **å¼·å¥æ¨ç†**: å¤šé‡è¦–è§’æå‡æº–ç¢ºæ€§
# 
# ### ğŸ­ ä»£ç†æ¶æ§‹
# æ ¹æ“šæ•™å­¸ææ–™ï¼Œæˆ‘å€‘å¯¦ä½œï¼š
# 1. **ç›£ç£è€…**: å”èª¿ä»»å‹™ä¸¦ç®¡ç†å·¥ä½œæµç¨‹
# 2. **é†«ç™‚å°ˆå®¶**: ç†è§£é†«å­¸è¡“èªå’Œæ¦‚å¿µ
# 3. **æ•¸å€¼åˆ†æå“¡**: è™•ç†é‡åŒ–è³‡æ–™å’Œçµ±è¨ˆ
# 4. **é‚è¼¯æª¢æŸ¥å“¡**: é©—è­‰é‚è¼¯é—œä¿‚
# 5. **èšåˆå“¡**: åŸºæ–¼æ‰€æœ‰è¼¸å…¥åšå‡ºæœ€çµ‚æ±ºç­–
# 
# > ğŸ’¬ **æ ¸å¿ƒæ¦‚å¿µ**: AutoGençš„ç¨ç‰¹ä¹‹è™•åœ¨æ–¼ä»£ç†é€éå°è©±é€²è¡Œå”ä½œï¼Œå°±åƒäººé¡åœ˜éšŠè¨è«–å•é¡Œä¸€æ¨£ã€‚é€™ç¨®è‡ªç„¶çš„äº’å‹•æ¨¡å¼ä½¿å¾—è¤‡é›œæ¨ç†éç¨‹æ›´åŠ é€æ˜å’Œå¯è§£é‡‹ã€‚

# In[ ]:


# ğŸ”§ Colab ç’°å¢ƒè¨­ç½® - ä¸€éµå®‰è£ AutoGen ç›¸é—œå¥—ä»¶
# é€™å€‹cellæœƒéœé»˜å®‰è£Microsoft AutoGenå¤šä»£ç†å”ä½œæ¡†æ¶æ‰€éœ€çš„å¥—ä»¶
get_ipython().system('pip install -q pyautogen[gemini] python-dotenv pandas tqdm')
get_ipython().system('pip install -q google-generativeai gdown')

# ç¢ºä¿ AutoGen ç›¸é—œä¾è³´å®Œæ•´å®‰è£
get_ipython().system('pip install -q openai>=1.0.0  # AutoGen éœ€è¦ OpenAI å®¢æˆ¶ç«¯åº«ï¼ˆå³ä½¿ä¸ä½¿ç”¨ OpenAIï¼‰')
get_ipython().system('pip install -q docker  # å¦‚æœéœ€è¦ä»£ç¢¼åŸ·è¡ŒåŠŸèƒ½')

print("âœ… AutoGen å¤šä»£ç†å”ä½œæ¡†æ¶å®‰è£å®Œæˆï¼å¯ä»¥é–‹å§‹å»ºæ§‹å°è©±å¼ä»£ç†åœ˜éšŠäº†")


# In[ ]:


# ğŸ“¥ å¾ Google Drive ä¸‹è¼‰è¨“ç·´è³‡æ–™
# é€™å€‹cellæœƒè‡ªå‹•ä¸‹è¼‰ä¸¦è§£å£“ç¸® clinicaltrial-nlp.zipï¼Œç¢ºä¿åœ¨Colabä¸­å¯ä»¥ç›´æ¥é‹è¡Œ
import os
import gdown
import zipfile
import shutil

# Google Drive zip æª”æ¡ˆ ID
file_id = "15GA5XI39DDxQ5QkIZXsFbApx1yEvCpcR"
zip_url = f"https://drive.google.com/uc?id={file_id}"
zip_filename = "clinicaltrial-nlp.zip"

# æª¢æŸ¥æ˜¯å¦å·²æœ‰è¨“ç·´è³‡æ–™
if not os.path.exists("training_data"):
    print("ğŸ“¥ å¾ Google Drive ä¸‹è¼‰ clinicaltrial-nlp.zip...")
    print("âš ï¸ å¦‚æœä¸‹è¼‰å¤±æ•—ï¼Œè«‹ç¢ºèª:")
    print("1. Google Drive é€£çµçš„æ¬Šé™è¨­å®šç‚º 'çŸ¥é“é€£çµçš„ä½¿ç”¨è€…'")
    print("2. ç¶²è·¯é€£ç·šæ­£å¸¸")
    print(f"3. æª”æ¡ˆé€£çµ: {zip_url}")
    
    try:
        # ä¸‹è¼‰ zip æª”æ¡ˆ
        print("ğŸ“¥ æ­£åœ¨ä¸‹è¼‰ zip æª”æ¡ˆ...")
        gdown.download(zip_url, zip_filename, quiet=False)
        
        # è§£å£“ç¸®æª”æ¡ˆ
        print("ğŸ“¦ æ­£åœ¨è§£å£“ç¸®æª”æ¡ˆ...")
        with zipfile.ZipFile(zip_filename, 'r') as zip_ref:
            zip_ref.extractall(".")
        
        # ç§»å‹• training_data åˆ°æ­£ç¢ºä½ç½®ï¼ˆå¦‚æœåœ¨å­è³‡æ–™å¤¾ä¸­ï¼‰
        if os.path.exists("clintrial-nlp/training_data") and not os.path.exists("training_data"):
            print("ğŸ“ ç§»å‹• training_data åˆ°æ­£ç¢ºä½ç½®...")
            shutil.move("clintrial-nlp/training_data", "training_data")
            # æ¸…ç†è§£å£“ç¸®çš„è³‡æ–™å¤¾
            if os.path.exists("clintrial-nlp"):
                shutil.rmtree("clintrial-nlp")
            if os.path.exists("__MACOSX"):  # æ¸…ç† macOS ç”¢ç”Ÿçš„éš±è—æª”æ¡ˆ
                shutil.rmtree("__MACOSX")
        
        # æ¸…ç† zip æª”æ¡ˆ
        os.remove(zip_filename)
        print("âœ… è¨“ç·´è³‡æ–™ä¸‹è¼‰ä¸¦è§£å£“ç¸®å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ ä¸‹è¼‰å¤±æ•—: {e}")
        print("\nğŸ”§ æ‰‹å‹•è§£æ±ºæ–¹æ¡ˆ:")
        print("1. é»æ“Šæ­¤é€£çµä¸‹è¼‰ zip æª”æ¡ˆ:")
        print("   https://drive.google.com/file/d/15GA5XI39DDxQ5QkIZXsFbApx1yEvCpcR/view?usp=sharing")
        print("2. ä¸Šå‚³ zip æª”æ¡ˆåˆ° Colab")
        print("3. è§£å£“ç¸®å¾Œé‡æ–°åŸ·è¡Œå¾ŒçºŒçš„ cells")
        
        # å‰µå»ºä¸€å€‹æç¤ºæª”æ¡ˆ
        os.makedirs("training_data", exist_ok=True)
        with open("training_data/DOWNLOAD_INSTRUCTIONS.txt", "w", encoding="utf-8") as f:
            f.write("è«‹æ‰‹å‹•ä¸‹è¼‰ä¸¦è§£å£“ç¸® clinicaltrial-nlp.zip:\n")
            f.write("https://drive.google.com/file/d/15GA5XI39DDxQ5QkIZXsFbApx1yEvCpcR/view?usp=sharing\n")
        
        print("\nğŸ“ å·²å‰µå»ºä¸‹è¼‰æŒ‡ç¤ºæª”æ¡ˆæ–¼ training_data/DOWNLOAD_INSTRUCTIONS.txt")
else:
    print("âœ… è¨“ç·´è³‡æ–™å·²å­˜åœ¨ï¼Œè·³éä¸‹è¼‰")

# æª¢æŸ¥ä¸‹è¼‰çš„è³‡æ–™çµæ§‹
if os.path.exists("training_data"):
    contents = os.listdir("training_data")
    print(f"ğŸ“‚ è³‡æ–™å¤¾å…§å®¹: {contents}")
    if os.path.exists("training_data/CT json"):
        ct_files = len([f for f in os.listdir("training_data/CT json") if f.endswith('.json')])
        print(f"ğŸ“„ æ‰¾åˆ° {ct_files} å€‹è‡¨åºŠè©¦é©—JSONæª”æ¡ˆ")
    else:
        print("âš ï¸ æ‰¾ä¸åˆ° 'CT json' å­è³‡æ–™å¤¾ï¼Œè«‹æª¢æŸ¥ä¸‹è¼‰æ˜¯å¦å®Œæ•´")


# In[ ]:


# ğŸ§ª æº–å‚™æ¸¬è©¦è³‡æ–™é›†
import json

def create_test_data_if_needed():
    if not os.path.exists("test.json"):
        try:
            with open("training_data/train.json", "r", encoding="utf-8") as f:
                train_data = json.load(f)
            test_data = dict(list(train_data.items())[:100])
            with open("test.json", "w", encoding="utf-8") as f:
                json.dump(test_data, f, indent=2, ensure_ascii=False)
            print(f"âœ… å·²å‰µå»ºæ¸¬è©¦è³‡æ–™é›†ï¼ŒåŒ…å« {len(test_data)} å€‹æ¨£æœ¬")
        except Exception as e:
            print(f"âŒ å‰µå»ºæ¸¬è©¦è³‡æ–™å¤±æ•—: {e}")
    else:
        print("âœ… test.json å·²å­˜åœ¨")

create_test_data_if_needed()


# ## ç’°å¢ƒè¨­ç½®å’Œå®‰è£
# 
# é¦–å…ˆï¼Œè®“æˆ‘å€‘å®‰è£å¿…è¦çš„å¥—ä»¶ä¸¦è¨­ç½®ç’°å¢ƒï¼š
# 
# > ğŸ“ **èªªæ˜**: AutoGenæ¡†æ¶æ”¯æ´å¤šç¨®LLMå¾Œç«¯ï¼Œé€™è£¡æˆ‘å€‘ä½¿ç”¨Google Geminiæ¨¡å‹é€²è¡Œç¤ºç¯„ã€‚

# In[ ]:


# Load environment variables
from dotenv import load_dotenv
import os

load_dotenv()
print("âœ… Environment loaded")


# In[ ]:


# Import required libraries
import json
import pandas as pd
from tqdm import tqdm
import autogen
from typing import Dict, List, Any, Optional
import warnings
warnings.filterwarnings('ignore')

print("âœ… Libraries imported successfully")


# ## Data Loading and Utilities
# 
# Let's create utility functions to load clinical trial data:

# In[ ]:


def load_clinical_trial(trial_id: str) -> Dict[str, Any]:
    """Load clinical trial data from JSON file.
    
    Args:
        trial_id: The NCT identifier for the clinical trial
        
    Returns:
        Dictionary containing trial data or error information
    """
    try:
        file_path = os.path.join("training_data", "CT json", f"{trial_id}.json")
        with open(file_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        return data
    except FileNotFoundError:
        return {"error": f"Clinical trial {trial_id} not found"}
    except Exception as e:
        return {"error": f"Error loading {trial_id}: {str(e)}"}

def load_dataset(filepath: str) -> Dict[str, Any]:
    """Load training or test dataset.
    
    Args:
        filepath: Path to the JSON dataset file
        
    Returns:
        Dictionary containing the dataset
    """
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        print(f"Error loading dataset: {e}")
        return {}

# Test data loading
sample_trial = load_clinical_trial("NCT00066573")
print(f"âœ… Data loading functions ready. Sample trial loaded: {sample_trial.get('Clinical Trial ID', 'Error')}")


# ## AutoGen ä»£ç†é…ç½®
# 
# ç¾åœ¨è®“æˆ‘å€‘ä½¿ç”¨Google Geminié…ç½®å¤šä»£ç†ç³»çµ±ã€‚æ¯å€‹ä»£ç†éƒ½æœ‰å°ˆé–€çš„è§’è‰²å’Œç‰¹å®šçš„æŒ‡ä»¤ï¼š
# 
# > ğŸ¤– **æŠ€è¡“èªªæ˜**: AutoGençš„AssistantAgenté¡åˆ¥å…è¨±æˆ‘å€‘å‰µå»ºå…·æœ‰ç‰¹å®šå°ˆæ¥­çŸ¥è­˜å’Œè¡Œç‚ºæ¨¡å¼çš„AIä»£ç†ï¼Œé€™äº›ä»£ç†å¯ä»¥é€éç¾¤çµ„èŠå¤©é€²è¡Œå”ä½œã€‚

# In[ ]:


# ğŸ¤– Setup Google Gemini 2.5 Flash model for AutoGen
# AutoGen will use this configuration to initialize all agent LLM backends
import google.generativeai as genai
import os

print("ğŸ”‘ Checking API key configuration...")

# Support both GEMINI_API_KEY and GOOGLE_API_KEY environment variables
api_key = os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")

if not api_key:
    print("âš ï¸ Please set GEMINI_API_KEY or GOOGLE_API_KEY environment variable")
    print("You can set it in Colab's 'Secrets' panel or use:")
    print("import os")
    print("os.environ['GEMINI_API_KEY'] = 'your-api-key'")
    print("or")
    print("os.environ['GOOGLE_API_KEY'] = 'your-api-key'")
    # Create fake config to avoid errors
    config_list = [{"model": "gpt-3.5-turbo", "api_key": "fake"}]
    api_key = "fake"
else:
    print(f"âœ… Found API key: {api_key[:8]}...{api_key[-4:]}")
    genai.configure(api_key=api_key)
    print("âœ… Google Gemini API configured")
    
    # Test API connection
    try:
        model = genai.GenerativeModel("gemini-2.5-flash")
        response = model.generate_content("Hello, respond with 'API test successful'")
        print(f"âœ… API connection test successful: {response.text[:50]}...")
    except Exception as e:
        print(f"âš ï¸ API connection test failed: {e}")

# AutoGen's LLM configuration - Use Google Gemini 2.5 Flash
# Based on official AutoGen documentation for Gemini integration
config_list = [
    {
        "model": "gemini-2.5-flash",
        "api_key": api_key,
        "api_type": "google"  # This is crucial for AutoGen to recognize it as Gemini
    }
]

# Test configuration
print(f"ğŸ“‹ LLM configuration model: {config_list[0]['model']}")
print(f"ğŸ“‹ API type: {config_list[0]['api_type']}")

llm_config = {
    "config_list": config_list,
    "temperature": 0.1,  # Low temperature for consistent results
    "timeout": 120,
    "seed": 42,  # Ensure reproducibility
}

print("âœ… AutoGen configuration ready, will use Google Gemini 2.5 Flash model")
print(f"ğŸ”§ Configuration details: temperature={llm_config['temperature']}, timeout={llm_config['timeout']}s")


# ## Agent Definitions
# 
# Let's define each agent with their specific roles and capabilities:

# In[ ]:


# 1. Supervisor Agent - Coordinates the overall workflow
supervisor = autogen.AssistantAgent(
    name="supervisor",
    system_message="""You are the Supervisor Agent responsible for coordinating clinical trial analysis.
    
    Your responsibilities:
    1. Break down complex clinical trial questions into manageable tasks
    2. Assign tasks to appropriate specialist agents
    3. Coordinate information flow between agents
    4. Ensure all aspects of the statement are thoroughly analyzed
    5. Guide the final decision-making process
    
    When given a statement and clinical trial data, you should:
    - First understand what the statement claims
    - Identify which sections of the trial are relevant
    - Delegate specific analysis tasks to specialist agents
    - Collect and synthesize their findings
    
    Always maintain a systematic approach and ensure thorough analysis.
    """,
    llm_config=llm_config,
)

# 2. Medical Expert Agent - Handles medical terminology and concepts
medical_expert = autogen.AssistantAgent(
    name="medical_expert",
    system_message="""You are the Medical Expert Agent specializing in clinical trial analysis.
    
    Your expertise includes:
    1. Medical terminology and clinical concepts
    2. Understanding of trial phases, interventions, and outcomes
    3. Clinical significance of findings
    4. Medical relationships and causations
    5. Safety profiles and adverse events
    
    When analyzing statements:
    - Focus on the medical accuracy and clinical relevance
    - Identify key medical terms and their implications
    - Assess whether medical claims align with trial evidence
    - Consider clinical context and medical plausibility
    
    Provide clear medical reasoning for your analysis.
    """,
    llm_config=llm_config,
)

# 3. Numerical Analyzer Agent - Processes quantitative data
numerical_analyzer = autogen.AssistantAgent(
    name="numerical_analyzer",
    system_message="""You are the Numerical Analyzer Agent specializing in quantitative analysis.
    
    Your expertise includes:
    1. Statistical analysis and interpretation
    2. Numerical comparisons and calculations
    3. Percentage, ratios, and statistical significance
    4. Data ranges, confidence intervals, and error margins
    5. Trend analysis and numerical patterns
    
    When analyzing statements:
    - Extract and verify all numerical claims
    - Perform calculations to validate numerical relationships
    - Compare stated numbers with trial data
    - Assess statistical significance and clinical relevance
    - Identify any numerical inconsistencies or errors
    
    Be precise and show your calculations when relevant.
    """,
    llm_config=llm_config,
)

# 4. Logic Checker Agent - Validates logical relationships
logic_checker = autogen.AssistantAgent(
    name="logic_checker",
    system_message="""You are the Logic Checker Agent responsible for validating logical reasoning.
    
    Your expertise includes:
    1. Logical consistency and coherence
    2. Cause-and-effect relationships
    3. Conditional logic and implications
    4. Contradiction detection
    5. Multi-step reasoning validation
    
    When analyzing statements:
    - Evaluate the logical structure of claims
    - Check for internal consistency
    - Identify logical fallacies or contradictions
    - Assess the validity of inferences
    - Ensure conclusions follow from premises
    
    Focus on the logical soundness rather than medical or numerical details.
    """,
    llm_config=llm_config,
)

# 5. Aggregator Agent - Makes final decisions
aggregator = autogen.AssistantAgent(
    name="aggregator",
    system_message="""You are the Aggregator Agent responsible for making final entailment decisions.
    
    Your responsibilities:
    1. Synthesize findings from all specialist agents
    2. Weigh different types of evidence appropriately
    3. Resolve conflicts between agent analyses
    4. Make the final Entailment vs Contradiction decision
    5. Provide confidence assessment for the decision
    
    Decision criteria:
    - ENTAILMENT: Statement is directly supported by trial data
    - CONTRADICTION: Statement is refuted by trial data
    
    When making decisions:
    - Consider input from Medical Expert, Numerical Analyzer, and Logic Checker
    - Prioritize evidence that directly addresses the statement
    - Be conservative: if evidence is unclear, consider context carefully
    - Always provide reasoning for your final decision
    
    Output format: "FINAL_DECISION: [Entailment/Contradiction]"
    """,
    llm_config=llm_config,
)

# User proxy for managing the conversation
user_proxy = autogen.UserProxyAgent(
    name="user_proxy",
    human_input_mode="NEVER",
    max_consecutive_auto_reply=10,
    is_termination_msg=lambda x: x.get("content", "").find("FINAL_DECISION:") >= 0,
    code_execution_config=False,
)

print("âœ… All agents created successfully")


# ## ç¾¤çµ„èŠå¤©è¨­ç½®
# 
# æˆ‘å€‘å°‡è¨­ç½®ä¸€å€‹ç¾¤çµ„èŠå¤©ï¼Œè®“ä»£ç†å€‘èƒ½å¤ å”ä½œåˆ†ææ¯å€‹é™³è¿°ï¼š
# 
# > ğŸ—£ï¸ **å”ä½œèªªæ˜**: GroupChatå…è¨±å¤šå€‹ä»£ç†åœ¨åŒä¸€å€‹å°è©±ä¸­äº’å‹•ï¼Œæ¯å€‹ä»£ç†è¼ªæµç™¼è¨€ï¼Œåˆ†äº«ä»–å€‘çš„åˆ†æè¦‹è§£ï¼Œå°±åƒåœ˜éšŠæœƒè­°ä¸€æ¨£ã€‚

# In[ ]:


# Create group chat with all agents
groupchat = autogen.GroupChat(
    agents=[supervisor, medical_expert, numerical_analyzer, logic_checker, aggregator, user_proxy],
    messages=[],
    max_round=15,  # Allow sufficient rounds for thorough analysis
    speaker_selection_method="round_robin",  # Ensure all agents participate
)

# Create group chat manager
manager = autogen.GroupChatManager(
    groupchat=groupchat,
    llm_config=llm_config
)

print("âœ… Group chat configured")


# ## Clinical Trial Analysis Pipeline
# 
# Now let's create our main analysis pipeline that coordinates the multi-agent analysis:

# In[ ]:


def analyze_statement_with_agents(statement: str, primary_id: str, secondary_id: Optional[str] = None, 
                                section_id: Optional[str] = None) -> str:
    """
    Analyze a statement using the multi-agent system.
    
    Args:
        statement: The natural language statement to analyze
        primary_id: Primary clinical trial ID
        secondary_id: Secondary trial ID for comparison statements
        section_id: Relevant section of the trial (Eligibility, Intervention, Results, Adverse Events)
        
    Returns:
        Final decision: 'Entailment' or 'Contradiction'
    """
    
    print(f"ğŸ” é–‹å§‹åˆ†æ: {statement[:50]}...")
    
    # Load clinical trial data
    primary_data = load_clinical_trial(primary_id)
    secondary_data = None
    if secondary_id:
        secondary_data = load_clinical_trial(secondary_id)
    
    # æª¢æŸ¥è³‡æ–™æ˜¯å¦è¼‰å…¥æˆåŠŸ
    if "error" in primary_data:
        print(f"âŒ ä¸»è¦è©¦é©—è³‡æ–™è¼‰å…¥å¤±æ•—: {primary_data['error']}")
        return "Contradiction"
    
    # Prepare secondary data section
    secondary_section = ""
    if secondary_data:
        secondary_section = f"SECONDARY TRIAL DATA:\n{json.dumps(secondary_data, indent=2)}"
    
    # Prepare the analysis context (ç¸®çŸ­ä»¥é¿å… token é™åˆ¶)
    context = f"""
CLINICAL TRIAL ANALYSIS TASK

Statement: "{statement}"
Primary Trial: {primary_id}
Secondary Trial: {secondary_id or "N/A"}
Section: {section_id or "All sections"}

PRIMARY TRIAL DATA (summarized):
Title: {primary_data.get('Official Title', 'N/A')}
Phase: {primary_data.get('Phase', 'N/A')}
Status: {primary_data.get('Overall Status', 'N/A')}
Conditions: {primary_data.get('Conditions', 'N/A')}
Interventions: {primary_data.get('Interventions', 'N/A')}

{secondary_section}

TASK: Analyze whether this statement is ENTAILMENT (supported) or CONTRADICTION (refuted).
Supervisor: Coordinate analysis with medical_expert, numerical_analyzer, logic_checker, then aggregator decides.
"""
    
    print("ğŸ¤– å•Ÿå‹•å¤šä»£ç†åˆ†æ...")
    
    # Reset group chat for new analysis
    groupchat.messages = []
    
    # Start the multi-agent analysis
    try:
        print("ğŸ“ é–‹å§‹ä»£ç†å°è©±...")
        
        # ä½¿ç”¨æ›´è©³ç´°çš„éŒ¯èª¤è™•ç†
        user_proxy.initiate_chat(
            manager,
            message=context,
            clear_history=True
        )
        
        print(f"ğŸ’¬ å°è©±å®Œæˆï¼Œå…± {len(groupchat.messages)} æ¢è¨Šæ¯")
        
        # Debug: é¡¯ç¤ºæœ€å¾Œå¹¾æ¢è¨Šæ¯
        if len(groupchat.messages) > 0:
            print("ğŸ“‹ æœ€å¾Œçš„è¨Šæ¯:")
            for i, msg in enumerate(groupchat.messages[-3:]):  # é¡¯ç¤ºæœ€å¾Œ3æ¢è¨Šæ¯
                sender = msg.get("name", "unknown")
                content = msg.get("content", "")[:100] + "..."
                print(f"  {i+1}. {sender}: {content}")
        
        # Extract final decision from the last message
        final_message = groupchat.messages[-1]["content"] if groupchat.messages else ""
        
        # Parse the final decision
        if "FINAL_DECISION: Entailment" in final_message:
            decision = "Entailment"
        elif "FINAL_DECISION: Contradiction" in final_message:
            decision = "Contradiction"
        else:
            # Fallback: look for decision keywords in the final message
            if "entailment" in final_message.lower():
                decision = "Entailment"
            else:
                decision = "Contradiction"
        
        print(f"âœ… åˆ†æå®Œæˆ: {decision}")
        return decision
                
    except Exception as e:
        print(f"âŒ ä»£ç†åˆ†æéŒ¯èª¤: {e}")
        print(f"éŒ¯èª¤é¡å‹: {type(e).__name__}")
        import traceback
        print(f"è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
        return "Contradiction"  # Conservative fallback

print("âœ… Analysis pipeline ready")


# # ğŸ§ª æ¸¬è©¦å¤šä»£ç†ç³»çµ±æ˜¯å¦æ­£å¸¸å·¥ä½œ
# def test_agent_system():
#     """æ¸¬è©¦å¤šä»£ç†ç³»çµ±æ˜¯å¦èƒ½æ­£å¸¸å”ä½œ"""
#     print("ğŸ§ª æ¸¬è©¦å¤šä»£ç†ç³»çµ±...")
#     
#     # ç°¡å–®çš„æ¸¬è©¦æ¡ˆä¾‹
#     test_context = """
#     è«‹å„ä½ä»£ç†å”ä½œåˆ†æï¼š
#     é™³è¿°: "é€™å€‹è©¦é©—æœ‰100ååƒèˆ‡è€…"
#     è©¦é©—è³‡æ–™: {"enrollment": 100, "participants": "100 patients enrolled"}
#     
#     è«‹ supervisor å”èª¿ï¼Œmedical_expert åˆ†æé†«å­¸ç›¸é—œæ€§ï¼Œnumerical_analyzer æª¢æŸ¥æ•¸å­—ï¼Œ
#     logic_checker é©—è­‰é‚è¼¯ï¼Œæœ€å¾Œ aggregator åšå‡ºæ±ºå®šã€‚
#     
#     è«‹ç¢ºä¿æ¯å€‹ä»£ç†éƒ½åƒèˆ‡è¨è«–ï¼Œæœ€å¾Œè¼¸å‡º "FINAL_DECISION: Entailment" æˆ– "FINAL_DECISION: Contradiction"
#     """
#     
#     # é‡ç½®ç¾¤çµ„èŠå¤©
#     groupchat.messages = []
#     
#     try:
#         print("ğŸ“ å•Ÿå‹•æ¸¬è©¦å°è©±...")
#         import time
#         start_time = time.time()
#         
#         user_proxy.initiate_chat(
#             manager,
#             message=test_context,
#             clear_history=True
#         )
#         
#         end_time = time.time()
#         duration = end_time - start_time
#         
#         print(f"â±ï¸ å°è©±è€—æ™‚: {duration:.2f} ç§’")
#         print(f"ğŸ’¬ ç¸½è¨Šæ¯æ•¸: {len(groupchat.messages)}")
#         
#         if len(groupchat.messages) == 0:
#             print("âŒ æ²’æœ‰ç”Ÿæˆä»»ä½•å°è©±è¨Šæ¯ï¼")
#             return False
#         elif duration < 1.0:
#             print("âš ï¸ å°è©±æ™‚é–“å¤ªçŸ­ï¼Œå¯èƒ½æ²’æœ‰çœŸæ­£åŸ·è¡Œ LLM èª¿ç”¨")
#             return False
#         else:
#             print("âœ… å¤šä»£ç†ç³»çµ±æ­£å¸¸å·¥ä½œ")
#             
#             # é¡¯ç¤ºä»£ç†åƒèˆ‡æƒ…æ³
#             agents_participated = set()
#             for msg in groupchat.messages:
#                 if "name" in msg:
#                     agents_participated.add(msg["name"])
#             
#             print(f"ğŸ¤– åƒèˆ‡çš„ä»£ç†: {list(agents_participated)}")
#             return True
#             
#     except Exception as e:
#         print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
#         return False
# 
# # é‹è¡Œæ¸¬è©¦
# test_result = test_agent_system()
# print(f"\nğŸ¯ ç³»çµ±æ¸¬è©¦çµæœ: {'é€šé' if test_result else 'å¤±æ•—'}")

# In[ ]:


# Test with a sample statement
test_statement = "there is a 13.2% difference between the results from the two the primary trial cohorts"
test_primary_id = "NCT00066573"

print(f"Testing with statement: '{test_statement}'")
print(f"Primary trial: {test_primary_id}")
print("\n" + "="*80 + "\n")

# Run the analysis
result = analyze_statement_with_agents(
    statement=test_statement,
    primary_id=test_primary_id,
    section_id="Results"
)

print(f"\n" + "="*80)
print(f"FINAL RESULT: {result}")
print("="*80)


# ## Evaluation on Training Data
# 
# Let's evaluate our AutoGen system on a subset of training data:

# In[ ]:


# Load training data
train_data = load_dataset("training_data/train.json")
print(f"Loaded {len(train_data)} training examples")

# Evaluate on first 20 examples (adjust as needed for testing)
sample_size = 20
examples = list(train_data.items())[:sample_size]

print(f"\nEvaluating on {len(examples)} examples...")

results = []
correct = 0

for i, (uuid, example) in enumerate(tqdm(examples, desc="Processing")):
    try:
        statement = example.get("Statement")
        primary_id = example.get("Primary_id")
        secondary_id = example.get("Secondary_id")
        section_id = example.get("Section_id")
        expected = example.get("Label")
        
        if not statement or not primary_id:
            results.append({
                "uuid": uuid,
                "expected": expected,
                "predicted": "SKIPPED",
                "correct": False
            })
            continue
        
        # Get prediction from multi-agent system
        predicted = analyze_statement_with_agents(
            statement=statement,
            primary_id=primary_id,
            secondary_id=secondary_id,
            section_id=section_id
        )
        
        # Check if correct
        is_correct = (predicted.strip() == expected.strip())
        if is_correct:
            correct += 1
            
        results.append({
            "uuid": uuid,
            "statement": statement[:100] + "..." if len(statement) > 100 else statement,
            "expected": expected,
            "predicted": predicted,
            "correct": is_correct
        })
        
        print(f"Example {i+1}: {expected} -> {predicted} {'âœ…' if is_correct else 'âŒ'}")
        
    except Exception as e:
        print(f"Error processing example {i+1}: {e}")
        results.append({
            "uuid": uuid,
            "expected": expected,
            "predicted": "ERROR",
            "correct": False
        })

# Calculate accuracy
accuracy = correct / len(examples) if examples else 0
print(f"\nğŸ“Š AutoGen Results:")
print(f"Accuracy: {accuracy:.2%} ({correct}/{len(examples)})")


# ## Error Analysis
# 
# Let's examine some examples where our system made mistakes:

# In[ ]:


# Show incorrect predictions for analysis
incorrect_results = [r for r in results if not r["correct"] and r["predicted"] not in ["SKIPPED", "ERROR"]]

print(f"\nğŸ” Error Analysis ({len(incorrect_results)} incorrect predictions):")
print("=" * 80)

for i, result in enumerate(incorrect_results[:5]):  # Show first 5 errors
    print(f"\nError #{i+1}:")
    print(f"Statement: {result['statement']}")
    print(f"Expected: {result['expected']}")
    print(f"Predicted: {result['predicted']}")
    print("-" * 40)


# ## Generate Submission File
# 
# Let's create a submission file for the test data:

# In[ ]:


def generate_autogen_submission(test_file="test.json", output_file="autogen_submission.json", sample_size=None):
    """
    Generate submission file using AutoGen multi-agent system.
    
    Args:
        test_file: Path to test data
        output_file: Output submission file
        sample_size: Number of examples to process (None for all)
    """
    
    # Load test data
    test_data = load_dataset(test_file)
    if not test_data:
        print(f"âŒ Could not load test data from {test_file}")
        return
    
    examples = list(test_data.items())
    if sample_size:
        examples = examples[:sample_size]
        
    print(f"ğŸš€ Generating AutoGen predictions for {len(examples)} examples...")
    
    submission = {}
    
    for i, (uuid, example) in enumerate(tqdm(examples, desc="AutoGen Processing")):
        try:
            statement = example.get("Statement")
            primary_id = example.get("Primary_id")
            secondary_id = example.get("Secondary_id")
            section_id = example.get("Section_id")
            
            if not statement or not primary_id:
                submission[uuid] = {"Prediction": "Contradiction"}  # Default fallback
                continue
                
            # Get prediction from multi-agent system
            prediction = analyze_statement_with_agents(
                statement=statement,
                primary_id=primary_id,
                secondary_id=secondary_id,
                section_id=section_id
            )
            
            submission[uuid] = {"Prediction": prediction}
            
        except Exception as e:
            print(f"Error processing {uuid}: {e}")
            submission[uuid] = {"Prediction": "Contradiction"}  # Conservative fallback
    
    # Save submission file
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(submission, f, indent=2)
    
    print(f"âœ… AutoGen submission saved to {output_file}")
    return submission

# Generate submission for a small sample (change sample_size as needed)
autogen_submission = generate_autogen_submission(
    test_file="test.json", 
    output_file="autogen_submission.json",
    sample_size=10  # Process only 10 examples for testing
)

print(f"Generated predictions for {len(autogen_submission)} examples")


# ## çµè«–èˆ‡æ´å¯Ÿ
# 
# ### AutoGen æ¡†æ¶å„ªå‹¢ï¼š
# 1. **å¤šè¦–è§’åˆ†æ**: æ¯å€‹ä»£ç†å¸¶ä¾†å°ˆé–€çš„å°ˆæ¥­çŸ¥è­˜
# 2. **çµæ§‹åŒ–å”ä½œ**: æ˜ç¢ºçš„è§’è‰²å’Œè²¬ä»»
# 3. **å½ˆæ€§å”èª¿**: ç›£ç£è€…ç®¡ç†è¤‡é›œçš„å·¥ä½œæµç¨‹
# 4. **å¼·å¥æ¨ç†**: å¤šé‡è§€é»æå‡æ±ºç­–å“è³ª
# 5. **å¯è§£é‡‹æ€§**: ä»£ç†å°è©±æä¾›æ¨ç†éç¨‹çš„æ´å¯Ÿ
# 
# ### é—œéµåŠŸèƒ½å±•ç¤ºï¼š
# - **è§’è‰²å°ˆæ¥­åŒ–**: é†«ç™‚ã€æ•¸å€¼å’Œé‚è¼¯åˆ†æ
# - **ç¾¤çµ„èŠå¤©å”èª¿**: ä»£ç†é€éçµæ§‹åŒ–å°è©±å”ä½œ
# - **ç³»çµ±åŒ–æ–¹æ³•**: ç›£ç£è€…ç¢ºä¿å…¨é¢åˆ†æ
# - **éŒ¯èª¤è™•ç†**: é‚Šç·£æ¡ˆä¾‹çš„å„ªé›…å›é€€
# - **å¯æ“´å±•æ¶æ§‹**: æ˜“æ–¼æ·»åŠ æ–°çš„å°ˆæ¥­ä»£ç†
# 
# ### å„ªåŒ–æ©Ÿæœƒï¼š
# 1. **æç¤ºå·¥ç¨‹**: å¾®èª¿ä»£ç†æŒ‡ä»¤ä»¥æå‡æ•ˆèƒ½
# 2. **ä»£ç†å”èª¿**: æ”¹å–„å°è©±æµç¨‹å’Œæ±ºç­–åˆ¶å®š
# 3. **éŒ¯èª¤åˆ†æ**: åˆ©ç”¨å¤±æ•—æ¡ˆä¾‹æ”¹é€²ä»£ç†æ¨ç†
# 4. **æ•ˆèƒ½èª¿æ•´**: æœ€ä½³åŒ–æ¨¡å‹åƒæ•¸å’Œå°è©±æ¨¡å¼
# 5. **é ˜åŸŸçŸ¥è­˜**: ç´å…¥æ›´å¤šé†«å­¸é ˜åŸŸå°ˆæ¥­çŸ¥è­˜
# 
# ### ä½•æ™‚ä½¿ç”¨ AutoGenï¼š
# - éœ€è¦å¤šé‡è¦–è§’çš„è¤‡é›œæ¨ç†ä»»å‹™
# - å¾è§’è‰²å°ˆæ¥­åŒ–ä¸­å—ç›Šçš„å•é¡Œ
# - å¯è§£é‡‹æ€§å¾ˆé‡è¦çš„å ´æ™¯
# - éœ€è¦å¼·å¥å”ä½œæ±ºç­–çš„æ‡‰ç”¨
# 
# ## ğŸ“ å­¸ç¿’é‡é»ç¸½çµ
# - **å°è©±å¼å”ä½œ**: ä»£ç†é€éè‡ªç„¶å°è©±é€²è¡Œå”ä½œ
# - **è§’è‰²åˆ†å·¥**: æ¯å€‹ä»£ç†å°ˆæ³¨æ–¼ç‰¹å®šåˆ†æé ˜åŸŸ
# - **ç›£ç£å”èª¿**: ä¸­å¤®å”èª¿ç¢ºä¿ç³»çµ±åŒ–åˆ†æ
# - **é€æ˜æ¨ç†**: å°è©±éç¨‹æä¾›æ±ºç­–é€æ˜åº¦
# 
# AutoGenåœ¨çµæ§‹åŒ–å¤šä»£ç†å”ä½œæ–¹é¢è¡¨ç¾å‡ºè‰²ï¼Œä¸¦ç‚ºæ¨ç†éç¨‹æä¾›å„ªç§€çš„é€æ˜åº¦ï¼Œä½¿å…¶æˆç‚ºè¤‡é›œè‡¨åºŠåˆ†æä»»å‹™çš„ç†æƒ³é¸æ“‡ã€‚
