{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Agno (Phidata) Framework Baseline for Clinical Trial NLP\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to use Agno (formerly Phidata) to build a high-performance, full-stack agent system for clinical trial natural language inference (NLI). Agno provides built-in memory, knowledge management, and reasoning capabilities.\n",
    "\n",
    "### Why Agno?\n",
    "- **Full-stack platform**: Comprehensive agent development environment\n",
    "- **Built-in memory**: Persistent context and conversation memory\n",
    "- **Knowledge integration**: RAG capabilities and knowledge base management\n",
    "- **High performance**: Optimized for production workloads\n",
    "- **Rich tooling**: Extensive built-in tools and integrations\n",
    "- **Enterprise ready**: Designed for large-scale applications\n",
    "\n",
    "### Agent Architecture\n",
    "We'll implement a coordinated agent system with:\n",
    "1. **Clinical Research Assistant**: Main coordinator with medical knowledge\n",
    "2. **Data Analyst Agent**: Specialized in numerical and statistical analysis\n",
    "3. **Logic Validator Agent**: Ensures logical consistency\n",
    "4. **Decision Maker Agent**: Final entailment classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## Setup and Installation\n",
    "\n",
    "First, let's set up our environment and import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "print(\"✅ Environment loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependencies",
   "metadata": {},
   "outputs": [],
   "source": "# Import required libraries\nimport json\nimport pandas as pd\nfrom tqdm import tqdm\nfrom typing import Dict, List, Any, Optional\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Phidata/Agno imports\nfrom phi.agent import Agent\nfrom phi.model.google import Gemini\nfrom phi.tools.duckduckgo import DuckDuckGo\nfrom phi.storage.agent.sqlite import SqlAgentStorage\nfrom phi.knowledge.text import TextKnowledgeBase\nfrom phi.vectordb.chroma import ChromaDb\n\nprint(\"✅ All libraries imported successfully\")"
  },
  {
   "cell_type": "markdown",
   "id": "data_utils",
   "metadata": {},
   "source": [
    "## Data Loading and Utilities\n",
    "\n",
    "Let's create utility functions for loading and processing clinical trial data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utils",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clinical_trial(trial_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"Load clinical trial data from JSON file.\n",
    "    \n",
    "    Args:\n",
    "        trial_id: The NCT identifier for the clinical trial\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing trial data or error information\n",
    "    \"\"\"\n",
    "    try:\n",
    "        file_path = os.path.join(\"training_data\", \"CT json\", f\"{trial_id}.json\")\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        return {\"error\": f\"Clinical trial {trial_id} not found\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error loading {trial_id}: {str(e)}\"}\n",
    "\n",
    "def load_dataset(filepath: str) -> Dict[str, Any]:\n",
    "    \"\"\"Load training or test dataset.\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to the JSON dataset file\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing the dataset\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        return {}\n",
    "\n",
    "def format_trial_data(trial_data: Dict[str, Any], focus_section: Optional[str] = None) -> str:\n",
    "    \"\"\"Format trial data for agent consumption.\n",
    "    \n",
    "    Args:\n",
    "        trial_data: Clinical trial data dictionary\n",
    "        focus_section: Optional section to focus on\n",
    "        \n",
    "    Returns:\n",
    "        Formatted string containing trial information\n",
    "    \"\"\"\n",
    "    if \"error\" in trial_data:\n",
    "        return f\"Error: {trial_data['error']}\"\n",
    "    \n",
    "    # Extract key sections\n",
    "    sections = {\n",
    "        \"Trial ID\": trial_data.get(\"Clinical Trial ID\", \"Unknown\"),\n",
    "        \"Eligibility\": trial_data.get(\"Eligibility\", []),\n",
    "        \"Intervention\": trial_data.get(\"Intervention\", []),\n",
    "        \"Results\": trial_data.get(\"Results\", []),\n",
    "        \"Adverse Events\": trial_data.get(\"Adverse_Events\", [])\n",
    "    }\n",
    "    \n",
    "    # Format output\n",
    "    formatted = [f\"Clinical Trial: {sections['Trial ID']}\"]\n",
    "    \n",
    "    # Focus on specific section if requested\n",
    "    if focus_section and focus_section in [\"Eligibility\", \"Intervention\", \"Results\", \"Adverse Events\"]:\n",
    "        section_data = sections[focus_section]\n",
    "        formatted.append(f\"\\n{focus_section}:\")\n",
    "        if isinstance(section_data, list):\n",
    "            for item in section_data:\n",
    "                formatted.append(f\"  - {item}\")\n",
    "        else:\n",
    "            formatted.append(f\"  {section_data}\")\n",
    "    else:\n",
    "        # Include all sections\n",
    "        for section_name, section_data in list(sections.items())[1:]:  # Skip Trial ID\n",
    "            if section_data:\n",
    "                formatted.append(f\"\\n{section_name}:\")\n",
    "                if isinstance(section_data, list):\n",
    "                    for item in section_data[:5]:  # Limit to first 5 items for readability\n",
    "                        formatted.append(f\"  - {item}\")\n",
    "                    if len(section_data) > 5:\n",
    "                        formatted.append(f\"  ... ({len(section_data)-5} more items)\")\n",
    "                else:\n",
    "                    formatted.append(f\"  {section_data}\")\n",
    "    \n",
    "    return \"\\n\".join(formatted)\n",
    "\n",
    "# Test utilities\n",
    "sample_trial = load_clinical_trial(\"NCT00066573\")\n",
    "print(f\"✅ Data utilities ready. Sample trial: {sample_trial.get('Clinical Trial ID', 'Error')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_setup",
   "metadata": {},
   "source": "## Model and Storage Configuration\n\nSet up the Gemini model and storage for agent memory:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_config",
   "metadata": {},
   "outputs": [],
   "source": "# Model configuration\nmodel = Gemini(\n    id=\"gemini-2.5-flash\",\n    api_key=os.getenv(\"GEMINI_API_KEY\"),\n    temperature=0.1  # Low temperature for consistent results\n)\n\n# Storage for agent memory (optional)\nstorage = SqlAgentStorage(\n    table_name=\"clinical_trial_agents\",\n    db_file=\"agno_agents.db\"\n)\n\nprint(\"✅ Model and storage configured\")"
  },
  {
   "cell_type": "markdown",
   "id": "knowledge_base",
   "metadata": {},
   "source": [
    "## Knowledge Base Setup\n",
    "\n",
    "Create a knowledge base with clinical trial information for RAG capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup_knowledge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create knowledge base with clinical trial concepts\n",
    "clinical_knowledge = TextKnowledgeBase(\n",
    "    sources=[\n",
    "        # Add clinical trial domain knowledge\n",
    "        \"\"\"\n",
    "        Clinical Trial Terminology:\n",
    "        \n",
    "        Entailment: A statement is entailed by trial data if it is directly supported by the evidence.\n",
    "        Contradiction: A statement contradicts trial data if it is refuted by the evidence.\n",
    "        \n",
    "        Trial Sections:\n",
    "        - Eligibility: Inclusion and exclusion criteria for participants\n",
    "        - Intervention: Treatment methods and procedures used\n",
    "        - Results: Outcome measures and statistical findings\n",
    "        - Adverse Events: Safety data and side effects reported\n",
    "        \n",
    "        Statistical Terms:\n",
    "        - Percentage: Proportion expressed as parts per hundred\n",
    "        - Confidence Interval: Range of values likely to contain the true value\n",
    "        - P-value: Probability of observing results by chance\n",
    "        - Hazard Ratio: Measure of relative risk over time\n",
    "        \n",
    "        Medical Concepts:\n",
    "        - Efficacy: How well a treatment works under ideal conditions\n",
    "        - Safety: Absence of harmful effects from treatment\n",
    "        - Primary Endpoint: Main outcome measure of a trial\n",
    "        - Secondary Endpoint: Additional outcome measures\n",
    "        \"\"\"\n",
    "    ],\n",
    "    vector_db=ChromaDb(\n",
    "        collection=\"clinical_knowledge\",\n",
    "        path=\"./agno_knowledge_db\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Load the knowledge base\n",
    "clinical_knowledge.load(recreate=False)  # Set to True to recreate\n",
    "\n",
    "print(\"✅ Knowledge base configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agent_definitions",
   "metadata": {},
   "source": [
    "## Agent Definitions\n",
    "\n",
    "Now let's define our specialized agents using Agno's capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical_agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Clinical Research Assistant - Main coordinator with medical expertise\n",
    "clinical_assistant = Agent(\n",
    "    name=\"Clinical Research Assistant\",\n",
    "    model=model,\n",
    "    storage=storage,\n",
    "    knowledge=clinical_knowledge,\n",
    "    description=\"Expert clinical researcher specializing in trial analysis and medical reasoning\",\n",
    "    instructions=[\n",
    "        \"You are a Clinical Research Assistant with deep expertise in clinical trials.\",\n",
    "        \"Your primary role is to analyze clinical trial data and statements from a medical perspective.\",\n",
    "        \"Focus on medical accuracy, clinical significance, and evidence-based reasoning.\",\n",
    "        \"Consider the clinical context and medical plausibility of statements.\",\n",
    "        \"Identify key medical concepts, terminology, and their implications.\",\n",
    "        \"Always ground your analysis in the actual trial data provided.\",\n",
    "        \"Provide clear medical reasoning for your assessments.\"\n",
    "    ],\n",
    "    show_tool_calls=False,\n",
    "    markdown=True\n",
    ")\n",
    "\n",
    "print(\"✅ Clinical Research Assistant created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_analyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Analyst Agent - Specialized in numerical and statistical analysis\n",
    "data_analyst = Agent(\n",
    "    name=\"Data Analyst\",\n",
    "    model=model,\n",
    "    storage=storage,\n",
    "    description=\"Statistical analyst specializing in clinical trial data analysis\",\n",
    "    instructions=[\n",
    "        \"You are a Data Analyst expert in statistical analysis of clinical trials.\",\n",
    "        \"Your role is to analyze numerical claims, statistics, and quantitative relationships.\",\n",
    "        \"Extract and verify all numerical values, percentages, and statistical measures.\",\n",
    "        \"Perform calculations to validate numerical relationships and claims.\",\n",
    "        \"Assess statistical significance and clinical meaningfulness of findings.\",\n",
    "        \"Identify discrepancies between stated numbers and actual trial data.\",\n",
    "        \"Be precise in your calculations and clearly show your work.\",\n",
    "        \"Consider confidence intervals, error margins, and statistical uncertainty.\"\n",
    "    ],\n",
    "    show_tool_calls=False,\n",
    "    markdown=True\n",
    ")\n",
    "\n",
    "print(\"✅ Data Analyst Agent created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logic_validator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Logic Validator Agent - Ensures logical consistency\n",
    "logic_validator = Agent(\n",
    "    name=\"Logic Validator\",\n",
    "    model=model,\n",
    "    storage=storage,\n",
    "    description=\"Logic expert specializing in reasoning validation and consistency checking\",\n",
    "    instructions=[\n",
    "        \"You are a Logic Validator expert in logical reasoning and consistency.\",\n",
    "        \"Your role is to validate the logical structure and coherence of claims.\",\n",
    "        \"Analyze cause-and-effect relationships and logical implications.\",\n",
    "        \"Check for internal consistency and logical contradictions.\",\n",
    "        \"Evaluate the validity of inferences and conclusions.\",\n",
    "        \"Identify logical fallacies or reasoning errors.\",\n",
    "        \"Ensure that conclusions follow logically from premises.\",\n",
    "        \"Focus on the logical soundness rather than medical or numerical details.\"\n",
    "    ],\n",
    "    show_tool_calls=False,\n",
    "    markdown=True\n",
    ")\n",
    "\n",
    "print(\"✅ Logic Validator Agent created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decision_maker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Decision Maker Agent - Final entailment classification\n",
    "decision_maker = Agent(\n",
    "    name=\"Decision Maker\",\n",
    "    model=model,\n",
    "    storage=storage,\n",
    "    description=\"Final decision authority for entailment classification\",\n",
    "    instructions=[\n",
    "        \"You are the Decision Maker responsible for final entailment classification.\",\n",
    "        \"Your role is to synthesize analyses from all other agents and make the final decision.\",\n",
    "        \"Consider medical, statistical, and logical evidence equally.\",\n",
    "        \"Determine if a statement is ENTAILMENT (supported) or CONTRADICTION (refuted).\",\n",
    "        \"ENTAILMENT: Statement is directly supported by the trial evidence.\",\n",
    "        \"CONTRADICTION: Statement is refuted or contradicted by the trial evidence.\",\n",
    "        \"Weigh evidence carefully and be conservative in your decisions.\",\n",
    "        \"Provide clear reasoning for your final classification.\",\n",
    "        \"Always end with: FINAL_DECISION: [Entailment/Contradiction]\"\n",
    "    ],\n",
    "    show_tool_calls=False,\n",
    "    markdown=True\n",
    ")\n",
    "\n",
    "print(\"✅ Decision Maker Agent created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pipeline",
   "metadata": {},
   "source": [
    "## Multi-Agent Analysis Pipeline\n",
    "\n",
    "Create a coordinated pipeline that leverages all agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analysis_pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agno_analysis_pipeline(statement: str, primary_id: str, secondary_id: Optional[str] = None, \n",
    "                          section_id: Optional[str] = None, verbose: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Run the complete Agno multi-agent analysis pipeline.\n",
    "    \n",
    "    Args:\n",
    "        statement: The natural language statement to analyze\n",
    "        primary_id: Primary clinical trial ID\n",
    "        secondary_id: Secondary trial ID for comparison statements\n",
    "        section_id: Relevant section of the trial\n",
    "        verbose: Whether to print intermediate results\n",
    "        \n",
    "    Returns:\n",
    "        Final decision: 'Entailment' or 'Contradiction'\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Load and format clinical trial data\n",
    "        primary_data = load_clinical_trial(primary_id)\n",
    "        secondary_data = None\n",
    "        if secondary_id:\n",
    "            secondary_data = load_clinical_trial(secondary_id)\n",
    "        \n",
    "        # Format trial data for analysis\n",
    "        primary_formatted = format_trial_data(primary_data, section_id)\n",
    "        secondary_formatted = None\n",
    "        if secondary_data:\n",
    "            secondary_formatted = format_trial_data(secondary_data, section_id)\n",
    "        \n",
    "        # Step 2: Create analysis prompt\n",
    "        analysis_prompt = f\"\"\"\n",
    "Analyze the following statement against the clinical trial evidence:\n",
    "\n",
    "STATEMENT: \"{statement}\"\n",
    "\n",
    "PRIMARY TRIAL EVIDENCE:\n",
    "{primary_formatted}\n",
    "\n",
    "{f'SECONDARY TRIAL EVIDENCE:\\n{secondary_formatted}' if secondary_formatted else ''}\n",
    "\n",
    "Please provide your expert analysis from your domain perspective.\n",
    "        \"\"\".strip()\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"📄 Analyzing: {statement[:100]}...\")\n",
    "            print(f\"🏥 Primary Trial: {primary_id}\")\n",
    "            if secondary_id:\n",
    "                print(f\"🏥 Secondary Trial: {secondary_id}\")\n",
    "        \n",
    "        # Step 3: Clinical Research Assistant Analysis\n",
    "        clinical_response = clinical_assistant.run(analysis_prompt)\n",
    "        clinical_analysis = clinical_response.content\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"🩺 Clinical Analysis: Complete\")\n",
    "        \n",
    "        # Step 4: Data Analyst Analysis\n",
    "        data_response = data_analyst.run(analysis_prompt)\n",
    "        data_analysis = data_response.content\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"📊 Data Analysis: Complete\")\n",
    "        \n",
    "        # Step 5: Logic Validator Analysis\n",
    "        logic_response = logic_validator.run(analysis_prompt)\n",
    "        logic_analysis = logic_response.content\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"🧠 Logic Validation: Complete\")\n",
    "        \n",
    "        # Step 6: Decision Making\n",
    "        decision_prompt = f\"\"\"\n",
    "Based on the following expert analyses, make the final entailment decision:\n",
    "\n",
    "ORIGINAL STATEMENT: \"{statement}\"\n",
    "\n",
    "CLINICAL RESEARCH ASSISTANT ANALYSIS:\n",
    "{clinical_analysis}\n",
    "\n",
    "DATA ANALYST ANALYSIS:\n",
    "{data_analysis}\n",
    "\n",
    "LOGIC VALIDATOR ANALYSIS:\n",
    "{logic_analysis}\n",
    "\n",
    "Synthesize these analyses and provide your final decision: Entailment or Contradiction?\n",
    "        \"\"\".strip()\n",
    "        \n",
    "        decision_response = decision_maker.run(decision_prompt)\n",
    "        final_analysis = decision_response.content\n",
    "        \n",
    "        # Step 7: Extract final decision\n",
    "        if \"FINAL_DECISION: Entailment\" in final_analysis:\n",
    "            decision = \"Entailment\"\n",
    "        elif \"FINAL_DECISION: Contradiction\" in final_analysis:\n",
    "            decision = \"Contradiction\"\n",
    "        else:\n",
    "            # Fallback parsing\n",
    "            if \"entailment\" in final_analysis.lower() and \"contradiction\" not in final_analysis.lower():\n",
    "                decision = \"Entailment\"\n",
    "            else:\n",
    "                decision = \"Contradiction\"\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"⚖️ Final Decision: {decision}\")\n",
    "            print(\"-\" * 50)\n",
    "        \n",
    "        return decision\n",
    "        \n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"❌ Error in Agno pipeline: {e}\")\n",
    "        return \"Contradiction\"  # Conservative fallback\n",
    "\n",
    "print(\"✅ Agno analysis pipeline ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test_example",
   "metadata": {},
   "source": [
    "## Test Example\n",
    "\n",
    "Let's test our Agno system with a sample case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a sample statement\n",
    "test_statement = \"there is a 13.2% difference between the results from the two the primary trial cohorts\"\n",
    "test_primary_id = \"NCT00066573\"\n",
    "\n",
    "print(f\"Testing Agno system with statement:\")\n",
    "print(f\"'{test_statement}'\")\n",
    "print(f\"Primary trial: {test_primary_id}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Run the analysis with verbose output\n",
    "result = agno_analysis_pipeline(\n",
    "    statement=test_statement,\n",
    "    primary_id=test_primary_id,\n",
    "    section_id=\"Results\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\n🎯 AGNO RESULT: {result}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation",
   "metadata": {},
   "source": [
    "## Evaluation on Training Data\n",
    "\n",
    "Let's evaluate our Agno system on training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_data = load_dataset(\"training_data/train.json\")\n",
    "print(f\"Loaded {len(train_data)} training examples\")\n",
    "\n",
    "# Evaluate on a sample (adjust sample_size as needed)\n",
    "sample_size = 25\n",
    "examples = list(train_data.items())[:sample_size]\n",
    "\n",
    "print(f\"\\nEvaluating Agno system on {len(examples)} examples...\")\n",
    "\n",
    "results = []\n",
    "correct = 0\n",
    "\n",
    "for i, (uuid, example) in enumerate(tqdm(examples, desc=\"Agno Processing\")):\n",
    "    try:\n",
    "        statement = example.get(\"Statement\")\n",
    "        primary_id = example.get(\"Primary_id\")\n",
    "        secondary_id = example.get(\"Secondary_id\")\n",
    "        section_id = example.get(\"Section_id\")\n",
    "        expected = example.get(\"Label\")\n",
    "        \n",
    "        if not statement or not primary_id:\n",
    "            results.append({\n",
    "                \"uuid\": uuid,\n",
    "                \"expected\": expected,\n",
    "                \"predicted\": \"SKIPPED\",\n",
    "                \"correct\": False\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Get prediction from Agno system\n",
    "        predicted = agno_analysis_pipeline(\n",
    "            statement=statement,\n",
    "            primary_id=primary_id,\n",
    "            secondary_id=secondary_id,\n",
    "            section_id=section_id,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Check if correct\n",
    "        is_correct = (predicted.strip() == expected.strip())\n",
    "        if is_correct:\n",
    "            correct += 1\n",
    "            \n",
    "        results.append({\n",
    "            \"uuid\": uuid,\n",
    "            \"statement\": statement[:100] + \"...\" if len(statement) > 100 else statement,\n",
    "            \"expected\": expected,\n",
    "            \"predicted\": predicted,\n",
    "            \"correct\": is_correct\n",
    "        })\n",
    "        \n",
    "        status = \"✅\" if is_correct else \"❌\"\n",
    "        print(f\"Example {i+1:2d}: {expected:12} -> {predicted:12} {status}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing example {i+1}: {e}\")\n",
    "        results.append({\n",
    "            \"uuid\": uuid,\n",
    "            \"expected\": expected,\n",
    "            \"predicted\": \"ERROR\",\n",
    "            \"correct\": False\n",
    "        })\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct / len(examples) if examples else 0\n",
    "print(f\"\\n📊 Agno Results:\")\n",
    "print(f\"Accuracy: {accuracy:.2%} ({correct}/{len(examples)})\")\n",
    "\n",
    "# Store results for comparison\n",
    "agno_results = results.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "memory_analysis",
   "metadata": {},
   "source": [
    "## Memory and Knowledge Analysis\n",
    "\n",
    "Let's analyze how Agno's memory and knowledge features work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "memory_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate memory capabilities\n",
    "print(\"🧠 Testing Agno Memory Capabilities:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test conversation memory\n",
    "memory_test_1 = clinical_assistant.run(\"Remember that NCT00066573 is about breast cancer treatment comparing exemestane and anastrozole.\")\n",
    "print(f\"Memory setup: {memory_test_1.content[:100]}...\")\n",
    "\n",
    "memory_test_2 = clinical_assistant.run(\"What trial were we just discussing?\")\n",
    "print(f\"Memory recall: {memory_test_2.content[:200]}...\")\n",
    "\n",
    "# Test knowledge base usage\n",
    "print(\"\\n📚 Testing Knowledge Base Integration:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "knowledge_test = clinical_assistant.run(\"What is the difference between entailment and contradiction in clinical trial analysis?\")\n",
    "print(f\"Knowledge response: {knowledge_test.content[:300]}...\")\n",
    "\n",
    "print(\"\\n✅ Memory and knowledge features demonstrated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "submission",
   "metadata": {},
   "source": [
    "## Generate Submission File\n",
    "\n",
    "Let's generate a submission file using our Agno system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate_submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_agno_submission(test_file=\"test.json\", output_file=\"agno_submission.json\", sample_size=None):\n",
    "    \"\"\"\n",
    "    Generate submission file using Agno system.\n",
    "    \n",
    "    Args:\n",
    "        test_file: Path to test data\n",
    "        output_file: Output submission file\n",
    "        sample_size: Number of examples to process (None for all)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load test data\n",
    "    test_data = load_dataset(test_file)\n",
    "    if not test_data:\n",
    "        print(f\"❌ Could not load test data from {test_file}\")\n",
    "        return\n",
    "    \n",
    "    examples = list(test_data.items())\n",
    "    if sample_size:\n",
    "        examples = examples[:sample_size]\n",
    "        \n",
    "    print(f\"🚀 Generating Agno predictions for {len(examples)} examples...\")\n",
    "    \n",
    "    submission = {}\n",
    "    \n",
    "    for i, (uuid, example) in enumerate(tqdm(examples, desc=\"Agno Processing\")):\n",
    "        try:\n",
    "            statement = example.get(\"Statement\")\n",
    "            primary_id = example.get(\"Primary_id\")\n",
    "            secondary_id = example.get(\"Secondary_id\")\n",
    "            section_id = example.get(\"Section_id\")\n",
    "            \n",
    "            if not statement or not primary_id:\n",
    "                submission[uuid] = {\"Prediction\": \"Contradiction\"}  # Default fallback\n",
    "                continue\n",
    "                \n",
    "            # Get prediction from Agno system\n",
    "            prediction = agno_analysis_pipeline(\n",
    "                statement=statement,\n",
    "                primary_id=primary_id,\n",
    "                secondary_id=secondary_id,\n",
    "                section_id=section_id,\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            submission[uuid] = {\"Prediction\": prediction}\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {uuid}: {e}\")\n",
    "            submission[uuid] = {\"Prediction\": \"Contradiction\"}  # Conservative fallback\n",
    "    \n",
    "    # Save submission file\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(submission, f, indent=2)\n",
    "    \n",
    "    print(f\"✅ Agno submission saved to {output_file}\")\n",
    "    return submission\n",
    "\n",
    "# Generate submission for a small sample\n",
    "agno_submission = generate_agno_submission(\n",
    "    test_file=\"test.json\", \n",
    "    output_file=\"agno_submission.json\",\n",
    "    sample_size=10  # Adjust as needed\n",
    ")\n",
    "\n",
    "print(f\"Generated predictions for {len(agno_submission)} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "error_analysis",
   "metadata": {},
   "source": [
    "## Error Analysis\n",
    "\n",
    "Let's analyze errors to understand system performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze_errors",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze incorrect predictions\n",
    "incorrect_results = [r for r in agno_results if not r[\"correct\"] and r[\"predicted\"] not in [\"SKIPPED\", \"ERROR\"]]\n",
    "\n",
    "print(f\"\\n🔍 Agno Error Analysis ({len(incorrect_results)} incorrect predictions):\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Group errors by type\n",
    "entailment_to_contradiction = [r for r in incorrect_results if r[\"expected\"] == \"Entailment\" and r[\"predicted\"] == \"Contradiction\"]\n",
    "contradiction_to_entailment = [r for r in incorrect_results if r[\"expected\"] == \"Contradiction\" and r[\"predicted\"] == \"Entailment\"]\n",
    "\n",
    "print(f\"Entailment -> Contradiction errors: {len(entailment_to_contradiction)}\")\n",
    "print(f\"Contradiction -> Entailment errors: {len(contradiction_to_entailment)}\")\n",
    "\n",
    "# Show some examples\n",
    "print(\"\\nSample errors:\")\n",
    "for i, result in enumerate(incorrect_results[:3]):\n",
    "    print(f\"\\nError #{i+1}:\")\n",
    "    print(f\"Statement: {result['statement']}\")\n",
    "    print(f\"Expected: {result['expected']} | Predicted: {result['predicted']}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusion and Insights\n",
    "\n",
    "### Agno Framework Strengths:\n",
    "1. **Full-stack capabilities**: Comprehensive agent development environment\n",
    "2. **Built-in memory**: Persistent conversation context and learning\n",
    "3. **Knowledge integration**: RAG capabilities with vector storage\n",
    "4. **High performance**: Optimized for production workloads\n",
    "5. **Rich tooling**: Extensive built-in tools and integrations\n",
    "6. **Enterprise ready**: Designed for large-scale applications\n",
    "\n",
    "### Key Features Demonstrated:\n",
    "- **Multi-agent coordination**: Clinical Assistant, Data Analyst, Logic Validator, Decision Maker\n",
    "- **Knowledge base**: Domain-specific clinical trial knowledge for RAG\n",
    "- **Memory persistence**: Conversation history and context retention\n",
    "- **Storage integration**: SQLite storage for agent state management\n",
    "- **Structured analysis**: Systematic approach to complex reasoning tasks\n",
    "\n",
    "### Architecture Benefits:\n",
    "- **Scalable design**: Easy to add new agents and capabilities\n",
    "- **Knowledge management**: Built-in RAG for domain expertise\n",
    "- **Memory continuity**: Persistent context across conversations\n",
    "- **Production ready**: Enterprise-grade features and performance\n",
    "- **Comprehensive tooling**: Rich ecosystem for agent development\n",
    "\n",
    "### Optimization Opportunities:\n",
    "1. **Knowledge base expansion**: Add more clinical trial domain knowledge\n",
    "2. **Memory optimization**: Fine-tune memory retention and retrieval\n",
    "3. **Agent specialization**: Enhance domain expertise for each agent\n",
    "4. **Tool integration**: Leverage additional Agno tools and capabilities\n",
    "5. **Performance tuning**: Optimize for speed vs. accuracy trade-offs\n",
    "\n",
    "### When to Use Agno:\n",
    "- Applications requiring persistent memory and learning\n",
    "- Systems needing knowledge base integration (RAG)\n",
    "- Enterprise applications with complex agent workflows\n",
    "- Projects requiring comprehensive tooling and infrastructure\n",
    "- Use cases where agent state persistence is important\n",
    "\n",
    "### Agno vs Other Frameworks:\n",
    "- **vs AutoGen**: Better for memory/knowledge, AutoGen better for conversations\n",
    "- **vs Atomic Agents**: More features but heavier, Atomic better for pure speed\n",
    "- **vs LangChain**: More agent-focused, LangChain broader ecosystem\n",
    "\n",
    "Agno excels in scenarios requiring persistent memory, knowledge integration, and enterprise-grade agent management, making it ideal for complex clinical analysis applications where context retention and domain expertise are crucial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}