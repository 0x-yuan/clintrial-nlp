{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/0x-yuan/clintrial-nlp/blob/main/agno_baseline.ipynb)\n",
    "\n",
    "# å”ä½œæ™ºèƒ½æ€è€ƒæ¡†æ¶åŸºç·š - è‡¨åºŠè©¦é©— NLP\n",
    "\n",
    "## æ¦‚è¿°\n",
    "\n",
    "æœ¬notebookå±•ç¤ºå¦‚ä½•ä½¿ç”¨ç°¡å–®çš„å”ä½œæ€è€ƒæ¨¡å¼é€²è¡Œè‡¨åºŠè©¦é©—è‡ªç„¶èªè¨€æ¨ç†(NLI)ã€‚æˆ‘å€‘æ¨¡æ“¬\"åœ˜éšŠå”ä½œ\"æ¦‚å¿µï¼Œè®“å¤šå€‹å°ˆæ¥­è§’è‰²å”åŒåˆ†æï¼Œæœ€çµ‚é”æˆå…±è­˜ã€‚\n",
    "\n",
    "## ğŸ“š å­¸ç¿’ç›®æ¨™\n",
    "- ç†è§£å”ä½œæ€è€ƒçš„é‡è¦æ€§\n",
    "- å»ºç«‹å°ˆæ¥­è§’è‰²å”ä½œæ¨¡å¼\n",
    "- å¯¦ä½œåœ˜éšŠå…±è­˜æ±ºç­–éç¨‹\n",
    "- è©•ä¼°ç³»çµ±æ•ˆèƒ½\n",
    "\n",
    "### ğŸ¤ å”ä½œæ€è€ƒæ¶æ§‹\n",
    "æˆ‘å€‘å¯¦ä½œ4å€‹å”ä½œè§’è‰²ï¼š\n",
    "1. **è‡¨åºŠç ”ç©¶ä¸»ç®¡**: ç¸½é«”å”èª¿å’Œé†«å­¸å°ˆæ¥­æŒ‡å°\n",
    "2. **è³‡æ–™ç§‘å­¸å®¶**: çµ±è¨ˆåˆ†æå’Œæ•¸æ“šé©—è­‰\n",
    "3. **å“è³ªä¿è­‰å“¡**: é‚è¼¯æª¢æŸ¥å’Œå“è³ªæ§åˆ¶\n",
    "4. **æ±ºç­–å§”å“¡æœƒ**: æ•´åˆæ‰€æœ‰æ„è¦‹ä¸¦é”æˆå…±è­˜\n",
    "\n",
    "> ğŸ’¡ **æ ¸å¿ƒæ¦‚å¿µ**: æ¯å€‹è§’è‰²éƒ½æœ‰ç¨ç‰¹çš„å°ˆæ¥­è¦–è§’ï¼Œé€šéå”ä½œè¨è«–ä¾†æé«˜æ±ºç­–å“è³ªã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”§ ç’°å¢ƒè¨­ç½® - ä¸€éµå®‰è£æ‰€éœ€å¥—ä»¶\n",
    "!pip install -q google-generativeai python-dotenv pandas tqdm gdown\n",
    "\n",
    "print(\"âœ… æ‰€æœ‰å¥—ä»¶å®‰è£å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¥ å¾ Google Drive ä¸‹è¼‰è¨“ç·´è³‡æ–™\n",
    "import os\n",
    "import gdown\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "# Google Drive zip æª”æ¡ˆ ID\n",
    "file_id = \"15GA5XI39DDxQ5QkIZXsFbApx1yEvCpcR\"\n",
    "zip_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "zip_filename = \"clinicaltrial-nlp.zip\"\n",
    "\n",
    "if not os.path.exists(\"training_data\"):\n",
    "    print(\"ğŸ“¥ å¾ Google Drive ä¸‹è¼‰ clinicaltrial-nlp.zip...\")\n",
    "    try:\n",
    "        gdown.download(zip_url, zip_filename, quiet=False)\n",
    "        \n",
    "        print(\"ğŸ“¦ æ­£åœ¨è§£å£“ç¸®æª”æ¡ˆ...\")\n",
    "        with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall(\".\")\n",
    "        \n",
    "        if os.path.exists(\"clintrial-nlp/training_data\"):\n",
    "            shutil.move(\"clintrial-nlp/training_data\", \"training_data\")\n",
    "            if os.path.exists(\"clintrial-nlp\"):\n",
    "                shutil.rmtree(\"clintrial-nlp\")\n",
    "        \n",
    "        os.remove(zip_filename)\n",
    "        print(\"âœ… è¨“ç·´è³‡æ–™ä¸‹è¼‰ä¸¦è§£å£“ç¸®å®Œæˆï¼\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ä¸‹è¼‰å¤±æ•—: {e}\")\n",
    "        print(\"è«‹æ‰‹å‹•ä¸‹è¼‰: https://drive.google.com/file/d/15GA5XI39DDxQ5QkIZXsFbApx1yEvCpcR/view\")\n",
    "else:\n",
    "    print(\"âœ… è¨“ç·´è³‡æ–™å·²å­˜åœ¨ï¼Œè·³éä¸‹è¼‰\")\n",
    "\n",
    "# æª¢æŸ¥ä¸‹è¼‰çš„è³‡æ–™\n",
    "if os.path.exists(\"training_data/CT json\"):\n",
    "    ct_files = len([f for f in os.listdir(\"training_data/CT json\") if f.endswith('.json')])\n",
    "    print(f\"ğŸ“„ æ‰¾åˆ° {ct_files} å€‹è‡¨åºŠè©¦é©—JSONæª”æ¡ˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§ª æº–å‚™æ¸¬è©¦è³‡æ–™é›†\n",
    "import json\n",
    "\n",
    "def create_test_data_if_needed():\n",
    "    if not os.path.exists(\"test.json\"):\n",
    "        try:\n",
    "            with open(\"training_data/train.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "                train_data = json.load(f)\n",
    "            test_data = dict(list(train_data.items())[:100])\n",
    "            with open(\"test.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(test_data, f, indent=2, ensure_ascii=False)\n",
    "            print(f\"âœ… å·²å‰µå»ºæ¸¬è©¦è³‡æ–™é›†ï¼ŒåŒ…å« {len(test_data)} å€‹æ¨£æœ¬\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ å‰µå»ºæ¸¬è©¦è³‡æ–™å¤±æ•—: {e}\")\n",
    "    else:\n",
    "        print(\"âœ… test.json å·²å­˜åœ¨\")\n",
    "\n",
    "create_test_data_if_needed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¼‰å…¥ç’°å¢ƒè®Šæ•¸å’Œå¿…è¦å‡½å¼åº«\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import google.generativeai as genai\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "load_dotenv()\n",
    "print(\"âœ… ç’°å¢ƒè®Šæ•¸è¼‰å…¥å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ¨¡å‹é…ç½®\n",
    "\n",
    "é…ç½®Google Geminiæ¨¡å‹é€²è¡Œæ¨ç†ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é…ç½® Google Gemini æ¨¡å‹\n",
    "from google.colab import userdata\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\") or userdata.get(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    print(\"âš ï¸ è«‹è¨­å®š GOOGLE_API_KEY ç’°å¢ƒè®Šæ•¸\")\n",
    "    print(\"å¯ä»¥åœ¨ Colab å·¦å´é¢æ¿çš„ 'Secrets' ä¸­è¨­å®š\")\n",
    "    raise ValueError(\"ç¼ºå°‘ API é‡‘é‘°\")\n",
    "else:\n",
    "    print(f\"âœ… æ‰¾åˆ° API é‡‘é‘°: {api_key[:8]}...{api_key[-4:]}\")\n",
    "\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# æ¸¬è©¦ API é€£æ¥\n",
    "try:\n",
    "    test_model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "    test_response = test_model.generate_content(\"Hello, respond with 'API test successful'\")\n",
    "    print(f\"âœ… API é€£æ¥æ¸¬è©¦æˆåŠŸ: {test_response.text[:50]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ API é€£æ¥æ¸¬è©¦å¤±æ•—: {e}\")\n",
    "    raise\n",
    "\n",
    "# å‰µå»º Gemini æ¨¡å‹å¯¦ä¾‹\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-2.5-flash\",\n",
    "    generation_config=genai.types.GenerationConfig(\n",
    "        temperature=0.1,\n",
    "        max_output_tokens=4096,\n",
    "        top_p=1,\n",
    "        top_k=1\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"âœ… Google Geminiæ¨¡å‹é…ç½®å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è³‡æ–™å·¥å…·å‡½å¼\n",
    "\n",
    "å»ºç«‹ç”¨æ–¼è¼‰å…¥å’Œè™•ç†è‡¨åºŠè©¦é©—è³‡æ–™çš„å·¥å…·å‡½å¼ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clinical_trial(trial_id: str) -> dict:\n",
    "    \"\"\"è¼‰å…¥è‡¨åºŠè©¦é©—è³‡æ–™\"\"\"\n",
    "    try:\n",
    "        file_path = os.path.join(\"training_data\", \"CT json\", f\"{trial_id}.json\")\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        return {\"error\": f\"æ‰¾ä¸åˆ°è‡¨åºŠè©¦é©— {trial_id}\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"è¼‰å…¥ {trial_id} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\"}\n",
    "\n",
    "def create_collaborative_context(trial_data: dict, focus_section: str = None) -> str:\n",
    "    \"\"\"å‰µå»ºå”ä½œè¨è«–çš„ä¸Šä¸‹æ–‡\"\"\"\n",
    "    if \"error\" in trial_data:\n",
    "        return f\"éŒ¯èª¤: {trial_data['error']}\"\n",
    "    \n",
    "    sections = {\n",
    "        \"Eligibility\": trial_data.get(\"Eligibility\", []),\n",
    "        \"Intervention\": trial_data.get(\"Intervention\", []),\n",
    "        \"Results\": trial_data.get(\"Results\", []),\n",
    "        \"Adverse Events\": trial_data.get(\"Adverse_Events\", [])\n",
    "    }\n",
    "    \n",
    "    context = [f\"è©¦é©—ç·¨è™Ÿ: {trial_data.get('Clinical Trial ID', 'Unknown')}\"]\n",
    "    context.append(\"\\n=== è©¦é©—è³‡æ–™æ‘˜è¦ ===\")\n",
    "    \n",
    "    if focus_section and focus_section in sections:\n",
    "        section_data = sections[focus_section]\n",
    "        context.append(f\"\\n{focus_section} é‡é»è³‡è¨Š:\")\n",
    "        if isinstance(section_data, list):\n",
    "            for i, item in enumerate(section_data[:5]):\n",
    "                context.append(f\"  {i+1}. {item}\")\n",
    "            if len(section_data) > 5:\n",
    "                context.append(f\"  ... (å¦æœ‰ {len(section_data)-5} é …è³‡è¨Š)\")\n",
    "        else:\n",
    "            context.append(f\"  {section_data}\")\n",
    "    else:\n",
    "        for section_name, section_data in sections.items():\n",
    "            if section_data:\n",
    "                context.append(f\"\\n{section_name}:\")\n",
    "                if isinstance(section_data, list):\n",
    "                    for item in section_data[:2]:\n",
    "                        context.append(f\"  â€¢ {item}\")\n",
    "                    if len(section_data) > 2:\n",
    "                        context.append(f\"  â€¢ ... (å…± {len(section_data)} é …)\")\n",
    "                else:\n",
    "                    context.append(f\"  â€¢ {section_data}\")\n",
    "    \n",
    "    return \"\\n\".join(context)\n",
    "\n",
    "# æ¸¬è©¦å·¥å…·å‡½å¼\n",
    "sample_trial = load_clinical_trial(\"NCT00066573\")\n",
    "print(f\"âœ… è³‡æ–™å·¥å…·å‡½å¼æº–å‚™å°±ç·’ã€‚ç¯„ä¾‹è©¦é©—: {sample_trial.get('Clinical Trial ID', 'éŒ¯èª¤')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å”ä½œè§’è‰²å®šç¾©\n",
    "\n",
    "å®šç¾©å››å€‹å”ä½œè§’è‰²ï¼Œæ¯å€‹è§’è‰²éƒ½æœ‰ç‰¹å®šçš„å°ˆæ¥­è·è²¬ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clinical_director_analysis(statement: str, trial_context: str) -> str:\n",
    "    \"\"\"è‡¨åºŠç ”ç©¶ä¸»ç®¡åˆ†æ\"\"\"\n",
    "    prompt = f\"\"\"ä½ æ˜¯è‡¨åºŠç ”ç©¶ä¸»ç®¡ï¼Œè² è²¬å¾æ•´é«”é†«å­¸è§’åº¦å”èª¿åˆ†æã€‚ä½ å…·æœ‰è±å¯Œçš„è‡¨åºŠè©¦é©—ç¶“é©—ã€‚\n",
    "\n",
    "éœ€è¦åˆ†æçš„é™³è¿°: \"{statement}\"\n",
    "\n",
    "è©¦é©—è³‡æ–™:\n",
    "{trial_context}\n",
    "\n",
    "ä½œç‚ºè‡¨åºŠç ”ç©¶ä¸»ç®¡ï¼Œè«‹æä¾›ä½ çš„å°ˆæ¥­åˆ†æï¼š\n",
    "1. å¾é†«å­¸å°ˆæ¥­è§’åº¦è©•ä¼°é™³è¿°çš„åˆç†æ€§\n",
    "2. è€ƒæ…®è‡¨åºŠè©¦é©—çš„æ•´é«”èƒŒæ™¯å’Œè¨­è¨ˆ\n",
    "3. è©•ä¼°é™³è¿°èˆ‡è‡¨åºŠå¯¦å‹™çš„ç›¸ç¬¦ç¨‹åº¦\n",
    "4. æä¾›åˆæ­¥çš„é†«å­¸åˆ¤æ–·\n",
    "\n",
    "è«‹æä¾›ç°¡æ½”çš„åˆ†æï¼Œæœ€å¾Œä»¥ã€Œä¸»ç®¡æ„è¦‹: [æ”¯æŒ/è³ªç–‘/éœ€è¦æ›´å¤šè³‡è¨Š]ã€çµå°¾ã€‚\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"è‡¨åºŠä¸»ç®¡åˆ†æéŒ¯èª¤: {str(e)}\"\n",
    "\n",
    "def data_scientist_analysis(statement: str, trial_context: str, director_input: str) -> str:\n",
    "    \"\"\"è³‡æ–™ç§‘å­¸å®¶åˆ†æ\"\"\"\n",
    "    prompt = f\"\"\"ä½ æ˜¯è³‡æ–™ç§‘å­¸å®¶ï¼Œå°ˆç²¾çµ±è¨ˆåˆ†æå’Œæ•¸æ“šé©—è­‰ã€‚ä½ å°‡å”åŠ©è‡¨åºŠç ”ç©¶ä¸»ç®¡é€²è¡ŒæŠ€è¡“åˆ†æã€‚\n",
    "\n",
    "éœ€è¦åˆ†æçš„é™³è¿°: \"{statement}\"\n",
    "\n",
    "è©¦é©—è³‡æ–™:\n",
    "{trial_context}\n",
    "\n",
    "è‡¨åºŠä¸»ç®¡çš„æ„è¦‹:\n",
    "{director_input}\n",
    "\n",
    "ä½œç‚ºè³‡æ–™ç§‘å­¸å®¶ï¼Œè«‹å”ä½œåˆ†æï¼š\n",
    "1. é©—è­‰é™³è¿°ä¸­æ¶‰åŠçš„æ•¸å€¼å’Œçµ±è¨ˆè³‡è¨Š\n",
    "2. æª¢æŸ¥è¨ˆç®—çš„æº–ç¢ºæ€§å’Œçµ±è¨ˆæ–¹æ³•\n",
    "3. è©•ä¼°æ•¸æ“šè§£é‡‹æ˜¯å¦æ°ç•¶\n",
    "4. èˆ‡ä¸»ç®¡çš„é†«å­¸è§€é»é€²è¡ŒæŠ€è¡“å°ç…§\n",
    "\n",
    "è«‹æä¾›æŠ€è¡“åˆ†æï¼Œæœ€å¾Œä»¥ã€Œæ•¸æ“šæ„è¦‹: [é©—è­‰é€šé/ç™¼ç¾å•é¡Œ/æ•¸æ“šä¸è¶³]ã€çµå°¾ã€‚\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"è³‡æ–™ç§‘å­¸å®¶åˆ†æéŒ¯èª¤: {str(e)}\"\n",
    "\n",
    "def quality_assurance_analysis(statement: str, director_input: str, data_input: str) -> str:\n",
    "    \"\"\"å“è³ªä¿è­‰å“¡åˆ†æ\"\"\"\n",
    "    prompt = f\"\"\"ä½ æ˜¯å“è³ªä¿è­‰å“¡ï¼Œè² è²¬é‚è¼¯æª¢æŸ¥å’Œå“è³ªæ§åˆ¶ã€‚ä½ å°‡æ•´åˆåœ˜éšŠçš„ä¸åŒè§€é»ã€‚\n",
    "\n",
    "éœ€è¦åˆ†æçš„é™³è¿°: \"{statement}\"\n",
    "\n",
    "è‡¨åºŠä¸»ç®¡çš„æ„è¦‹:\n",
    "{director_input}\n",
    "\n",
    "è³‡æ–™ç§‘å­¸å®¶çš„æ„è¦‹:\n",
    "{data_input}\n",
    "\n",
    "ä½œç‚ºå“è³ªä¿è­‰å“¡ï¼Œè«‹å”ä½œåˆ†æï¼š\n",
    "1. æª¢æŸ¥é™³è¿°çš„é‚è¼¯ä¸€è‡´æ€§\n",
    "2. é©—è­‰æ¨ç†éç¨‹æ˜¯å¦åˆç†\n",
    "3. è©•ä¼°åœ˜éšŠæ„è¦‹ä¹‹é–“çš„ä¸€è‡´æ€§\n",
    "4. è­˜åˆ¥å¯èƒ½çš„å“è³ªé¢¨éšªæˆ–çŸ›ç›¾\n",
    "\n",
    "è«‹æä¾›å“è³ªæª¢æŸ¥çµæœï¼Œæœ€å¾Œä»¥ã€Œå“è³ªæ„è¦‹: [é€šéæª¢æŸ¥/ç™¼ç¾é¢¨éšª/éœ€è¦æ¾„æ¸…]ã€çµå°¾ã€‚\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"å“è³ªä¿è­‰åˆ†æéŒ¯èª¤: {str(e)}\"\n",
    "\n",
    "def decision_committee_consensus(statement: str, director_input: str, data_input: str, qa_input: str) -> str:\n",
    "    \"\"\"æ±ºç­–å§”å“¡æœƒå…±è­˜\"\"\"\n",
    "    prompt = f\"\"\"ä½ æ˜¯æ±ºç­–å§”å“¡æœƒä¸»å¸­ï¼Œè² è²¬æ•´åˆæ‰€æœ‰åœ˜éšŠæˆå“¡çš„å°ˆæ¥­æ„è¦‹ï¼Œé”æˆæœ€çµ‚å…±è­˜ã€‚\n",
    "\n",
    "éœ€è¦æ±ºç­–çš„é™³è¿°: \"{statement}\"\n",
    "\n",
    "è‡¨åºŠç ”ç©¶ä¸»ç®¡æ„è¦‹:\n",
    "{director_input}\n",
    "\n",
    "è³‡æ–™ç§‘å­¸å®¶æ„è¦‹:\n",
    "{data_input}\n",
    "\n",
    "å“è³ªä¿è­‰å“¡æ„è¦‹:\n",
    "{qa_input}\n",
    "\n",
    "ä½œç‚ºå§”å“¡æœƒä¸»å¸­ï¼Œè«‹å”èª¿æ‰€æœ‰æ„è¦‹ä¸¦åšå‡ºæœ€çµ‚æ±ºç­–ï¼š\n",
    "1. ç¶œåˆè©•ä¼°å„å°ˆæ¥­è§’åº¦çš„æ„è¦‹\n",
    "2. æ¬Šè¡¡ä¸åŒè§€é»çš„é‡è¦æ€§\n",
    "3. è­˜åˆ¥é—œéµçš„æ±ºç­–å› ç´ \n",
    "4. é”æˆåœ˜éšŠå…±è­˜\n",
    "\n",
    "ä»»å‹™: åˆ¤æ–·é™³è¿°æ˜¯ã€Œè˜Šå«ã€(Entailment)é‚„æ˜¯ã€ŒçŸ›ç›¾ã€(Contradiction)\n",
    "- è˜Šå«: é™³è¿°è¢«è©¦é©—è­‰æ“šæ”¯æŒ\n",
    "- çŸ›ç›¾: é™³è¿°è¢«è©¦é©—è­‰æ“šåé§\n",
    "\n",
    "è«‹æä¾›ç°¡è¦çš„åœ˜éšŠå…±è­˜ç†ç”±ï¼Œç„¶å¾Œä»¥ã€Œå§”å“¡æœƒæ±ºè­°: [Entailment/Contradiction]ã€çµå°¾ã€‚\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"å§”å“¡æœƒæ±ºè­°éŒ¯èª¤: {str(e)}\"\n",
    "\n",
    "print(\"âœ… å››å€‹å”ä½œè§’è‰²å®šç¾©å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å”ä½œæ™ºèƒ½åˆ†æç®¡é“\n",
    "\n",
    "å‰µå»ºå”èª¿æ‰€æœ‰è§’è‰²çš„åœ˜éšŠå”ä½œåˆ†æç®¡é“ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collaborative_intelligence_pipeline(statement: str, primary_id: str, secondary_id: str = None, \n",
    "                                       section_id: str = None, verbose: bool = False) -> str:\n",
    "    \"\"\"é‹è¡Œå®Œæ•´çš„å”ä½œæ™ºèƒ½åˆ†æç®¡é“\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # æº–å‚™å”ä½œä¸Šä¸‹æ–‡\n",
    "        primary_data = load_clinical_trial(primary_id)\n",
    "        trial_context = create_collaborative_context(primary_data, section_id)\n",
    "        \n",
    "        if secondary_id:\n",
    "            secondary_data = load_clinical_trial(secondary_id)\n",
    "            secondary_context = create_collaborative_context(secondary_data, section_id)\n",
    "            trial_context += f\"\\n\\n=== æ¬¡è¦è©¦é©—è³‡æ–™ ===\\n{secondary_context}\"\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"ğŸ“„ å”ä½œåˆ†æé™³è¿°: {statement[:100]}...\")\n",
    "            print(f\"ğŸ¥ ä¸»è¦è©¦é©—: {primary_id}\")\n",
    "            if secondary_id:\n",
    "                print(f\"ğŸ¥ æ¬¡è¦è©¦é©—: {secondary_id}\")\n",
    "        \n",
    "        # ç¬¬ä¸€è¼ª: è‡¨åºŠç ”ç©¶ä¸»ç®¡åˆ†æ\n",
    "        director_analysis = clinical_director_analysis(statement, trial_context)\n",
    "        if verbose:\n",
    "            print(\"ğŸ‘” è‡¨åºŠç ”ç©¶ä¸»ç®¡: å®Œæˆåˆæ­¥åˆ†æ\")\n",
    "        \n",
    "        # ç¬¬äºŒè¼ª: è³‡æ–™ç§‘å­¸å®¶å”ä½œåˆ†æ\n",
    "        data_analysis = data_scientist_analysis(statement, trial_context, director_analysis)\n",
    "        if verbose:\n",
    "            print(\"ğŸ“Š è³‡æ–™ç§‘å­¸å®¶: å®ŒæˆæŠ€è¡“é©—è­‰\")\n",
    "        \n",
    "        # ç¬¬ä¸‰è¼ª: å“è³ªä¿è­‰å“¡æ•´åˆåˆ†æ\n",
    "        qa_analysis = quality_assurance_analysis(statement, director_analysis, data_analysis)\n",
    "        if verbose:\n",
    "            print(\"ğŸ” å“è³ªä¿è­‰å“¡: å®Œæˆå“è³ªæª¢æŸ¥\")\n",
    "        \n",
    "        # ç¬¬å››è¼ª: æ±ºç­–å§”å“¡æœƒé”æˆå…±è­˜\n",
    "        consensus_decision = decision_committee_consensus(\n",
    "            statement, director_analysis, data_analysis, qa_analysis\n",
    "        )\n",
    "        \n",
    "        # æå–æœ€çµ‚æ±ºç­–\n",
    "        if \"å§”å“¡æœƒæ±ºè­°: Entailment\" in consensus_decision:\n",
    "            decision = \"Entailment\"\n",
    "        elif \"å§”å“¡æœƒæ±ºè­°: Contradiction\" in consensus_decision:\n",
    "            decision = \"Contradiction\"\n",
    "        else:\n",
    "            # å‚™ç”¨è§£æ\n",
    "            if \"entailment\" in consensus_decision.lower() and \"contradiction\" not in consensus_decision.lower():\n",
    "                decision = \"Entailment\"\n",
    "            else:\n",
    "                decision = \"Contradiction\"\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"ğŸ¤ æ±ºç­–å§”å“¡æœƒ: é”æˆå…±è­˜ - {decision}\")\n",
    "            print(\"-\" * 50)\n",
    "        \n",
    "        return decision\n",
    "        \n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"âŒ å”ä½œç®¡é“éŒ¯èª¤: {e}\")\n",
    "        return \"Contradiction\"  # ä¿å®ˆçš„å‚™ç”¨æ–¹æ¡ˆ\n",
    "\n",
    "print(\"âœ… å”ä½œæ™ºèƒ½åˆ†æç®¡é“æº–å‚™å°±ç·’\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ¸¬è©¦ç¯„ä¾‹\n",
    "\n",
    "æ¸¬è©¦æˆ‘å€‘çš„å”ä½œæ™ºèƒ½ç³»çµ±ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¸¬è©¦ç¯„ä¾‹\n",
    "test_statement = \"there is a 13.2% difference between the results from the two the primary trial cohorts\"\n",
    "test_primary_id = \"NCT00066573\"\n",
    "\n",
    "print(f\"æ¸¬è©¦å”ä½œæ™ºèƒ½ç³»çµ±:\")\n",
    "print(f\"é™³è¿°: '{test_statement}'\")\n",
    "print(f\"ä¸»è¦è©¦é©—: {test_primary_id}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# åŸ·è¡Œåˆ†æ\n",
    "start_time = time.time()\n",
    "result = collaborative_intelligence_pipeline(\n",
    "    statement=test_statement,\n",
    "    primary_id=test_primary_id,\n",
    "    section_id=\"Results\",\n",
    "    verbose=True\n",
    ")\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"\\nğŸ¯ å”ä½œæ™ºèƒ½çµæœ: {result}\")\n",
    "print(f\"â±ï¸ åŸ·è¡Œæ™‚é–“: {end_time - start_time:.2f} ç§’\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åœ¨è¨“ç·´è³‡æ–™ä¸Šè©•ä¼°\n",
    "\n",
    "åœ¨è¨“ç·´è³‡æ–™æ¨£æœ¬ä¸Šè©•ä¼°æˆ‘å€‘çš„ç³»çµ±ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¼‰å…¥è¨“ç·´è³‡æ–™\n",
    "with open(\"training_data/train.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    train_data = json.load(f)\n",
    "print(f\"è¼‰å…¥ {len(train_data)} å€‹è¨“ç·´ç¯„ä¾‹\")\n",
    "\n",
    "# åœ¨æ¨£æœ¬ä¸Šè©•ä¼°\n",
    "sample_size = 12\n",
    "examples = list(train_data.items())[:sample_size]\n",
    "\n",
    "print(f\"\\nåœ¨ {len(examples)} å€‹ç¯„ä¾‹ä¸Šè©•ä¼°å”ä½œæ™ºèƒ½ç³»çµ±...\")\n",
    "\n",
    "results = []\n",
    "correct = 0\n",
    "total_time = 0\n",
    "\n",
    "for i, (uuid, example) in enumerate(tqdm(examples, desc=\"å”ä½œæ™ºèƒ½è™•ç†\")):\n",
    "    try:\n",
    "        statement = example.get(\"Statement\")\n",
    "        primary_id = example.get(\"Primary_id\")\n",
    "        secondary_id = example.get(\"Secondary_id\")\n",
    "        section_id = example.get(\"Section_id\")\n",
    "        expected = example.get(\"Label\")\n",
    "        \n",
    "        if not statement or not primary_id:\n",
    "            results.append({\n",
    "                \"uuid\": uuid,\n",
    "                \"expected\": expected,\n",
    "                \"predicted\": \"SKIPPED\",\n",
    "                \"correct\": False,\n",
    "                \"time\": 0\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # ç²å–é æ¸¬\n",
    "        start_time = time.time()\n",
    "        predicted = collaborative_intelligence_pipeline(\n",
    "            statement=statement,\n",
    "            primary_id=primary_id,\n",
    "            secondary_id=secondary_id,\n",
    "            section_id=section_id,\n",
    "            verbose=False\n",
    "        )\n",
    "        end_time = time.time()\n",
    "        \n",
    "        execution_time = end_time - start_time\n",
    "        total_time += execution_time\n",
    "        \n",
    "        # æª¢æŸ¥æ­£ç¢ºæ€§\n",
    "        is_correct = (predicted.strip() == expected.strip())\n",
    "        if is_correct:\n",
    "            correct += 1\n",
    "            \n",
    "        results.append({\n",
    "            \"uuid\": uuid,\n",
    "            \"statement\": statement[:80] + \"...\" if len(statement) > 80 else statement,\n",
    "            \"expected\": expected,\n",
    "            \"predicted\": predicted,\n",
    "            \"correct\": is_correct,\n",
    "            \"time\": execution_time\n",
    "        })\n",
    "        \n",
    "        status = \"âœ…\" if is_correct else \"âŒ\"\n",
    "        print(f\"ç¯„ä¾‹ {i+1:2d}: {expected:12} -> {predicted:12} {status} ({execution_time:.1f}s)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"è™•ç†ç¯„ä¾‹ {i+1} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
    "        results.append({\n",
    "            \"uuid\": uuid,\n",
    "            \"expected\": expected,\n",
    "            \"predicted\": \"ERROR\",\n",
    "            \"correct\": False,\n",
    "            \"time\": 0\n",
    "        })\n",
    "\n",
    "# è¨ˆç®—æº–ç¢ºç‡\n",
    "accuracy = correct / len(examples) if examples else 0\n",
    "avg_time = total_time / len(examples) if examples else 0\n",
    "\n",
    "print(f\"\\nğŸ“Š å”ä½œæ™ºèƒ½ç³»çµ±çµæœ:\")\n",
    "print(f\"æº–ç¢ºç‡: {accuracy:.2%} ({correct}/{len(examples)})\")\n",
    "print(f\"å¹³å‡åŸ·è¡Œæ™‚é–“: {avg_time:.2f} ç§’/ä¾‹\")\n",
    "print(f\"ç¸½åŸ·è¡Œæ™‚é–“: {total_time:.2f} ç§’\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç”¢ç”Ÿæäº¤æª”æ¡ˆ\n",
    "\n",
    "ä½¿ç”¨æˆ‘å€‘çš„å”ä½œæ™ºèƒ½ç³»çµ±ç”¢ç”Ÿé æ¸¬çµæœï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_collaborative_submission(test_file=\"test.json\", output_file=\"collaborative_intelligence_submission.json\", sample_size=None):\n",
    "    \"\"\"ä½¿ç”¨å”ä½œæ™ºèƒ½ç³»çµ±ç”¢ç”Ÿæäº¤æª”æ¡ˆ\"\"\"\n",
    "    \n",
    "    # è¼‰å…¥æ¸¬è©¦è³‡æ–™\n",
    "    try:\n",
    "        with open(test_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            test_data = json.load(f)\n",
    "    except:\n",
    "        print(f\"âŒ ç„¡æ³•è¼‰å…¥æ¸¬è©¦è³‡æ–™ {test_file}\")\n",
    "        return\n",
    "    \n",
    "    examples = list(test_data.items())\n",
    "    if sample_size:\n",
    "        examples = examples[:sample_size]\n",
    "        \n",
    "    print(f\"ğŸš€ ç‚º {len(examples)} å€‹ç¯„ä¾‹ç”¢ç”Ÿå”ä½œæ™ºèƒ½é æ¸¬...\")\n",
    "    \n",
    "    submission = {}\n",
    "    \n",
    "    for i, (uuid, example) in enumerate(tqdm(examples, desc=\"å”ä½œæ™ºèƒ½è™•ç†\")):\n",
    "        try:\n",
    "            statement = example.get(\"Statement\")\n",
    "            primary_id = example.get(\"Primary_id\")\n",
    "            secondary_id = example.get(\"Secondary_id\")\n",
    "            section_id = example.get(\"Section_id\")\n",
    "            \n",
    "            if not statement or not primary_id:\n",
    "                submission[uuid] = {\"Prediction\": \"Contradiction\"}\n",
    "                continue\n",
    "                \n",
    "            # ç²å–é æ¸¬\n",
    "            prediction = collaborative_intelligence_pipeline(\n",
    "                statement=statement,\n",
    "                primary_id=primary_id,\n",
    "                secondary_id=secondary_id,\n",
    "                section_id=section_id,\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            submission[uuid] = {\"Prediction\": prediction}\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"è™•ç† {uuid} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}\")\n",
    "            submission[uuid] = {\"Prediction\": \"Contradiction\"}\n",
    "    \n",
    "    # å„²å­˜æäº¤æª”æ¡ˆ\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(submission, f, indent=2)\n",
    "    \n",
    "    print(f\"âœ… å”ä½œæ™ºèƒ½æäº¤æª”æ¡ˆå·²å„²å­˜è‡³ {output_file}\")\n",
    "    return submission\n",
    "\n",
    "# ç”¢ç”Ÿå°æ¨£æœ¬æäº¤\n",
    "collaborative_submission = generate_collaborative_submission(\n",
    "    test_file=\"test.json\", \n",
    "    output_file=\"collaborative_intelligence_submission.json\",\n",
    "    sample_size=10\n",
    ")\n",
    "\n",
    "print(f\"ç‚º {len(collaborative_submission)} å€‹ç¯„ä¾‹ç”¢ç”Ÿäº†é æ¸¬\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## çµè«–\n",
    "\n",
    "### å”ä½œæ™ºèƒ½ç³»çµ±å„ªå‹¢ï¼š\n",
    "1. **åœ˜éšŠå”ä½œ**: æ¨¡æ“¬çœŸå¯¦çš„å°ˆæ¥­åœ˜éšŠæ±ºç­–éç¨‹\n",
    "2. **å¤šé‡è¦–è§’**: å¾é†«å­¸ã€æŠ€è¡“ã€å“è³ªç­‰ä¸åŒè§’åº¦åˆ†æ\n",
    "3. **å…±è­˜æ±ºç­–**: é€šéå”å•†é”æˆå¹³è¡¡çš„åˆ¤æ–·\n",
    "4. **å°ˆæ¥­åˆ†å·¥**: æ¯å€‹è§’è‰²éƒ½æœ‰æ˜ç¢ºçš„è·è²¬ç¯„åœ\n",
    "5. **å“è³ªä¿è­‰**: å…§å»ºçš„æª¢æŸ¥å’Œé©—è­‰æ©Ÿåˆ¶\n",
    "\n",
    "### å››è§’è‰²å”ä½œæ¶æ§‹ï¼š\n",
    "- **è‡¨åºŠç ”ç©¶ä¸»ç®¡**: æä¾›é†«å­¸å°ˆæ¥­æŒ‡å°å’Œæ•´é«”å”èª¿\n",
    "- **è³‡æ–™ç§‘å­¸å®¶**: é€²è¡ŒæŠ€è¡“é©—è­‰å’Œçµ±è¨ˆåˆ†æ\n",
    "- **å“è³ªä¿è­‰å“¡**: åŸ·è¡Œé‚è¼¯æª¢æŸ¥å’Œå“è³ªæ§åˆ¶\n",
    "- **æ±ºç­–å§”å“¡æœƒ**: æ•´åˆæ‰€æœ‰æ„è¦‹ä¸¦é”æˆæœ€çµ‚å…±è­˜\n",
    "\n",
    "### å”ä½œæµç¨‹ç‰¹è‰²ï¼š\n",
    "- **é †åºå”ä½œ**: æ¯å€‹è§’è‰²å»ºç«‹åœ¨å‰é¢çš„åˆ†æåŸºç¤ä¸Š\n",
    "- **äº¤å‰é©—è­‰**: ä¸åŒå°ˆæ¥­è¦–è§’çš„ç›¸äº’å°è­‰\n",
    "- **å…±è­˜æ©Ÿåˆ¶**: æœ€çµ‚æ±ºç­–åæ˜ åœ˜éšŠé›†é«”æ™ºæ…§\n",
    "- **å“è³ªæŠŠé—œ**: å¤šå±¤æ¬¡çš„æª¢æŸ¥ç¢ºä¿çµæœå¯é æ€§\n",
    "\n",
    "### é©ç”¨å ´æ™¯ï¼š\n",
    "- éœ€è¦å¤šå°ˆæ¥­å”ä½œçš„è¤‡é›œæ±ºç­–\n",
    "- è¦æ±‚é«˜å¯é æ€§çš„è‡¨åºŠåˆ†æ\n",
    "- åœ˜éšŠæ±ºç­–æµç¨‹çš„æ¨¡æ“¬\n",
    "- éœ€è¦é€æ˜åŒ–æ±ºç­–éç¨‹çš„æ‡‰ç”¨\n",
    "\n",
    "é€™å€‹å”ä½œæ™ºèƒ½ç³»çµ±å±•ç¤ºäº†å¦‚ä½•é€šéæ¨¡æ“¬å°ˆæ¥­åœ˜éšŠçš„å”ä½œæ¨¡å¼ä¾†æé«˜è‡¨åºŠè©¦é©—NLPåˆ†æçš„å“è³ªå’Œå¯é æ€§ï¼Œæ¯å€‹è§’è‰²éƒ½è²¢ç»å…¶å°ˆæ¥­å„ªå‹¢ï¼Œæœ€çµ‚é”æˆåœ˜éšŠå…±è­˜ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
