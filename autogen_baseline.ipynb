{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4f2b8d1",
   "metadata": {},
   "source": [
    "# AutoGen Framework Baseline for Clinical Trial NLP\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to use Microsoft AutoGen to build a multi-agent system for clinical trial natural language inference (NLI). AutoGen excels at multi-agent collaboration through conversation patterns.\n",
    "\n",
    "### Why AutoGen?\n",
    "- **Multi-agent dialogue**: Natural conversation between specialized agents\n",
    "- **Role specialization**: Each agent has specific expertise\n",
    "- **Flexible coordination**: Supervisor manages task distribution\n",
    "- **Robust reasoning**: Multiple perspectives improve accuracy\n",
    "\n",
    "### Agent Architecture\n",
    "Based on the teaching material, we implement:\n",
    "1. **Supervisor**: Coordinates tasks and manages workflow\n",
    "2. **Medical Expert**: Understands medical terminology and concepts\n",
    "3. **Numerical Analyzer**: Processes quantitative data and statistics\n",
    "4. **Logic Checker**: Validates logical relationships\n",
    "5. **Aggregator**: Makes final decisions based on all inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e9c5d2",
   "metadata": {},
   "source": [
    "## Setup and Installation\n",
    "\n",
    "First, let's install the required packages and set up our environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a5c8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "print(\"✅ Environment loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import autogen\n",
    "from typing import Dict, List, Any, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c6d7e8",
   "metadata": {},
   "source": [
    "## Data Loading and Utilities\n",
    "\n",
    "Let's create utility functions to load clinical trial data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_utils",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clinical_trial(trial_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"Load clinical trial data from JSON file.\n",
    "    \n",
    "    Args:\n",
    "        trial_id: The NCT identifier for the clinical trial\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing trial data or error information\n",
    "    \"\"\"\n",
    "    try:\n",
    "        file_path = os.path.join(\"training_data\", \"CT json\", f\"{trial_id}.json\")\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        return {\"error\": f\"Clinical trial {trial_id} not found\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error loading {trial_id}: {str(e)}\"}\n",
    "\n",
    "def load_dataset(filepath: str) -> Dict[str, Any]:\n",
    "    \"\"\"Load training or test dataset.\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to the JSON dataset file\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing the dataset\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        return {}\n",
    "\n",
    "# Test data loading\n",
    "sample_trial = load_clinical_trial(\"NCT00066573\")\n",
    "print(f\"✅ Data loading functions ready. Sample trial loaded: {sample_trial.get('Clinical Trial ID', 'Error')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agent_config",
   "metadata": {},
   "source": [
    "## AutoGen Agent Configuration\n",
    "\n",
    "Now let's configure our multi-agent system. Each agent has a specialized role and specific instructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for OpenAI models\n",
    "config_list = [\n",
    "    {\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"api_key\": os.getenv(\"OPENAI_API_KEY\")\n",
    "    }\n",
    "]\n",
    "\n",
    "# LLM configuration\n",
    "llm_config = {\n",
    "    \"config_list\": config_list,\n",
    "    \"temperature\": 0.1,  # Low temperature for consistent results\n",
    "    \"timeout\": 120,\n",
    "}\n",
    "\n",
    "print(\"✅ AutoGen configuration ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agent_definitions",
   "metadata": {},
   "source": [
    "## Agent Definitions\n",
    "\n",
    "Let's define each agent with their specific roles and capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_agents",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Supervisor Agent - Coordinates the overall workflow\n",
    "supervisor = autogen.AssistantAgent(\n",
    "    name=\"supervisor\",\n",
    "    system_message=\"\"\"You are the Supervisor Agent responsible for coordinating clinical trial analysis.\n",
    "    \n",
    "    Your responsibilities:\n",
    "    1. Break down complex clinical trial questions into manageable tasks\n",
    "    2. Assign tasks to appropriate specialist agents\n",
    "    3. Coordinate information flow between agents\n",
    "    4. Ensure all aspects of the statement are thoroughly analyzed\n",
    "    5. Guide the final decision-making process\n",
    "    \n",
    "    When given a statement and clinical trial data, you should:\n",
    "    - First understand what the statement claims\n",
    "    - Identify which sections of the trial are relevant\n",
    "    - Delegate specific analysis tasks to specialist agents\n",
    "    - Collect and synthesize their findings\n",
    "    \n",
    "    Always maintain a systematic approach and ensure thorough analysis.\n",
    "    \"\"\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# 2. Medical Expert Agent - Handles medical terminology and concepts\n",
    "medical_expert = autogen.AssistantAgent(\n",
    "    name=\"medical_expert\",\n",
    "    system_message=\"\"\"You are the Medical Expert Agent specializing in clinical trial analysis.\n",
    "    \n",
    "    Your expertise includes:\n",
    "    1. Medical terminology and clinical concepts\n",
    "    2. Understanding of trial phases, interventions, and outcomes\n",
    "    3. Clinical significance of findings\n",
    "    4. Medical relationships and causations\n",
    "    5. Safety profiles and adverse events\n",
    "    \n",
    "    When analyzing statements:\n",
    "    - Focus on the medical accuracy and clinical relevance\n",
    "    - Identify key medical terms and their implications\n",
    "    - Assess whether medical claims align with trial evidence\n",
    "    - Consider clinical context and medical plausibility\n",
    "    \n",
    "    Provide clear medical reasoning for your analysis.\n",
    "    \"\"\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# 3. Numerical Analyzer Agent - Processes quantitative data\n",
    "numerical_analyzer = autogen.AssistantAgent(\n",
    "    name=\"numerical_analyzer\",\n",
    "    system_message=\"\"\"You are the Numerical Analyzer Agent specializing in quantitative analysis.\n",
    "    \n",
    "    Your expertise includes:\n",
    "    1. Statistical analysis and interpretation\n",
    "    2. Numerical comparisons and calculations\n",
    "    3. Percentage, ratios, and statistical significance\n",
    "    4. Data ranges, confidence intervals, and error margins\n",
    "    5. Trend analysis and numerical patterns\n",
    "    \n",
    "    When analyzing statements:\n",
    "    - Extract and verify all numerical claims\n",
    "    - Perform calculations to validate numerical relationships\n",
    "    - Compare stated numbers with trial data\n",
    "    - Assess statistical significance and clinical relevance\n",
    "    - Identify any numerical inconsistencies or errors\n",
    "    \n",
    "    Be precise and show your calculations when relevant.\n",
    "    \"\"\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# 4. Logic Checker Agent - Validates logical relationships\n",
    "logic_checker = autogen.AssistantAgent(\n",
    "    name=\"logic_checker\",\n",
    "    system_message=\"\"\"You are the Logic Checker Agent responsible for validating logical reasoning.\n",
    "    \n",
    "    Your expertise includes:\n",
    "    1. Logical consistency and coherence\n",
    "    2. Cause-and-effect relationships\n",
    "    3. Conditional logic and implications\n",
    "    4. Contradiction detection\n",
    "    5. Multi-step reasoning validation\n",
    "    \n",
    "    When analyzing statements:\n",
    "    - Evaluate the logical structure of claims\n",
    "    - Check for internal consistency\n",
    "    - Identify logical fallacies or contradictions\n",
    "    - Assess the validity of inferences\n",
    "    - Ensure conclusions follow from premises\n",
    "    \n",
    "    Focus on the logical soundness rather than medical or numerical details.\n",
    "    \"\"\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# 5. Aggregator Agent - Makes final decisions\n",
    "aggregator = autogen.AssistantAgent(\n",
    "    name=\"aggregator\",\n",
    "    system_message=\"\"\"You are the Aggregator Agent responsible for making final entailment decisions.\n",
    "    \n",
    "    Your responsibilities:\n",
    "    1. Synthesize findings from all specialist agents\n",
    "    2. Weigh different types of evidence appropriately\n",
    "    3. Resolve conflicts between agent analyses\n",
    "    4. Make the final Entailment vs Contradiction decision\n",
    "    5. Provide confidence assessment for the decision\n",
    "    \n",
    "    Decision criteria:\n",
    "    - ENTAILMENT: Statement is directly supported by trial data\n",
    "    - CONTRADICTION: Statement is refuted by trial data\n",
    "    \n",
    "    When making decisions:\n",
    "    - Consider input from Medical Expert, Numerical Analyzer, and Logic Checker\n",
    "    - Prioritize evidence that directly addresses the statement\n",
    "    - Be conservative: if evidence is unclear, consider context carefully\n",
    "    - Always provide reasoning for your final decision\n",
    "    \n",
    "    Output format: \"FINAL_DECISION: [Entailment/Contradiction]\"\n",
    "    \"\"\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# User proxy for managing the conversation\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\").find(\"FINAL_DECISION:\") >= 0,\n",
    "    code_execution_config=False,\n",
    ")\n",
    "\n",
    "print(\"✅ All agents created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "group_chat",
   "metadata": {},
   "source": [
    "## Group Chat Setup\n",
    "\n",
    "We'll set up a group chat where agents can collaborate on analyzing each statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup_groupchat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create group chat with all agents\n",
    "groupchat = autogen.GroupChat(\n",
    "    agents=[supervisor, medical_expert, numerical_analyzer, logic_checker, aggregator, user_proxy],\n",
    "    messages=[],\n",
    "    max_round=15,  # Allow sufficient rounds for thorough analysis\n",
    "    speaker_selection_method=\"round_robin\",  # Ensure all agents participate\n",
    ")\n",
    "\n",
    "# Create group chat manager\n",
    "manager = autogen.GroupChatManager(\n",
    "    groupchat=groupchat,\n",
    "    llm_config=llm_config\n",
    ")\n",
    "\n",
    "print(\"✅ Group chat configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pipeline",
   "metadata": {},
   "source": [
    "## Clinical Trial Analysis Pipeline\n",
    "\n",
    "Now let's create our main analysis pipeline that coordinates the multi-agent analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analysis_pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_statement_with_agents(statement: str, primary_id: str, secondary_id: Optional[str] = None, \n",
    "                                section_id: Optional[str] = None) -> str:\n",
    "    \"\"\"\n",
    "    Analyze a statement using the multi-agent system.\n",
    "    \n",
    "    Args:\n",
    "        statement: The natural language statement to analyze\n",
    "        primary_id: Primary clinical trial ID\n",
    "        secondary_id: Secondary trial ID for comparison statements\n",
    "        section_id: Relevant section of the trial (Eligibility, Intervention, Results, Adverse Events)\n",
    "        \n",
    "    Returns:\n",
    "        Final decision: 'Entailment' or 'Contradiction'\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load clinical trial data\n",
    "    primary_data = load_clinical_trial(primary_id)\n",
    "    secondary_data = None\n",
    "    if secondary_id:\n",
    "        secondary_data = load_clinical_trial(secondary_id)\n",
    "    \n",
    "    # Prepare the analysis context\n",
    "    context = f\"\"\"\n",
    "    CLINICAL TRIAL ANALYSIS TASK\n",
    "    \n",
    "    Statement to analyze: \"{statement}\"\n",
    "    \n",
    "    Primary Trial ID: {primary_id}\n",
    "    Secondary Trial ID: {secondary_id if secondary_id else \"N/A\"}\n",
    "    Relevant Section: {section_id if section_id else \"All sections\"}\n",
    "    \n",
    "    PRIMARY TRIAL DATA:\n",
    "    {json.dumps(primary_data, indent=2)}\n",
    "    \n",
    "    {f'SECONDARY TRIAL DATA:\\n{json.dumps(secondary_data, indent=2)}' if secondary_data else ''}\n",
    "    \n",
    "    TASK: Determine whether the statement represents ENTAILMENT (supported by data) or CONTRADICTION (refuted by data).\n",
    "    \n",
    "    Supervisor: Please coordinate the analysis. Each specialist should examine the statement from their domain perspective.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Reset group chat for new analysis\n",
    "    groupchat.messages = []\n",
    "    \n",
    "    # Start the multi-agent analysis\n",
    "    try:\n",
    "        user_proxy.initiate_chat(\n",
    "            manager,\n",
    "            message=context\n",
    "        )\n",
    "        \n",
    "        # Extract final decision from the last message\n",
    "        final_message = groupchat.messages[-1][\"content\"] if groupchat.messages else \"\"\n",
    "        \n",
    "        # Parse the final decision\n",
    "        if \"FINAL_DECISION: Entailment\" in final_message:\n",
    "            return \"Entailment\"\n",
    "        elif \"FINAL_DECISION: Contradiction\" in final_message:\n",
    "            return \"Contradiction\"\n",
    "        else:\n",
    "            # Fallback: look for decision keywords in the final message\n",
    "            if \"entailment\" in final_message.lower():\n",
    "                return \"Entailment\"\n",
    "            else:\n",
    "                return \"Contradiction\"\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error in analysis: {e}\")\n",
    "        return \"Contradiction\"  # Conservative fallback\n",
    "\n",
    "print(\"✅ Analysis pipeline ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test_example",
   "metadata": {},
   "source": [
    "## Test Example\n",
    "\n",
    "Let's test our multi-agent system with a sample case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a sample statement\n",
    "test_statement = \"there is a 13.2% difference between the results from the two the primary trial cohorts\"\n",
    "test_primary_id = \"NCT00066573\"\n",
    "\n",
    "print(f\"Testing with statement: '{test_statement}'\")\n",
    "print(f\"Primary trial: {test_primary_id}\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Run the analysis\n",
    "result = analyze_statement_with_agents(\n",
    "    statement=test_statement,\n",
    "    primary_id=test_primary_id,\n",
    "    section_id=\"Results\"\n",
    ")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"FINAL RESULT: {result}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation",
   "metadata": {},
   "source": [
    "## Evaluation on Training Data\n",
    "\n",
    "Let's evaluate our AutoGen system on a subset of training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_data = load_dataset(\"training_data/train.json\")\n",
    "print(f\"Loaded {len(train_data)} training examples\")\n",
    "\n",
    "# Evaluate on first 20 examples (adjust as needed for testing)\n",
    "sample_size = 20\n",
    "examples = list(train_data.items())[:sample_size]\n",
    "\n",
    "print(f\"\\nEvaluating on {len(examples)} examples...\")\n",
    "\n",
    "results = []\n",
    "correct = 0\n",
    "\n",
    "for i, (uuid, example) in enumerate(tqdm(examples, desc=\"Processing\")):\n",
    "    try:\n",
    "        statement = example.get(\"Statement\")\n",
    "        primary_id = example.get(\"Primary_id\")\n",
    "        secondary_id = example.get(\"Secondary_id\")\n",
    "        section_id = example.get(\"Section_id\")\n",
    "        expected = example.get(\"Label\")\n",
    "        \n",
    "        if not statement or not primary_id:\n",
    "            results.append({\n",
    "                \"uuid\": uuid,\n",
    "                \"expected\": expected,\n",
    "                \"predicted\": \"SKIPPED\",\n",
    "                \"correct\": False\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Get prediction from multi-agent system\n",
    "        predicted = analyze_statement_with_agents(\n",
    "            statement=statement,\n",
    "            primary_id=primary_id,\n",
    "            secondary_id=secondary_id,\n",
    "            section_id=section_id\n",
    "        )\n",
    "        \n",
    "        # Check if correct\n",
    "        is_correct = (predicted.strip() == expected.strip())\n",
    "        if is_correct:\n",
    "            correct += 1\n",
    "            \n",
    "        results.append({\n",
    "            \"uuid\": uuid,\n",
    "            \"statement\": statement[:100] + \"...\" if len(statement) > 100 else statement,\n",
    "            \"expected\": expected,\n",
    "            \"predicted\": predicted,\n",
    "            \"correct\": is_correct\n",
    "        })\n",
    "        \n",
    "        print(f\"Example {i+1}: {expected} -> {predicted} {'✅' if is_correct else '❌'}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing example {i+1}: {e}\")\n",
    "        results.append({\n",
    "            \"uuid\": uuid,\n",
    "            \"expected\": expected,\n",
    "            \"predicted\": \"ERROR\",\n",
    "            \"correct\": False\n",
    "        })\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct / len(examples) if examples else 0\n",
    "print(f\"\\n📊 AutoGen Results:\")\n",
    "print(f\"Accuracy: {accuracy:.2%} ({correct}/{len(examples)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "error_analysis",
   "metadata": {},
   "source": [
    "## Error Analysis\n",
    "\n",
    "Let's examine some examples where our system made mistakes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze_errors",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show incorrect predictions for analysis\n",
    "incorrect_results = [r for r in results if not r[\"correct\"] and r[\"predicted\"] not in [\"SKIPPED\", \"ERROR\"]]\n",
    "\n",
    "print(f\"\\n🔍 Error Analysis ({len(incorrect_results)} incorrect predictions):\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, result in enumerate(incorrect_results[:5]):  # Show first 5 errors\n",
    "    print(f\"\\nError #{i+1}:\")\n",
    "    print(f\"Statement: {result['statement']}\")\n",
    "    print(f\"Expected: {result['expected']}\")\n",
    "    print(f\"Predicted: {result['predicted']}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test_submission",
   "metadata": {},
   "source": [
    "## Generate Submission File\n",
    "\n",
    "Let's create a submission file for the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate_submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_autogen_submission(test_file=\"test.json\", output_file=\"autogen_submission.json\", sample_size=None):\n",
    "    \"\"\"\n",
    "    Generate submission file using AutoGen multi-agent system.\n",
    "    \n",
    "    Args:\n",
    "        test_file: Path to test data\n",
    "        output_file: Output submission file\n",
    "        sample_size: Number of examples to process (None for all)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load test data\n",
    "    test_data = load_dataset(test_file)\n",
    "    if not test_data:\n",
    "        print(f\"❌ Could not load test data from {test_file}\")\n",
    "        return\n",
    "    \n",
    "    examples = list(test_data.items())\n",
    "    if sample_size:\n",
    "        examples = examples[:sample_size]\n",
    "        \n",
    "    print(f\"🚀 Generating AutoGen predictions for {len(examples)} examples...\")\n",
    "    \n",
    "    submission = {}\n",
    "    \n",
    "    for i, (uuid, example) in enumerate(tqdm(examples, desc=\"AutoGen Processing\")):\n",
    "        try:\n",
    "            statement = example.get(\"Statement\")\n",
    "            primary_id = example.get(\"Primary_id\")\n",
    "            secondary_id = example.get(\"Secondary_id\")\n",
    "            section_id = example.get(\"Section_id\")\n",
    "            \n",
    "            if not statement or not primary_id:\n",
    "                submission[uuid] = {\"Prediction\": \"Contradiction\"}  # Default fallback\n",
    "                continue\n",
    "                \n",
    "            # Get prediction from multi-agent system\n",
    "            prediction = analyze_statement_with_agents(\n",
    "                statement=statement,\n",
    "                primary_id=primary_id,\n",
    "                secondary_id=secondary_id,\n",
    "                section_id=section_id\n",
    "            )\n",
    "            \n",
    "            submission[uuid] = {\"Prediction\": prediction}\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {uuid}: {e}\")\n",
    "            submission[uuid] = {\"Prediction\": \"Contradiction\"}  # Conservative fallback\n",
    "    \n",
    "    # Save submission file\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(submission, f, indent=2)\n",
    "    \n",
    "    print(f\"✅ AutoGen submission saved to {output_file}\")\n",
    "    return submission\n",
    "\n",
    "# Generate submission for a small sample (change sample_size as needed)\n",
    "autogen_submission = generate_autogen_submission(\n",
    "    test_file=\"test.json\", \n",
    "    output_file=\"autogen_submission.json\",\n",
    "    sample_size=10  # Process only 10 examples for testing\n",
    ")\n",
    "\n",
    "print(f\"Generated predictions for {len(autogen_submission)} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusion and Insights\n",
    "\n",
    "### AutoGen Framework Strengths:\n",
    "1. **Multi-perspective analysis**: Each agent brings specialized expertise\n",
    "2. **Structured collaboration**: Clear roles and responsibilities\n",
    "3. **Flexible coordination**: Supervisor manages complex workflows\n",
    "4. **Robust reasoning**: Multiple viewpoints improve decision quality\n",
    "5. **Interpretability**: Agent conversations provide insight into reasoning\n",
    "\n",
    "### Key Features Demonstrated:\n",
    "- **Role specialization**: Medical, numerical, and logical analysis\n",
    "- **Group chat coordination**: Agents collaborate through structured dialogue\n",
    "- **Systematic approach**: Supervisor ensures comprehensive analysis\n",
    "- **Error handling**: Graceful fallbacks for edge cases\n",
    "- **Scalable architecture**: Easy to add new specialized agents\n",
    "\n",
    "### Optimization Opportunities:\n",
    "1. **Prompt engineering**: Fine-tune agent instructions for better performance\n",
    "2. **Agent coordination**: Improve conversation flow and decision-making\n",
    "3. **Error analysis**: Use failed cases to improve agent reasoning\n",
    "4. **Performance tuning**: Optimize model parameters and conversation patterns\n",
    "5. **Domain knowledge**: Incorporate more medical domain expertise\n",
    "\n",
    "### When to Use AutoGen:\n",
    "- Complex reasoning tasks requiring multiple perspectives\n",
    "- Problems that benefit from role specialization\n",
    "- Scenarios where interpretability is important\n",
    "- Applications needing robust collaborative decision-making\n",
    "\n",
    "AutoGen excels at structured multi-agent collaboration and provides excellent transparency into the reasoning process, making it ideal for complex clinical analysis tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}