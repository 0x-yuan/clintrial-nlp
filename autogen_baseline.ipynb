{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4f2b8d1",
   "metadata": {},
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/0x-yuan/clintrial-nlp/blob/main/autogen_baseline.ipynb)\n\n# AutoGen 框架基線 - 臨床試驗 NLP\n\n## 概述\n\n本notebook展示如何使用Microsoft AutoGen建構一個多代理系統，用於臨床試驗自然語言推理(NLI)。AutoGen在透過對話模式進行多代理協作方面表現卓越。\n\n## 📚 學習目標\n完成本教學後，您將學會：\n- 理解 AutoGen 的多代理對話框架\n- 建立專業化的角色代理\n- 實作群組聊天協作模式\n- 管理代理間的任務分配和協調\n\n### 為什麼選擇 AutoGen？\n- **多代理對話**: 代理間的自然對話\n- **角色專業化**: 每個代理都有特定的專業知識\n- **彈性協調**: 監督者管理任務分配\n- **強健推理**: 多重視角提升準確性\n\n### 🎭 代理架構\n根據教學材料，我們實作：\n1. **監督者**: 協調任務並管理工作流程\n2. **醫療專家**: 理解醫學術語和概念\n3. **數值分析員**: 處理量化資料和統計\n4. **邏輯檢查員**: 驗證邏輯關係\n5. **聚合員**: 基於所有輸入做出最終決策\n\n> 💬 **核心概念**: AutoGen的獨特之處在於代理透過對話進行協作，就像人類團隊討論問題一樣。這種自然的互動模式使得複雜推理過程更加透明和可解釋。"
  },
  {
   "cell_type": "code",
   "id": "syx92jslbf",
   "source": "# 🔧 Colab 環境設置 - 一鍵安裝 AutoGen 相關套件\n# 這個cell會靜默安裝Microsoft AutoGen多代理協作框架所需的套件\n!pip install -q pyautogen[gemini] python-dotenv pandas tqdm\n!pip install -q google-generativeai gdown\n\n# 確保 AutoGen 相關依賴完整安裝\n!pip install -q openai>=1.0.0  # AutoGen 需要 OpenAI 客戶端庫（即使不使用 OpenAI）\n!pip install -q docker  # 如果需要代碼執行功能\n\nprint(\"✅ AutoGen 多代理協作框架安裝完成！可以開始建構對話式代理團隊了\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "alumru56r6k",
   "source": "# 📥 從 Google Drive 下載訓練資料\n# 這個cell會自動下載並解壓縮 clinicaltrial-nlp.zip，確保在Colab中可以直接運行\nimport os\nimport gdown\nimport zipfile\nimport shutil\n\n# Google Drive zip 檔案 ID\nfile_id = \"15GA5XI39DDxQ5QkIZXsFbApx1yEvCpcR\"\nzip_url = f\"https://drive.google.com/uc?id={file_id}\"\nzip_filename = \"clinicaltrial-nlp.zip\"\n\n# 檢查是否已有訓練資料\nif not os.path.exists(\"training_data\"):\n    print(\"📥 從 Google Drive 下載 clinicaltrial-nlp.zip...\")\n    print(\"⚠️ 如果下載失敗，請確認:\")\n    print(\"1. Google Drive 連結的權限設定為 '知道連結的使用者'\")\n    print(\"2. 網路連線正常\")\n    print(f\"3. 檔案連結: {zip_url}\")\n    \n    try:\n        # 下載 zip 檔案\n        print(\"📥 正在下載 zip 檔案...\")\n        gdown.download(zip_url, zip_filename, quiet=False)\n        \n        # 解壓縮檔案\n        print(\"📦 正在解壓縮檔案...\")\n        with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n            zip_ref.extractall(\".\")\n        \n        # 移動 training_data 到正確位置（如果在子資料夾中）\n        if os.path.exists(\"clintrial-nlp/training_data\") and not os.path.exists(\"training_data\"):\n            print(\"📁 移動 training_data 到正確位置...\")\n            shutil.move(\"clintrial-nlp/training_data\", \"training_data\")\n            # 清理解壓縮的資料夾\n            if os.path.exists(\"clintrial-nlp\"):\n                shutil.rmtree(\"clintrial-nlp\")\n            if os.path.exists(\"__MACOSX\"):  # 清理 macOS 產生的隱藏檔案\n                shutil.rmtree(\"__MACOSX\")\n        \n        # 清理 zip 檔案\n        os.remove(zip_filename)\n        print(\"✅ 訓練資料下載並解壓縮完成！\")\n        \n    except Exception as e:\n        print(f\"❌ 下載失敗: {e}\")\n        print(\"\\n🔧 手動解決方案:\")\n        print(\"1. 點擊此連結下載 zip 檔案:\")\n        print(\"   https://drive.google.com/file/d/15GA5XI39DDxQ5QkIZXsFbApx1yEvCpcR/view?usp=sharing\")\n        print(\"2. 上傳 zip 檔案到 Colab\")\n        print(\"3. 解壓縮後重新執行後續的 cells\")\n        \n        # 創建一個提示檔案\n        os.makedirs(\"training_data\", exist_ok=True)\n        with open(\"training_data/DOWNLOAD_INSTRUCTIONS.txt\", \"w\", encoding=\"utf-8\") as f:\n            f.write(\"請手動下載並解壓縮 clinicaltrial-nlp.zip:\\n\")\n            f.write(\"https://drive.google.com/file/d/15GA5XI39DDxQ5QkIZXsFbApx1yEvCpcR/view?usp=sharing\\n\")\n        \n        print(\"\\n📝 已創建下載指示檔案於 training_data/DOWNLOAD_INSTRUCTIONS.txt\")\nelse:\n    print(\"✅ 訓練資料已存在，跳過下載\")\n\n# 檢查下載的資料結構\nif os.path.exists(\"training_data\"):\n    contents = os.listdir(\"training_data\")\n    print(f\"📂 資料夾內容: {contents}\")\n    if os.path.exists(\"training_data/CT json\"):\n        ct_files = len([f for f in os.listdir(\"training_data/CT json\") if f.endswith('.json')])\n        print(f\"📄 找到 {ct_files} 個臨床試驗JSON檔案\")\n    else:\n        print(\"⚠️ 找不到 'CT json' 子資料夾，請檢查下載是否完整\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "su14hvy4xor",
   "source": "# 🧪 準備測試資料集\nimport json\n\ndef create_test_data_if_needed():\n    if not os.path.exists(\"test.json\"):\n        try:\n            with open(\"training_data/train.json\", \"r\", encoding=\"utf-8\") as f:\n                train_data = json.load(f)\n            test_data = dict(list(train_data.items())[:100])\n            with open(\"test.json\", \"w\", encoding=\"utf-8\") as f:\n                json.dump(test_data, f, indent=2, ensure_ascii=False)\n            print(f\"✅ 已創建測試資料集，包含 {len(test_data)} 個樣本\")\n        except Exception as e:\n            print(f\"❌ 創建測試資料失敗: {e}\")\n    else:\n        print(\"✅ test.json 已存在\")\n\ncreate_test_data_if_needed()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f2e9c5d2",
   "metadata": {},
   "source": "## 環境設置和安裝\n\n首先，讓我們安裝必要的套件並設置環境：\n\n> 📝 **說明**: AutoGen框架支援多種LLM後端，這裡我們使用Google Gemini模型進行示範。"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a5c8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "print(\"✅ Environment loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import autogen\n",
    "from typing import Dict, List, Any, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c6d7e8",
   "metadata": {},
   "source": [
    "## Data Loading and Utilities\n",
    "\n",
    "Let's create utility functions to load clinical trial data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_utils",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clinical_trial(trial_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"Load clinical trial data from JSON file.\n",
    "    \n",
    "    Args:\n",
    "        trial_id: The NCT identifier for the clinical trial\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing trial data or error information\n",
    "    \"\"\"\n",
    "    try:\n",
    "        file_path = os.path.join(\"training_data\", \"CT json\", f\"{trial_id}.json\")\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        return {\"error\": f\"Clinical trial {trial_id} not found\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error loading {trial_id}: {str(e)}\"}\n",
    "\n",
    "def load_dataset(filepath: str) -> Dict[str, Any]:\n",
    "    \"\"\"Load training or test dataset.\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to the JSON dataset file\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing the dataset\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        return {}\n",
    "\n",
    "# Test data loading\n",
    "sample_trial = load_clinical_trial(\"NCT00066573\")\n",
    "print(f\"✅ Data loading functions ready. Sample trial loaded: {sample_trial.get('Clinical Trial ID', 'Error')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agent_config",
   "metadata": {},
   "source": "## AutoGen 代理配置\n\n現在讓我們使用Google Gemini配置多代理系統。每個代理都有專門的角色和特定的指令：\n\n> 🤖 **技術說明**: AutoGen的AssistantAgent類別允許我們創建具有特定專業知識和行為模式的AI代理，這些代理可以透過群組聊天進行協作。"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config_setup",
   "metadata": {},
   "outputs": [],
   "source": "# 🤖 設定Google Gemini 2.5 Flash 模型\n# AutoGen 會使用這個配置來初始化所有代理的 LLM 後端\nimport google.generativeai as genai\n\n# 設定Google Gemini API\napi_key = os.getenv(\"GEMINI_API_KEY\")\nif not api_key:\n    print(\"⚠️ 請設定 GEMINI_API_KEY 環境變數\")\n    print(\"可以在 Colab 左側面板的 'Secrets' 中設定，或使用以下方式:\")\n    print(\"import os\")\n    print(\"os.environ['GEMINI_API_KEY'] = '您的API金鑰'\")\nelse:\n    genai.configure(api_key=api_key)\n    print(\"✅ Google Gemini API 配置完成\")\n\n# AutoGen 的 LLM 配置 - 使用 Google Gemini 2.5 Flash\nconfig_list = [\n    {\n        \"model\": \"gemini-2.5-flash\",\n        \"api_key\": api_key,\n        \"api_type\": \"google\"\n    }\n]\n\nllm_config = {\n    \"config_list\": config_list,\n    \"temperature\": 0.1,  # 低溫度以獲得一致的結果\n    \"timeout\": 120,\n}\n\nprint(\"✅ AutoGen 配置已準備就緒，將使用 Google Gemini 2.5 Flash 模型\")"
  },
  {
   "cell_type": "markdown",
   "id": "agent_definitions",
   "metadata": {},
   "source": [
    "## Agent Definitions\n",
    "\n",
    "Let's define each agent with their specific roles and capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_agents",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Supervisor Agent - Coordinates the overall workflow\n",
    "supervisor = autogen.AssistantAgent(\n",
    "    name=\"supervisor\",\n",
    "    system_message=\"\"\"You are the Supervisor Agent responsible for coordinating clinical trial analysis.\n",
    "    \n",
    "    Your responsibilities:\n",
    "    1. Break down complex clinical trial questions into manageable tasks\n",
    "    2. Assign tasks to appropriate specialist agents\n",
    "    3. Coordinate information flow between agents\n",
    "    4. Ensure all aspects of the statement are thoroughly analyzed\n",
    "    5. Guide the final decision-making process\n",
    "    \n",
    "    When given a statement and clinical trial data, you should:\n",
    "    - First understand what the statement claims\n",
    "    - Identify which sections of the trial are relevant\n",
    "    - Delegate specific analysis tasks to specialist agents\n",
    "    - Collect and synthesize their findings\n",
    "    \n",
    "    Always maintain a systematic approach and ensure thorough analysis.\n",
    "    \"\"\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# 2. Medical Expert Agent - Handles medical terminology and concepts\n",
    "medical_expert = autogen.AssistantAgent(\n",
    "    name=\"medical_expert\",\n",
    "    system_message=\"\"\"You are the Medical Expert Agent specializing in clinical trial analysis.\n",
    "    \n",
    "    Your expertise includes:\n",
    "    1. Medical terminology and clinical concepts\n",
    "    2. Understanding of trial phases, interventions, and outcomes\n",
    "    3. Clinical significance of findings\n",
    "    4. Medical relationships and causations\n",
    "    5. Safety profiles and adverse events\n",
    "    \n",
    "    When analyzing statements:\n",
    "    - Focus on the medical accuracy and clinical relevance\n",
    "    - Identify key medical terms and their implications\n",
    "    - Assess whether medical claims align with trial evidence\n",
    "    - Consider clinical context and medical plausibility\n",
    "    \n",
    "    Provide clear medical reasoning for your analysis.\n",
    "    \"\"\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# 3. Numerical Analyzer Agent - Processes quantitative data\n",
    "numerical_analyzer = autogen.AssistantAgent(\n",
    "    name=\"numerical_analyzer\",\n",
    "    system_message=\"\"\"You are the Numerical Analyzer Agent specializing in quantitative analysis.\n",
    "    \n",
    "    Your expertise includes:\n",
    "    1. Statistical analysis and interpretation\n",
    "    2. Numerical comparisons and calculations\n",
    "    3. Percentage, ratios, and statistical significance\n",
    "    4. Data ranges, confidence intervals, and error margins\n",
    "    5. Trend analysis and numerical patterns\n",
    "    \n",
    "    When analyzing statements:\n",
    "    - Extract and verify all numerical claims\n",
    "    - Perform calculations to validate numerical relationships\n",
    "    - Compare stated numbers with trial data\n",
    "    - Assess statistical significance and clinical relevance\n",
    "    - Identify any numerical inconsistencies or errors\n",
    "    \n",
    "    Be precise and show your calculations when relevant.\n",
    "    \"\"\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# 4. Logic Checker Agent - Validates logical relationships\n",
    "logic_checker = autogen.AssistantAgent(\n",
    "    name=\"logic_checker\",\n",
    "    system_message=\"\"\"You are the Logic Checker Agent responsible for validating logical reasoning.\n",
    "    \n",
    "    Your expertise includes:\n",
    "    1. Logical consistency and coherence\n",
    "    2. Cause-and-effect relationships\n",
    "    3. Conditional logic and implications\n",
    "    4. Contradiction detection\n",
    "    5. Multi-step reasoning validation\n",
    "    \n",
    "    When analyzing statements:\n",
    "    - Evaluate the logical structure of claims\n",
    "    - Check for internal consistency\n",
    "    - Identify logical fallacies or contradictions\n",
    "    - Assess the validity of inferences\n",
    "    - Ensure conclusions follow from premises\n",
    "    \n",
    "    Focus on the logical soundness rather than medical or numerical details.\n",
    "    \"\"\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# 5. Aggregator Agent - Makes final decisions\n",
    "aggregator = autogen.AssistantAgent(\n",
    "    name=\"aggregator\",\n",
    "    system_message=\"\"\"You are the Aggregator Agent responsible for making final entailment decisions.\n",
    "    \n",
    "    Your responsibilities:\n",
    "    1. Synthesize findings from all specialist agents\n",
    "    2. Weigh different types of evidence appropriately\n",
    "    3. Resolve conflicts between agent analyses\n",
    "    4. Make the final Entailment vs Contradiction decision\n",
    "    5. Provide confidence assessment for the decision\n",
    "    \n",
    "    Decision criteria:\n",
    "    - ENTAILMENT: Statement is directly supported by trial data\n",
    "    - CONTRADICTION: Statement is refuted by trial data\n",
    "    \n",
    "    When making decisions:\n",
    "    - Consider input from Medical Expert, Numerical Analyzer, and Logic Checker\n",
    "    - Prioritize evidence that directly addresses the statement\n",
    "    - Be conservative: if evidence is unclear, consider context carefully\n",
    "    - Always provide reasoning for your final decision\n",
    "    \n",
    "    Output format: \"FINAL_DECISION: [Entailment/Contradiction]\"\n",
    "    \"\"\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# User proxy for managing the conversation\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\").find(\"FINAL_DECISION:\") >= 0,\n",
    "    code_execution_config=False,\n",
    ")\n",
    "\n",
    "print(\"✅ All agents created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "group_chat",
   "metadata": {},
   "source": "## 群組聊天設置\n\n我們將設置一個群組聊天，讓代理們能夠協作分析每個陳述：\n\n> 🗣️ **協作說明**: GroupChat允許多個代理在同一個對話中互動，每個代理輪流發言，分享他們的分析見解，就像團隊會議一樣。"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup_groupchat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create group chat with all agents\n",
    "groupchat = autogen.GroupChat(\n",
    "    agents=[supervisor, medical_expert, numerical_analyzer, logic_checker, aggregator, user_proxy],\n",
    "    messages=[],\n",
    "    max_round=15,  # Allow sufficient rounds for thorough analysis\n",
    "    speaker_selection_method=\"round_robin\",  # Ensure all agents participate\n",
    ")\n",
    "\n",
    "# Create group chat manager\n",
    "manager = autogen.GroupChatManager(\n",
    "    groupchat=groupchat,\n",
    "    llm_config=llm_config\n",
    ")\n",
    "\n",
    "print(\"✅ Group chat configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pipeline",
   "metadata": {},
   "source": [
    "## Clinical Trial Analysis Pipeline\n",
    "\n",
    "Now let's create our main analysis pipeline that coordinates the multi-agent analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analysis_pipeline",
   "metadata": {},
   "outputs": [],
   "source": "def analyze_statement_with_agents(statement: str, primary_id: str, secondary_id: Optional[str] = None, \n                                section_id: Optional[str] = None) -> str:\n    \"\"\"\n    Analyze a statement using the multi-agent system.\n    \n    Args:\n        statement: The natural language statement to analyze\n        primary_id: Primary clinical trial ID\n        secondary_id: Secondary trial ID for comparison statements\n        section_id: Relevant section of the trial (Eligibility, Intervention, Results, Adverse Events)\n        \n    Returns:\n        Final decision: 'Entailment' or 'Contradiction'\n    \"\"\"\n    \n    # Load clinical trial data\n    primary_data = load_clinical_trial(primary_id)\n    secondary_data = None\n    if secondary_id:\n        secondary_data = load_clinical_trial(secondary_id)\n    \n    # Prepare secondary data section\n    secondary_section = \"\"\n    if secondary_data:\n        secondary_section = f\"SECONDARY TRIAL DATA:\\n{json.dumps(secondary_data, indent=2)}\"\n    \n    # Prepare the analysis context\n    context = f\"\"\"\n    CLINICAL TRIAL ANALYSIS TASK\n    \n    Statement to analyze: \"{statement}\"\n    \n    Primary Trial ID: {primary_id}\n    Secondary Trial ID: {secondary_id if secondary_id else \"N/A\"}\n    Relevant Section: {section_id if section_id else \"All sections\"}\n    \n    PRIMARY TRIAL DATA:\n    {json.dumps(primary_data, indent=2)}\n    \n    {secondary_section}\n    \n    TASK: Determine whether the statement represents ENTAILMENT (supported by data) or CONTRADICTION (refuted by data).\n    \n    Supervisor: Please coordinate the analysis. Each specialist should examine the statement from their domain perspective.\n    \"\"\"\n    \n    # Reset group chat for new analysis\n    groupchat.messages = []\n    \n    # Start the multi-agent analysis\n    try:\n        user_proxy.initiate_chat(\n            manager,\n            message=context\n        )\n        \n        # Extract final decision from the last message\n        final_message = groupchat.messages[-1][\"content\"] if groupchat.messages else \"\"\n        \n        # Parse the final decision\n        if \"FINAL_DECISION: Entailment\" in final_message:\n            return \"Entailment\"\n        elif \"FINAL_DECISION: Contradiction\" in final_message:\n            return \"Contradiction\"\n        else:\n            # Fallback: look for decision keywords in the final message\n            if \"entailment\" in final_message.lower():\n                return \"Entailment\"\n            else:\n                return \"Contradiction\"\n                \n    except Exception as e:\n        print(f\"Error in analysis: {e}\")\n        return \"Contradiction\"  # Conservative fallback\n\nprint(\"✅ Analysis pipeline ready\")"
  },
  {
   "cell_type": "markdown",
   "id": "test_example",
   "metadata": {},
   "source": [
    "## Test Example\n",
    "\n",
    "Let's test our multi-agent system with a sample case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a sample statement\n",
    "test_statement = \"there is a 13.2% difference between the results from the two the primary trial cohorts\"\n",
    "test_primary_id = \"NCT00066573\"\n",
    "\n",
    "print(f\"Testing with statement: '{test_statement}'\")\n",
    "print(f\"Primary trial: {test_primary_id}\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Run the analysis\n",
    "result = analyze_statement_with_agents(\n",
    "    statement=test_statement,\n",
    "    primary_id=test_primary_id,\n",
    "    section_id=\"Results\"\n",
    ")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"FINAL RESULT: {result}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation",
   "metadata": {},
   "source": [
    "## Evaluation on Training Data\n",
    "\n",
    "Let's evaluate our AutoGen system on a subset of training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_data = load_dataset(\"training_data/train.json\")\n",
    "print(f\"Loaded {len(train_data)} training examples\")\n",
    "\n",
    "# Evaluate on first 20 examples (adjust as needed for testing)\n",
    "sample_size = 20\n",
    "examples = list(train_data.items())[:sample_size]\n",
    "\n",
    "print(f\"\\nEvaluating on {len(examples)} examples...\")\n",
    "\n",
    "results = []\n",
    "correct = 0\n",
    "\n",
    "for i, (uuid, example) in enumerate(tqdm(examples, desc=\"Processing\")):\n",
    "    try:\n",
    "        statement = example.get(\"Statement\")\n",
    "        primary_id = example.get(\"Primary_id\")\n",
    "        secondary_id = example.get(\"Secondary_id\")\n",
    "        section_id = example.get(\"Section_id\")\n",
    "        expected = example.get(\"Label\")\n",
    "        \n",
    "        if not statement or not primary_id:\n",
    "            results.append({\n",
    "                \"uuid\": uuid,\n",
    "                \"expected\": expected,\n",
    "                \"predicted\": \"SKIPPED\",\n",
    "                \"correct\": False\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Get prediction from multi-agent system\n",
    "        predicted = analyze_statement_with_agents(\n",
    "            statement=statement,\n",
    "            primary_id=primary_id,\n",
    "            secondary_id=secondary_id,\n",
    "            section_id=section_id\n",
    "        )\n",
    "        \n",
    "        # Check if correct\n",
    "        is_correct = (predicted.strip() == expected.strip())\n",
    "        if is_correct:\n",
    "            correct += 1\n",
    "            \n",
    "        results.append({\n",
    "            \"uuid\": uuid,\n",
    "            \"statement\": statement[:100] + \"...\" if len(statement) > 100 else statement,\n",
    "            \"expected\": expected,\n",
    "            \"predicted\": predicted,\n",
    "            \"correct\": is_correct\n",
    "        })\n",
    "        \n",
    "        print(f\"Example {i+1}: {expected} -> {predicted} {'✅' if is_correct else '❌'}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing example {i+1}: {e}\")\n",
    "        results.append({\n",
    "            \"uuid\": uuid,\n",
    "            \"expected\": expected,\n",
    "            \"predicted\": \"ERROR\",\n",
    "            \"correct\": False\n",
    "        })\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct / len(examples) if examples else 0\n",
    "print(f\"\\n📊 AutoGen Results:\")\n",
    "print(f\"Accuracy: {accuracy:.2%} ({correct}/{len(examples)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "error_analysis",
   "metadata": {},
   "source": [
    "## Error Analysis\n",
    "\n",
    "Let's examine some examples where our system made mistakes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze_errors",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show incorrect predictions for analysis\n",
    "incorrect_results = [r for r in results if not r[\"correct\"] and r[\"predicted\"] not in [\"SKIPPED\", \"ERROR\"]]\n",
    "\n",
    "print(f\"\\n🔍 Error Analysis ({len(incorrect_results)} incorrect predictions):\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, result in enumerate(incorrect_results[:5]):  # Show first 5 errors\n",
    "    print(f\"\\nError #{i+1}:\")\n",
    "    print(f\"Statement: {result['statement']}\")\n",
    "    print(f\"Expected: {result['expected']}\")\n",
    "    print(f\"Predicted: {result['predicted']}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test_submission",
   "metadata": {},
   "source": [
    "## Generate Submission File\n",
    "\n",
    "Let's create a submission file for the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate_submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_autogen_submission(test_file=\"test.json\", output_file=\"autogen_submission.json\", sample_size=None):\n",
    "    \"\"\"\n",
    "    Generate submission file using AutoGen multi-agent system.\n",
    "    \n",
    "    Args:\n",
    "        test_file: Path to test data\n",
    "        output_file: Output submission file\n",
    "        sample_size: Number of examples to process (None for all)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load test data\n",
    "    test_data = load_dataset(test_file)\n",
    "    if not test_data:\n",
    "        print(f\"❌ Could not load test data from {test_file}\")\n",
    "        return\n",
    "    \n",
    "    examples = list(test_data.items())\n",
    "    if sample_size:\n",
    "        examples = examples[:sample_size]\n",
    "        \n",
    "    print(f\"🚀 Generating AutoGen predictions for {len(examples)} examples...\")\n",
    "    \n",
    "    submission = {}\n",
    "    \n",
    "    for i, (uuid, example) in enumerate(tqdm(examples, desc=\"AutoGen Processing\")):\n",
    "        try:\n",
    "            statement = example.get(\"Statement\")\n",
    "            primary_id = example.get(\"Primary_id\")\n",
    "            secondary_id = example.get(\"Secondary_id\")\n",
    "            section_id = example.get(\"Section_id\")\n",
    "            \n",
    "            if not statement or not primary_id:\n",
    "                submission[uuid] = {\"Prediction\": \"Contradiction\"}  # Default fallback\n",
    "                continue\n",
    "                \n",
    "            # Get prediction from multi-agent system\n",
    "            prediction = analyze_statement_with_agents(\n",
    "                statement=statement,\n",
    "                primary_id=primary_id,\n",
    "                secondary_id=secondary_id,\n",
    "                section_id=section_id\n",
    "            )\n",
    "            \n",
    "            submission[uuid] = {\"Prediction\": prediction}\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {uuid}: {e}\")\n",
    "            submission[uuid] = {\"Prediction\": \"Contradiction\"}  # Conservative fallback\n",
    "    \n",
    "    # Save submission file\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(submission, f, indent=2)\n",
    "    \n",
    "    print(f\"✅ AutoGen submission saved to {output_file}\")\n",
    "    return submission\n",
    "\n",
    "# Generate submission for a small sample (change sample_size as needed)\n",
    "autogen_submission = generate_autogen_submission(\n",
    "    test_file=\"test.json\", \n",
    "    output_file=\"autogen_submission.json\",\n",
    "    sample_size=10  # Process only 10 examples for testing\n",
    ")\n",
    "\n",
    "print(f\"Generated predictions for {len(autogen_submission)} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": "## 結論與洞察\n\n### AutoGen 框架優勢：\n1. **多視角分析**: 每個代理帶來專門的專業知識\n2. **結構化協作**: 明確的角色和責任\n3. **彈性協調**: 監督者管理複雜的工作流程\n4. **強健推理**: 多重觀點提升決策品質\n5. **可解釋性**: 代理對話提供推理過程的洞察\n\n### 關鍵功能展示：\n- **角色專業化**: 醫療、數值和邏輯分析\n- **群組聊天協調**: 代理透過結構化對話協作\n- **系統化方法**: 監督者確保全面分析\n- **錯誤處理**: 邊緣案例的優雅回退\n- **可擴展架構**: 易於添加新的專業代理\n\n### 優化機會：\n1. **提示工程**: 微調代理指令以提升效能\n2. **代理協調**: 改善對話流程和決策制定\n3. **錯誤分析**: 利用失敗案例改進代理推理\n4. **效能調整**: 最佳化模型參數和對話模式\n5. **領域知識**: 納入更多醫學領域專業知識\n\n### 何時使用 AutoGen：\n- 需要多重視角的複雜推理任務\n- 從角色專業化中受益的問題\n- 可解釋性很重要的場景\n- 需要強健協作決策的應用\n\n## 🎓 學習重點總結\n- **對話式協作**: 代理透過自然對話進行協作\n- **角色分工**: 每個代理專注於特定分析領域\n- **監督協調**: 中央協調確保系統化分析\n- **透明推理**: 對話過程提供決策透明度\n\nAutoGen在結構化多代理協作方面表現出色，並為推理過程提供優秀的透明度，使其成為複雜臨床分析任務的理想選擇。"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}