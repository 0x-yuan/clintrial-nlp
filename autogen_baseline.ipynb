{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4f2b8d1",
   "metadata": {},
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/luyuan/clintrial-nlp/blob/main/autogen_baseline.ipynb)\n\n# AutoGen 框架基線 - 臨床試驗 NLP\n\n## 概述\n\n本notebook展示如何使用Microsoft AutoGen建構一個多代理系統，用於臨床試驗自然語言推理(NLI)。AutoGen在透過對話模式進行多代理協作方面表現卓越。\n\n## 📚 學習目標\n完成本教學後，您將學會：\n- 理解 AutoGen 的多代理對話框架\n- 建立專業化的角色代理\n- 實作群組聊天協作模式\n- 管理代理間的任務分配和協調\n\n### 為什麼選擇 AutoGen？\n- **多代理對話**: 代理間的自然對話\n- **角色專業化**: 每個代理都有特定的專業知識\n- **彈性協調**: 監督者管理任務分配\n- **強健推理**: 多重視角提升準確性\n\n### 🎭 代理架構\n根據教學材料，我們實作：\n1. **監督者**: 協調任務並管理工作流程\n2. **醫療專家**: 理解醫學術語和概念\n3. **數值分析員**: 處理量化資料和統計\n4. **邏輯檢查員**: 驗證邏輯關係\n5. **聚合員**: 基於所有輸入做出最終決策\n\n> 💬 **核心概念**: AutoGen的獨特之處在於代理透過對話進行協作，就像人類團隊討論問題一樣。這種自然的互動模式使得複雜推理過程更加透明和可解釋。"
  },
  {
   "cell_type": "code",
   "id": "syx92jslbf",
   "source": "# 🔧 Colab 環境設置 - 一鍵安裝 AutoGen 相關套件\n# 這個cell會靜默安裝Microsoft AutoGen多代理協作框架所需的套件\n!pip install -q pyautogen python-dotenv pandas tqdm\n!pip install -q google-generativeai\n\nprint(\"✅ AutoGen 多代理協作框架安裝完成！可以開始建構對話式代理團隊了\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f2e9c5d2",
   "metadata": {},
   "source": "## 環境設置和安裝\n\n首先，讓我們安裝必要的套件並設置環境：\n\n> 📝 **說明**: AutoGen框架支援多種LLM後端，這裡我們使用Google Gemini模型進行示範。"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a5c8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "print(\"✅ Environment loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import autogen\n",
    "from typing import Dict, List, Any, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c6d7e8",
   "metadata": {},
   "source": [
    "## Data Loading and Utilities\n",
    "\n",
    "Let's create utility functions to load clinical trial data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_utils",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clinical_trial(trial_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"Load clinical trial data from JSON file.\n",
    "    \n",
    "    Args:\n",
    "        trial_id: The NCT identifier for the clinical trial\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing trial data or error information\n",
    "    \"\"\"\n",
    "    try:\n",
    "        file_path = os.path.join(\"training_data\", \"CT json\", f\"{trial_id}.json\")\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        return {\"error\": f\"Clinical trial {trial_id} not found\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error loading {trial_id}: {str(e)}\"}\n",
    "\n",
    "def load_dataset(filepath: str) -> Dict[str, Any]:\n",
    "    \"\"\"Load training or test dataset.\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to the JSON dataset file\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing the dataset\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        return {}\n",
    "\n",
    "# Test data loading\n",
    "sample_trial = load_clinical_trial(\"NCT00066573\")\n",
    "print(f\"✅ Data loading functions ready. Sample trial loaded: {sample_trial.get('Clinical Trial ID', 'Error')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agent_config",
   "metadata": {},
   "source": "## AutoGen 代理配置\n\n現在讓我們使用Google Gemini配置多代理系統。每個代理都有專門的角色和特定的指令：\n\n> 🤖 **技術說明**: AutoGen的AssistantAgent類別允許我們創建具有特定專業知識和行為模式的AI代理，這些代理可以透過群組聊天進行協作。"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config_setup",
   "metadata": {},
   "outputs": [],
   "source": "# Configuration for Gemini models\nconfig_list = [\n    {\n        \"model\": \"gemini-2.5-flash\",\n        \"api_key\": os.getenv(\"GEMINI_API_KEY\"),\n        \"api_type\": \"google\"\n    }\n]\n\n# LLM configuration\nllm_config = {\n    \"config_list\": config_list,\n    \"temperature\": 0.1,  # Low temperature for consistent results\n    \"timeout\": 120,\n}\n\nprint(\"✅ AutoGen configuration ready\")"
  },
  {
   "cell_type": "markdown",
   "id": "agent_definitions",
   "metadata": {},
   "source": [
    "## Agent Definitions\n",
    "\n",
    "Let's define each agent with their specific roles and capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_agents",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Supervisor Agent - Coordinates the overall workflow\n",
    "supervisor = autogen.AssistantAgent(\n",
    "    name=\"supervisor\",\n",
    "    system_message=\"\"\"You are the Supervisor Agent responsible for coordinating clinical trial analysis.\n",
    "    \n",
    "    Your responsibilities:\n",
    "    1. Break down complex clinical trial questions into manageable tasks\n",
    "    2. Assign tasks to appropriate specialist agents\n",
    "    3. Coordinate information flow between agents\n",
    "    4. Ensure all aspects of the statement are thoroughly analyzed\n",
    "    5. Guide the final decision-making process\n",
    "    \n",
    "    When given a statement and clinical trial data, you should:\n",
    "    - First understand what the statement claims\n",
    "    - Identify which sections of the trial are relevant\n",
    "    - Delegate specific analysis tasks to specialist agents\n",
    "    - Collect and synthesize their findings\n",
    "    \n",
    "    Always maintain a systematic approach and ensure thorough analysis.\n",
    "    \"\"\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# 2. Medical Expert Agent - Handles medical terminology and concepts\n",
    "medical_expert = autogen.AssistantAgent(\n",
    "    name=\"medical_expert\",\n",
    "    system_message=\"\"\"You are the Medical Expert Agent specializing in clinical trial analysis.\n",
    "    \n",
    "    Your expertise includes:\n",
    "    1. Medical terminology and clinical concepts\n",
    "    2. Understanding of trial phases, interventions, and outcomes\n",
    "    3. Clinical significance of findings\n",
    "    4. Medical relationships and causations\n",
    "    5. Safety profiles and adverse events\n",
    "    \n",
    "    When analyzing statements:\n",
    "    - Focus on the medical accuracy and clinical relevance\n",
    "    - Identify key medical terms and their implications\n",
    "    - Assess whether medical claims align with trial evidence\n",
    "    - Consider clinical context and medical plausibility\n",
    "    \n",
    "    Provide clear medical reasoning for your analysis.\n",
    "    \"\"\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# 3. Numerical Analyzer Agent - Processes quantitative data\n",
    "numerical_analyzer = autogen.AssistantAgent(\n",
    "    name=\"numerical_analyzer\",\n",
    "    system_message=\"\"\"You are the Numerical Analyzer Agent specializing in quantitative analysis.\n",
    "    \n",
    "    Your expertise includes:\n",
    "    1. Statistical analysis and interpretation\n",
    "    2. Numerical comparisons and calculations\n",
    "    3. Percentage, ratios, and statistical significance\n",
    "    4. Data ranges, confidence intervals, and error margins\n",
    "    5. Trend analysis and numerical patterns\n",
    "    \n",
    "    When analyzing statements:\n",
    "    - Extract and verify all numerical claims\n",
    "    - Perform calculations to validate numerical relationships\n",
    "    - Compare stated numbers with trial data\n",
    "    - Assess statistical significance and clinical relevance\n",
    "    - Identify any numerical inconsistencies or errors\n",
    "    \n",
    "    Be precise and show your calculations when relevant.\n",
    "    \"\"\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# 4. Logic Checker Agent - Validates logical relationships\n",
    "logic_checker = autogen.AssistantAgent(\n",
    "    name=\"logic_checker\",\n",
    "    system_message=\"\"\"You are the Logic Checker Agent responsible for validating logical reasoning.\n",
    "    \n",
    "    Your expertise includes:\n",
    "    1. Logical consistency and coherence\n",
    "    2. Cause-and-effect relationships\n",
    "    3. Conditional logic and implications\n",
    "    4. Contradiction detection\n",
    "    5. Multi-step reasoning validation\n",
    "    \n",
    "    When analyzing statements:\n",
    "    - Evaluate the logical structure of claims\n",
    "    - Check for internal consistency\n",
    "    - Identify logical fallacies or contradictions\n",
    "    - Assess the validity of inferences\n",
    "    - Ensure conclusions follow from premises\n",
    "    \n",
    "    Focus on the logical soundness rather than medical or numerical details.\n",
    "    \"\"\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# 5. Aggregator Agent - Makes final decisions\n",
    "aggregator = autogen.AssistantAgent(\n",
    "    name=\"aggregator\",\n",
    "    system_message=\"\"\"You are the Aggregator Agent responsible for making final entailment decisions.\n",
    "    \n",
    "    Your responsibilities:\n",
    "    1. Synthesize findings from all specialist agents\n",
    "    2. Weigh different types of evidence appropriately\n",
    "    3. Resolve conflicts between agent analyses\n",
    "    4. Make the final Entailment vs Contradiction decision\n",
    "    5. Provide confidence assessment for the decision\n",
    "    \n",
    "    Decision criteria:\n",
    "    - ENTAILMENT: Statement is directly supported by trial data\n",
    "    - CONTRADICTION: Statement is refuted by trial data\n",
    "    \n",
    "    When making decisions:\n",
    "    - Consider input from Medical Expert, Numerical Analyzer, and Logic Checker\n",
    "    - Prioritize evidence that directly addresses the statement\n",
    "    - Be conservative: if evidence is unclear, consider context carefully\n",
    "    - Always provide reasoning for your final decision\n",
    "    \n",
    "    Output format: \"FINAL_DECISION: [Entailment/Contradiction]\"\n",
    "    \"\"\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# User proxy for managing the conversation\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\").find(\"FINAL_DECISION:\") >= 0,\n",
    "    code_execution_config=False,\n",
    ")\n",
    "\n",
    "print(\"✅ All agents created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "group_chat",
   "metadata": {},
   "source": "## 群組聊天設置\n\n我們將設置一個群組聊天，讓代理們能夠協作分析每個陳述：\n\n> 🗣️ **協作說明**: GroupChat允許多個代理在同一個對話中互動，每個代理輪流發言，分享他們的分析見解，就像團隊會議一樣。"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup_groupchat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create group chat with all agents\n",
    "groupchat = autogen.GroupChat(\n",
    "    agents=[supervisor, medical_expert, numerical_analyzer, logic_checker, aggregator, user_proxy],\n",
    "    messages=[],\n",
    "    max_round=15,  # Allow sufficient rounds for thorough analysis\n",
    "    speaker_selection_method=\"round_robin\",  # Ensure all agents participate\n",
    ")\n",
    "\n",
    "# Create group chat manager\n",
    "manager = autogen.GroupChatManager(\n",
    "    groupchat=groupchat,\n",
    "    llm_config=llm_config\n",
    ")\n",
    "\n",
    "print(\"✅ Group chat configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pipeline",
   "metadata": {},
   "source": [
    "## Clinical Trial Analysis Pipeline\n",
    "\n",
    "Now let's create our main analysis pipeline that coordinates the multi-agent analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analysis_pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_statement_with_agents(statement: str, primary_id: str, secondary_id: Optional[str] = None, \n",
    "                                section_id: Optional[str] = None) -> str:\n",
    "    \"\"\"\n",
    "    Analyze a statement using the multi-agent system.\n",
    "    \n",
    "    Args:\n",
    "        statement: The natural language statement to analyze\n",
    "        primary_id: Primary clinical trial ID\n",
    "        secondary_id: Secondary trial ID for comparison statements\n",
    "        section_id: Relevant section of the trial (Eligibility, Intervention, Results, Adverse Events)\n",
    "        \n",
    "    Returns:\n",
    "        Final decision: 'Entailment' or 'Contradiction'\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load clinical trial data\n",
    "    primary_data = load_clinical_trial(primary_id)\n",
    "    secondary_data = None\n",
    "    if secondary_id:\n",
    "        secondary_data = load_clinical_trial(secondary_id)\n",
    "    \n",
    "    # Prepare the analysis context\n",
    "    context = f\"\"\"\n",
    "    CLINICAL TRIAL ANALYSIS TASK\n",
    "    \n",
    "    Statement to analyze: \"{statement}\"\n",
    "    \n",
    "    Primary Trial ID: {primary_id}\n",
    "    Secondary Trial ID: {secondary_id if secondary_id else \"N/A\"}\n",
    "    Relevant Section: {section_id if section_id else \"All sections\"}\n",
    "    \n",
    "    PRIMARY TRIAL DATA:\n",
    "    {json.dumps(primary_data, indent=2)}\n",
    "    \n",
    "    {f'SECONDARY TRIAL DATA:\\n{json.dumps(secondary_data, indent=2)}' if secondary_data else ''}\n",
    "    \n",
    "    TASK: Determine whether the statement represents ENTAILMENT (supported by data) or CONTRADICTION (refuted by data).\n",
    "    \n",
    "    Supervisor: Please coordinate the analysis. Each specialist should examine the statement from their domain perspective.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Reset group chat for new analysis\n",
    "    groupchat.messages = []\n",
    "    \n",
    "    # Start the multi-agent analysis\n",
    "    try:\n",
    "        user_proxy.initiate_chat(\n",
    "            manager,\n",
    "            message=context\n",
    "        )\n",
    "        \n",
    "        # Extract final decision from the last message\n",
    "        final_message = groupchat.messages[-1][\"content\"] if groupchat.messages else \"\"\n",
    "        \n",
    "        # Parse the final decision\n",
    "        if \"FINAL_DECISION: Entailment\" in final_message:\n",
    "            return \"Entailment\"\n",
    "        elif \"FINAL_DECISION: Contradiction\" in final_message:\n",
    "            return \"Contradiction\"\n",
    "        else:\n",
    "            # Fallback: look for decision keywords in the final message\n",
    "            if \"entailment\" in final_message.lower():\n",
    "                return \"Entailment\"\n",
    "            else:\n",
    "                return \"Contradiction\"\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error in analysis: {e}\")\n",
    "        return \"Contradiction\"  # Conservative fallback\n",
    "\n",
    "print(\"✅ Analysis pipeline ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test_example",
   "metadata": {},
   "source": [
    "## Test Example\n",
    "\n",
    "Let's test our multi-agent system with a sample case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a sample statement\n",
    "test_statement = \"there is a 13.2% difference between the results from the two the primary trial cohorts\"\n",
    "test_primary_id = \"NCT00066573\"\n",
    "\n",
    "print(f\"Testing with statement: '{test_statement}'\")\n",
    "print(f\"Primary trial: {test_primary_id}\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Run the analysis\n",
    "result = analyze_statement_with_agents(\n",
    "    statement=test_statement,\n",
    "    primary_id=test_primary_id,\n",
    "    section_id=\"Results\"\n",
    ")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"FINAL RESULT: {result}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation",
   "metadata": {},
   "source": [
    "## Evaluation on Training Data\n",
    "\n",
    "Let's evaluate our AutoGen system on a subset of training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_data = load_dataset(\"training_data/train.json\")\n",
    "print(f\"Loaded {len(train_data)} training examples\")\n",
    "\n",
    "# Evaluate on first 20 examples (adjust as needed for testing)\n",
    "sample_size = 20\n",
    "examples = list(train_data.items())[:sample_size]\n",
    "\n",
    "print(f\"\\nEvaluating on {len(examples)} examples...\")\n",
    "\n",
    "results = []\n",
    "correct = 0\n",
    "\n",
    "for i, (uuid, example) in enumerate(tqdm(examples, desc=\"Processing\")):\n",
    "    try:\n",
    "        statement = example.get(\"Statement\")\n",
    "        primary_id = example.get(\"Primary_id\")\n",
    "        secondary_id = example.get(\"Secondary_id\")\n",
    "        section_id = example.get(\"Section_id\")\n",
    "        expected = example.get(\"Label\")\n",
    "        \n",
    "        if not statement or not primary_id:\n",
    "            results.append({\n",
    "                \"uuid\": uuid,\n",
    "                \"expected\": expected,\n",
    "                \"predicted\": \"SKIPPED\",\n",
    "                \"correct\": False\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Get prediction from multi-agent system\n",
    "        predicted = analyze_statement_with_agents(\n",
    "            statement=statement,\n",
    "            primary_id=primary_id,\n",
    "            secondary_id=secondary_id,\n",
    "            section_id=section_id\n",
    "        )\n",
    "        \n",
    "        # Check if correct\n",
    "        is_correct = (predicted.strip() == expected.strip())\n",
    "        if is_correct:\n",
    "            correct += 1\n",
    "            \n",
    "        results.append({\n",
    "            \"uuid\": uuid,\n",
    "            \"statement\": statement[:100] + \"...\" if len(statement) > 100 else statement,\n",
    "            \"expected\": expected,\n",
    "            \"predicted\": predicted,\n",
    "            \"correct\": is_correct\n",
    "        })\n",
    "        \n",
    "        print(f\"Example {i+1}: {expected} -> {predicted} {'✅' if is_correct else '❌'}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing example {i+1}: {e}\")\n",
    "        results.append({\n",
    "            \"uuid\": uuid,\n",
    "            \"expected\": expected,\n",
    "            \"predicted\": \"ERROR\",\n",
    "            \"correct\": False\n",
    "        })\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct / len(examples) if examples else 0\n",
    "print(f\"\\n📊 AutoGen Results:\")\n",
    "print(f\"Accuracy: {accuracy:.2%} ({correct}/{len(examples)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "error_analysis",
   "metadata": {},
   "source": [
    "## Error Analysis\n",
    "\n",
    "Let's examine some examples where our system made mistakes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze_errors",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show incorrect predictions for analysis\n",
    "incorrect_results = [r for r in results if not r[\"correct\"] and r[\"predicted\"] not in [\"SKIPPED\", \"ERROR\"]]\n",
    "\n",
    "print(f\"\\n🔍 Error Analysis ({len(incorrect_results)} incorrect predictions):\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, result in enumerate(incorrect_results[:5]):  # Show first 5 errors\n",
    "    print(f\"\\nError #{i+1}:\")\n",
    "    print(f\"Statement: {result['statement']}\")\n",
    "    print(f\"Expected: {result['expected']}\")\n",
    "    print(f\"Predicted: {result['predicted']}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test_submission",
   "metadata": {},
   "source": [
    "## Generate Submission File\n",
    "\n",
    "Let's create a submission file for the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate_submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_autogen_submission(test_file=\"test.json\", output_file=\"autogen_submission.json\", sample_size=None):\n",
    "    \"\"\"\n",
    "    Generate submission file using AutoGen multi-agent system.\n",
    "    \n",
    "    Args:\n",
    "        test_file: Path to test data\n",
    "        output_file: Output submission file\n",
    "        sample_size: Number of examples to process (None for all)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load test data\n",
    "    test_data = load_dataset(test_file)\n",
    "    if not test_data:\n",
    "        print(f\"❌ Could not load test data from {test_file}\")\n",
    "        return\n",
    "    \n",
    "    examples = list(test_data.items())\n",
    "    if sample_size:\n",
    "        examples = examples[:sample_size]\n",
    "        \n",
    "    print(f\"🚀 Generating AutoGen predictions for {len(examples)} examples...\")\n",
    "    \n",
    "    submission = {}\n",
    "    \n",
    "    for i, (uuid, example) in enumerate(tqdm(examples, desc=\"AutoGen Processing\")):\n",
    "        try:\n",
    "            statement = example.get(\"Statement\")\n",
    "            primary_id = example.get(\"Primary_id\")\n",
    "            secondary_id = example.get(\"Secondary_id\")\n",
    "            section_id = example.get(\"Section_id\")\n",
    "            \n",
    "            if not statement or not primary_id:\n",
    "                submission[uuid] = {\"Prediction\": \"Contradiction\"}  # Default fallback\n",
    "                continue\n",
    "                \n",
    "            # Get prediction from multi-agent system\n",
    "            prediction = analyze_statement_with_agents(\n",
    "                statement=statement,\n",
    "                primary_id=primary_id,\n",
    "                secondary_id=secondary_id,\n",
    "                section_id=section_id\n",
    "            )\n",
    "            \n",
    "            submission[uuid] = {\"Prediction\": prediction}\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {uuid}: {e}\")\n",
    "            submission[uuid] = {\"Prediction\": \"Contradiction\"}  # Conservative fallback\n",
    "    \n",
    "    # Save submission file\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(submission, f, indent=2)\n",
    "    \n",
    "    print(f\"✅ AutoGen submission saved to {output_file}\")\n",
    "    return submission\n",
    "\n",
    "# Generate submission for a small sample (change sample_size as needed)\n",
    "autogen_submission = generate_autogen_submission(\n",
    "    test_file=\"test.json\", \n",
    "    output_file=\"autogen_submission.json\",\n",
    "    sample_size=10  # Process only 10 examples for testing\n",
    ")\n",
    "\n",
    "print(f\"Generated predictions for {len(autogen_submission)} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": "## 結論與洞察\n\n### AutoGen 框架優勢：\n1. **多視角分析**: 每個代理帶來專門的專業知識\n2. **結構化協作**: 明確的角色和責任\n3. **彈性協調**: 監督者管理複雜的工作流程\n4. **強健推理**: 多重觀點提升決策品質\n5. **可解釋性**: 代理對話提供推理過程的洞察\n\n### 關鍵功能展示：\n- **角色專業化**: 醫療、數值和邏輯分析\n- **群組聊天協調**: 代理透過結構化對話協作\n- **系統化方法**: 監督者確保全面分析\n- **錯誤處理**: 邊緣案例的優雅回退\n- **可擴展架構**: 易於添加新的專業代理\n\n### 優化機會：\n1. **提示工程**: 微調代理指令以提升效能\n2. **代理協調**: 改善對話流程和決策制定\n3. **錯誤分析**: 利用失敗案例改進代理推理\n4. **效能調整**: 最佳化模型參數和對話模式\n5. **領域知識**: 納入更多醫學領域專業知識\n\n### 何時使用 AutoGen：\n- 需要多重視角的複雜推理任務\n- 從角色專業化中受益的問題\n- 可解釋性很重要的場景\n- 需要強健協作決策的應用\n\n## 🎓 學習重點總結\n- **對話式協作**: 代理透過自然對話進行協作\n- **角色分工**: 每個代理專注於特定分析領域\n- **監督協調**: 中央協調確保系統化分析\n- **透明推理**: 對話過程提供決策透明度\n\nAutoGen在結構化多代理協作方面表現出色，並為推理過程提供優秀的透明度，使其成為複雜臨床分析任務的理想選擇。"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}