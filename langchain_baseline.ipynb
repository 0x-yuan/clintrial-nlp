{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# LangChain/LangGraph Framework Baseline for Clinical Trial NLP\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to use LangChain and LangGraph to build a stateful, graph-based agent system for clinical trial natural language inference (NLI). LangChain provides the most mature and feature-rich ecosystem for LLM applications.\n",
    "\n",
    "### Why LangChain/LangGraph?\n",
    "- **Mature ecosystem**: Most established LLM application framework\n",
    "- **Rich integrations**: Extensive tool and service integrations\n",
    "- **Stateful workflows**: LangGraph enables complex, stateful agent interactions\n",
    "- **Advanced patterns**: Support for complex reasoning and decision patterns\n",
    "- **Community support**: Large community and extensive documentation\n",
    "- **Production ready**: Battle-tested in numerous real-world applications\n",
    "\n",
    "### Agent Architecture with LangGraph\n",
    "We'll implement a graph-based workflow with stateful agents:\n",
    "1. **Clinical Data Extractor**: Processes and structures trial data\n",
    "2. **Medical Analysis Node**: Expert medical reasoning\n",
    "3. **Statistical Analysis Node**: Numerical and statistical validation\n",
    "4. **Logic Verification Node**: Logical consistency checking\n",
    "5. **Decision Synthesis Node**: Final entailment classification\n",
    "6. **State Management**: Persistent state across the analysis workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## Setup and Installation\n",
    "\n",
    "First, let's set up our environment and import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "print(\"✅ Environment loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependencies",
   "metadata": {},
   "outputs": [],
   "source": "# Import required libraries\nimport json\nimport pandas as pd\nfrom tqdm import tqdm\nfrom typing import Dict, List, Any, Optional, TypedDict, Annotated\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# LangChain imports\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain_core.messages import HumanMessage, AIMessage, SystemMessage\nfrom langchain_core.prompts import ChatPromptTemplate, PromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain.schema import Document\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\n# LangGraph imports\nfrom langgraph.graph import StateGraph, END\nfrom langgraph.checkpoint.sqlite import SqliteSaver\nfrom langgraph.prebuilt import ToolExecutor\nimport operator\n\nprint(\"✅ All libraries imported successfully\")"
  },
  {
   "cell_type": "markdown",
   "id": "data_utils",
   "metadata": {},
   "source": [
    "## Data Loading and Utilities\n",
    "\n",
    "Let's create utility functions for loading and processing clinical trial data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utils",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clinical_trial(trial_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"Load clinical trial data from JSON file.\n",
    "    \n",
    "    Args:\n",
    "        trial_id: The NCT identifier for the clinical trial\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing trial data or error information\n",
    "    \"\"\"\n",
    "    try:\n",
    "        file_path = os.path.join(\"training_data\", \"CT json\", f\"{trial_id}.json\")\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        return {\"error\": f\"Clinical trial {trial_id} not found\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error loading {trial_id}: {str(e)}\"}\n",
    "\n",
    "def load_dataset(filepath: str) -> Dict[str, Any]:\n",
    "    \"\"\"Load training or test dataset.\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to the JSON dataset file\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing the dataset\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        return {}\n",
    "\n",
    "def create_trial_documents(trial_data: Dict[str, Any]) -> List[Document]:\n",
    "    \"\"\"Create LangChain documents from trial data for better processing.\n",
    "    \n",
    "    Args:\n",
    "        trial_data: Clinical trial data dictionary\n",
    "        \n",
    "    Returns:\n",
    "        List of Document objects for LangChain processing\n",
    "    \"\"\"\n",
    "    if \"error\" in trial_data:\n",
    "        return [Document(page_content=f\"Error: {trial_data['error']}\", metadata={\"section\": \"error\"})]\n",
    "    \n",
    "    documents = []\n",
    "    trial_id = trial_data.get(\"Clinical Trial ID\", \"Unknown\")\n",
    "    \n",
    "    # Create documents for each section\n",
    "    sections = {\n",
    "        \"Eligibility\": trial_data.get(\"Eligibility\", []),\n",
    "        \"Intervention\": trial_data.get(\"Intervention\", []),\n",
    "        \"Results\": trial_data.get(\"Results\", []),\n",
    "        \"Adverse_Events\": trial_data.get(\"Adverse_Events\", [])\n",
    "    }\n",
    "    \n",
    "    for section_name, section_data in sections.items():\n",
    "        if section_data:\n",
    "            if isinstance(section_data, list):\n",
    "                content = \"\\n\".join(str(item) for item in section_data)\n",
    "            else:\n",
    "                content = str(section_data)\n",
    "            \n",
    "            documents.append(Document(\n",
    "                page_content=content,\n",
    "                metadata={\n",
    "                    \"trial_id\": trial_id,\n",
    "                    \"section\": section_name\n",
    "                }\n",
    "            ))\n",
    "    \n",
    "    return documents\n",
    "\n",
    "# Test utilities\n",
    "sample_trial = load_clinical_trial(\"NCT00066573\")\n",
    "sample_docs = create_trial_documents(sample_trial)\n",
    "print(f\"✅ Data utilities ready. Sample trial: {sample_trial.get('Clinical Trial ID', 'Error')}\")\n",
    "print(f\"Created {len(sample_docs)} documents from sample trial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_setup",
   "metadata": {},
   "source": "## Model Configuration\n\nSet up the ChatGoogleGenerativeAI model for LangChain:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_config",
   "metadata": {},
   "outputs": [],
   "source": "# Initialize ChatGoogleGenerativeAI model\nllm = ChatGoogleGenerativeAI(\n    model=\"gemini-2.5-flash\",\n    temperature=0.1,  # Low temperature for consistent results\n    google_api_key=os.getenv(\"GEMINI_API_KEY\")\n)\n\n# Initialize checkpointer for state persistence\ncheckpointer = SqliteSaver.from_conn_string(\":memory:\")\n\nprint(\"✅ Model and checkpointer configured\")"
  },
  {
   "cell_type": "markdown",
   "id": "state_definition",
   "metadata": {},
   "source": [
    "## State Definition\n",
    "\n",
    "Define the state structure for our LangGraph workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "state_schema",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClinicalAnalysisState(TypedDict):\n",
    "    \"\"\"State schema for clinical trial analysis workflow.\"\"\"\n",
    "    \n",
    "    # Input data\n",
    "    statement: str\n",
    "    primary_trial_id: str\n",
    "    secondary_trial_id: Optional[str]\n",
    "    focus_section: Optional[str]\n",
    "    \n",
    "    # Trial data\n",
    "    primary_trial_data: Dict[str, Any]\n",
    "    secondary_trial_data: Optional[Dict[str, Any]]\n",
    "    trial_documents: List[Document]\n",
    "    \n",
    "    # Analysis results\n",
    "    medical_analysis: Optional[str]\n",
    "    statistical_analysis: Optional[str]\n",
    "    logical_analysis: Optional[str]\n",
    "    \n",
    "    # Final decision\n",
    "    final_decision: Optional[str]\n",
    "    confidence_score: Optional[float]\n",
    "    \n",
    "    # Workflow control\n",
    "    next_action: Optional[str]\n",
    "    error_messages: Annotated[List[str], operator.add]\n",
    "\n",
    "print(\"✅ State schema defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "node_definitions",
   "metadata": {},
   "source": [
    "## Node Definitions\n",
    "\n",
    "Define the analysis nodes for our LangGraph workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_extractor_node",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clinical_data_extractor(state: ClinicalAnalysisState) -> ClinicalAnalysisState:\n",
    "    \"\"\"Extract and structure clinical trial data.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Load primary trial data\n",
    "        primary_data = load_clinical_trial(state[\"primary_trial_id\"])\n",
    "        state[\"primary_trial_data\"] = primary_data\n",
    "        \n",
    "        # Load secondary trial data if provided\n",
    "        if state[\"secondary_trial_id\"]:\n",
    "            secondary_data = load_clinical_trial(state[\"secondary_trial_id\"])\n",
    "            state[\"secondary_trial_data\"] = secondary_data\n",
    "        \n",
    "        # Create documents for processing\n",
    "        documents = create_trial_documents(primary_data)\n",
    "        if state[\"secondary_trial_data\"]:\n",
    "            documents.extend(create_trial_documents(state[\"secondary_trial_data\"]))\n",
    "        \n",
    "        state[\"trial_documents\"] = documents\n",
    "        state[\"next_action\"] = \"medical_analysis\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        state[\"error_messages\"].append(f\"Data extraction error: {str(e)}\")\n",
    "        state[\"next_action\"] = \"end\"\n",
    "    \n",
    "    return state\n",
    "\n",
    "print(\"✅ Data extractor node defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical_analysis_node",
   "metadata": {},
   "outputs": [],
   "source": [
    "def medical_analysis_node(state: ClinicalAnalysisState) -> ClinicalAnalysisState:\n",
    "    \"\"\"Perform medical analysis of the statement against trial data.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Create medical analysis prompt\n",
    "        medical_prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessage(content=\"\"\"\n",
    "You are a Medical Expert specializing in clinical trial analysis.\n",
    "Your role is to analyze statements from a medical perspective and assess their accuracy against clinical trial evidence.\n",
    "\n",
    "Focus on:\n",
    "- Medical terminology accuracy\n",
    "- Clinical relevance and significance\n",
    "- Medical plausibility of claims\n",
    "- Clinical context and implications\n",
    "- Medical evidence alignment\n",
    "\n",
    "Provide a thorough medical analysis and end with:\n",
    "MEDICAL_VERDICT: [SUPPORTS/CONTRADICTS/UNCLEAR] - brief reasoning\n",
    "            \"\"\".strip()),\n",
    "            HumanMessage(content=\"\"\"\n",
    "STATEMENT TO ANALYZE: \"{statement}\"\n",
    "\n",
    "CLINICAL TRIAL EVIDENCE:\n",
    "{trial_evidence}\n",
    "\n",
    "Please provide your medical analysis of this statement against the trial evidence.\n",
    "            \"\"\".strip())\n",
    "        ])\n",
    "        \n",
    "        # Prepare trial evidence\n",
    "        trial_evidence = \"\"\n",
    "        for doc in state[\"trial_documents\"]:\n",
    "            if state[\"focus_section\"] and doc.metadata.get(\"section\") != state[\"focus_section\"]:\n",
    "                continue\n",
    "            trial_evidence += f\"\\n{doc.metadata.get('section', 'Unknown')}:\\n{doc.page_content}\\n\"\n",
    "        \n",
    "        # Run medical analysis\n",
    "        medical_chain = medical_prompt | llm | StrOutputParser()\n",
    "        medical_result = medical_chain.invoke({\n",
    "            \"statement\": state[\"statement\"],\n",
    "            \"trial_evidence\": trial_evidence\n",
    "        })\n",
    "        \n",
    "        state[\"medical_analysis\"] = medical_result\n",
    "        state[\"next_action\"] = \"statistical_analysis\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        state[\"error_messages\"].append(f\"Medical analysis error: {str(e)}\")\n",
    "        state[\"next_action\"] = \"statistical_analysis\"  # Continue with next analysis\n",
    "    \n",
    "    return state\n",
    "\n",
    "print(\"✅ Medical analysis node defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical_analysis_node",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistical_analysis_node(state: ClinicalAnalysisState) -> ClinicalAnalysisState:\n",
    "    \"\"\"Perform statistical and numerical analysis.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Create statistical analysis prompt\n",
    "        statistical_prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessage(content=\"\"\"\n",
    "You are a Statistical Analyst specializing in clinical trial data analysis.\n",
    "Your role is to analyze numerical claims, statistics, and quantitative relationships in clinical trials.\n",
    "\n",
    "Focus on:\n",
    "- Numerical accuracy and verification\n",
    "- Statistical significance and validity\n",
    "- Quantitative relationships and comparisons\n",
    "- Data calculations and mathematical reasoning\n",
    "- Confidence intervals and error margins\n",
    "\n",
    "Perform detailed calculations and end with:\n",
    "STATISTICAL_VERDICT: [ACCURATE/INACCURATE/PARTIALLY_ACCURATE] - numerical reasoning\n",
    "            \"\"\".strip()),\n",
    "            HumanMessage(content=\"\"\"\n",
    "STATEMENT TO ANALYZE: \"{statement}\"\n",
    "\n",
    "CLINICAL TRIAL DATA:\n",
    "{trial_evidence}\n",
    "\n",
    "Please perform statistical analysis of the numerical claims in this statement.\n",
    "            \"\"\".strip())\n",
    "        ])\n",
    "        \n",
    "        # Prepare trial evidence (focus on Results section for statistical data)\n",
    "        trial_evidence = \"\"\n",
    "        for doc in state[\"trial_documents\"]:\n",
    "            # Prioritize Results and statistical sections\n",
    "            if doc.metadata.get(\"section\") in [\"Results\", \"Adverse_Events\"] or not state[\"focus_section\"]:\n",
    "                trial_evidence += f\"\\n{doc.metadata.get('section', 'Unknown')}:\\n{doc.page_content}\\n\"\n",
    "        \n",
    "        # Run statistical analysis\n",
    "        statistical_chain = statistical_prompt | llm | StrOutputParser()\n",
    "        statistical_result = statistical_chain.invoke({\n",
    "            \"statement\": state[\"statement\"],\n",
    "            \"trial_evidence\": trial_evidence\n",
    "        })\n",
    "        \n",
    "        state[\"statistical_analysis\"] = statistical_result\n",
    "        state[\"next_action\"] = \"logical_analysis\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        state[\"error_messages\"].append(f\"Statistical analysis error: {str(e)}\")\n",
    "        state[\"next_action\"] = \"logical_analysis\"  # Continue with next analysis\n",
    "    \n",
    "    return state\n",
    "\n",
    "print(\"✅ Statistical analysis node defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical_analysis_node",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logical_analysis_node(state: ClinicalAnalysisState) -> ClinicalAnalysisState:\n",
    "    \"\"\"Perform logical consistency analysis.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Create logical analysis prompt\n",
    "        logical_prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessage(content=\"\"\"\n",
    "You are a Logic Analyst specializing in reasoning validation and consistency checking.\n",
    "Your role is to validate logical relationships, consistency, and reasoning soundness.\n",
    "\n",
    "Focus on:\n",
    "- Logical structure and coherence\n",
    "- Cause-and-effect relationships\n",
    "- Internal consistency\n",
    "- Validity of inferences\n",
    "- Detection of logical fallacies\n",
    "- Reasoning pattern analysis\n",
    "\n",
    "Provide logical analysis and end with:\n",
    "LOGICAL_VERDICT: [SOUND/UNSOUND/QUESTIONABLE] - logical reasoning\n",
    "            \"\"\".strip()),\n",
    "            HumanMessage(content=\"\"\"\n",
    "STATEMENT TO ANALYZE: \"{statement}\"\n",
    "\n",
    "EVIDENCE CONTEXT:\n",
    "{trial_evidence}\n",
    "\n",
    "Please analyze the logical consistency and reasoning of this statement.\n",
    "            \"\"\".strip())\n",
    "        ])\n",
    "        \n",
    "        # Prepare trial evidence\n",
    "        trial_evidence = \"\"\n",
    "        for doc in state[\"trial_documents\"]:\n",
    "            if state[\"focus_section\"] and doc.metadata.get(\"section\") != state[\"focus_section\"]:\n",
    "                continue\n",
    "            trial_evidence += f\"\\n{doc.metadata.get('section', 'Unknown')}:\\n{doc.page_content[:500]}...\\n\"\n",
    "        \n",
    "        # Run logical analysis\n",
    "        logical_chain = logical_prompt | llm | StrOutputParser()\n",
    "        logical_result = logical_chain.invoke({\n",
    "            \"statement\": state[\"statement\"],\n",
    "            \"trial_evidence\": trial_evidence\n",
    "        })\n",
    "        \n",
    "        state[\"logical_analysis\"] = logical_result\n",
    "        state[\"next_action\"] = \"decision_synthesis\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        state[\"error_messages\"].append(f\"Logical analysis error: {str(e)}\")\n",
    "        state[\"next_action\"] = \"decision_synthesis\"  # Continue to final decision\n",
    "    \n",
    "    return state\n",
    "\n",
    "print(\"✅ Logical analysis node defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decision_synthesis_node",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_synthesis_node(state: ClinicalAnalysisState) -> ClinicalAnalysisState:\n",
    "    \"\"\"Synthesize all analyses and make final decision.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Create decision synthesis prompt\n",
    "        decision_prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessage(content=\"\"\"\n",
    "You are the Decision Synthesizer responsible for making final entailment classifications.\n",
    "Your role is to synthesize expert analyses and determine the final verdict.\n",
    "\n",
    "Classification Rules:\n",
    "- ENTAILMENT: Statement is directly supported by the trial evidence\n",
    "- CONTRADICTION: Statement is refuted or contradicted by the trial evidence\n",
    "\n",
    "Weigh all evidence types:\n",
    "- Medical expert analysis (clinical accuracy)\n",
    "- Statistical analysis (numerical validity)\n",
    "- Logical analysis (reasoning soundness)\n",
    "\n",
    "Provide reasoning and confidence, then end with:\n",
    "FINAL_DECISION: [Entailment/Contradiction]\n",
    "CONFIDENCE: [0.0-1.0]\n",
    "            \"\"\".strip()),\n",
    "            HumanMessage(content=\"\"\"\n",
    "ORIGINAL STATEMENT: \"{statement}\"\n",
    "\n",
    "MEDICAL ANALYSIS:\n",
    "{medical_analysis}\n",
    "\n",
    "STATISTICAL ANALYSIS:\n",
    "{statistical_analysis}\n",
    "\n",
    "LOGICAL ANALYSIS:\n",
    "{logical_analysis}\n",
    "\n",
    "Based on these expert analyses, provide your final entailment decision.\n",
    "            \"\"\".strip())\n",
    "        ])\n",
    "        \n",
    "        # Run decision synthesis\n",
    "        decision_chain = decision_prompt | llm | StrOutputParser()\n",
    "        decision_result = decision_chain.invoke({\n",
    "            \"statement\": state[\"statement\"],\n",
    "            \"medical_analysis\": state.get(\"medical_analysis\", \"Not available\"),\n",
    "            \"statistical_analysis\": state.get(\"statistical_analysis\", \"Not available\"),\n",
    "            \"logical_analysis\": state.get(\"logical_analysis\", \"Not available\")\n",
    "        })\n",
    "        \n",
    "        # Parse decision and confidence\n",
    "        if \"FINAL_DECISION: Entailment\" in decision_result:\n",
    "            final_decision = \"Entailment\"\n",
    "        elif \"FINAL_DECISION: Contradiction\" in decision_result:\n",
    "            final_decision = \"Contradiction\"\n",
    "        else:\n",
    "            # Fallback parsing\n",
    "            if \"entailment\" in decision_result.lower() and \"contradiction\" not in decision_result.lower():\n",
    "                final_decision = \"Entailment\"\n",
    "            else:\n",
    "                final_decision = \"Contradiction\"\n",
    "        \n",
    "        # Extract confidence score\n",
    "        confidence = 0.5  # Default\n",
    "        try:\n",
    "            if \"CONFIDENCE:\" in decision_result:\n",
    "                confidence_str = decision_result.split(\"CONFIDENCE:\")[1].strip().split()[0]\n",
    "                confidence = float(confidence_str)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        state[\"final_decision\"] = final_decision\n",
    "        state[\"confidence_score\"] = confidence\n",
    "        state[\"next_action\"] = \"end\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        state[\"error_messages\"].append(f\"Decision synthesis error: {str(e)}\")\n",
    "        state[\"final_decision\"] = \"Contradiction\"  # Conservative fallback\n",
    "        state[\"confidence_score\"] = 0.1\n",
    "        state[\"next_action\"] = \"end\"\n",
    "    \n",
    "    return state\n",
    "\n",
    "print(\"✅ Decision synthesis node defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "workflow_definition",
   "metadata": {},
   "source": [
    "## Workflow Definition\n",
    "\n",
    "Create the LangGraph workflow by connecting all nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "workflow_creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clinical_analysis_workflow():\n",
    "    \"\"\"Create the clinical analysis workflow using LangGraph.\"\"\"\n",
    "    \n",
    "    # Create the StateGraph\n",
    "    workflow = StateGraph(ClinicalAnalysisState)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"data_extraction\", clinical_data_extractor)\n",
    "    workflow.add_node(\"medical_analysis\", medical_analysis_node)\n",
    "    workflow.add_node(\"statistical_analysis\", statistical_analysis_node)\n",
    "    workflow.add_node(\"logical_analysis\", logical_analysis_node)\n",
    "    workflow.add_node(\"decision_synthesis\", decision_synthesis_node)\n",
    "    \n",
    "    # Add edges\n",
    "    workflow.set_entry_point(\"data_extraction\")\n",
    "    workflow.add_edge(\"data_extraction\", \"medical_analysis\")\n",
    "    workflow.add_edge(\"medical_analysis\", \"statistical_analysis\")\n",
    "    workflow.add_edge(\"statistical_analysis\", \"logical_analysis\")\n",
    "    workflow.add_edge(\"logical_analysis\", \"decision_synthesis\")\n",
    "    workflow.add_edge(\"decision_synthesis\", END)\n",
    "    \n",
    "    # Compile the workflow\n",
    "    app = workflow.compile(checkpointer=checkpointer)\n",
    "    \n",
    "    return app\n",
    "\n",
    "# Create the workflow\n",
    "clinical_workflow = create_clinical_analysis_workflow()\n",
    "\n",
    "print(\"✅ LangGraph workflow created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pipeline",
   "metadata": {},
   "source": [
    "## Analysis Pipeline\n",
    "\n",
    "Create the main pipeline function that uses our LangGraph workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analysis_pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def langchain_analysis_pipeline(statement: str, primary_id: str, secondary_id: Optional[str] = None, \n",
    "                               section_id: Optional[str] = None, verbose: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Run the complete LangChain/LangGraph analysis pipeline.\n",
    "    \n",
    "    Args:\n",
    "        statement: The natural language statement to analyze\n",
    "        primary_id: Primary clinical trial ID\n",
    "        secondary_id: Secondary trial ID for comparison statements\n",
    "        section_id: Relevant section of the trial\n",
    "        verbose: Whether to print intermediate results\n",
    "        \n",
    "    Returns:\n",
    "        Final decision: 'Entailment' or 'Contradiction'\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        if verbose:\n",
    "            print(f\"📄 Analyzing: {statement[:100]}...\")\n",
    "            print(f\"🏥 Primary Trial: {primary_id}\")\n",
    "            if secondary_id:\n",
    "                print(f\"🏥 Secondary Trial: {secondary_id}\")\n",
    "        \n",
    "        # Create initial state\n",
    "        initial_state = {\n",
    "            \"statement\": statement,\n",
    "            \"primary_trial_id\": primary_id,\n",
    "            \"secondary_trial_id\": secondary_id,\n",
    "            \"focus_section\": section_id,\n",
    "            \"primary_trial_data\": {},\n",
    "            \"secondary_trial_data\": None,\n",
    "            \"trial_documents\": [],\n",
    "            \"medical_analysis\": None,\n",
    "            \"statistical_analysis\": None,\n",
    "            \"logical_analysis\": None,\n",
    "            \"final_decision\": None,\n",
    "            \"confidence_score\": None,\n",
    "            \"next_action\": None,\n",
    "            \"error_messages\": []\n",
    "        }\n",
    "        \n",
    "        # Run the workflow\n",
    "        config = {\"configurable\": {\"thread_id\": f\"analysis_{hash(statement)}\"[:10]}}\n",
    "        result = clinical_workflow.invoke(initial_state, config)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"🩺 Medical Analysis: {'✅' if result.get('medical_analysis') else '❌'}\")\n",
    "            print(f\"📊 Statistical Analysis: {'✅' if result.get('statistical_analysis') else '❌'}\")\n",
    "            print(f\"🧠 Logical Analysis: {'✅' if result.get('logical_analysis') else '❌'}\")\n",
    "            print(f\"⚖️ Final Decision: {result.get('final_decision', 'Unknown')}\")\n",
    "            print(f\"🎯 Confidence: {result.get('confidence_score', 0.0):.2f}\")\n",
    "            \n",
    "            if result.get(\"error_messages\"):\n",
    "                print(f\"⚠️ Errors: {len(result['error_messages'])}\")\n",
    "            print(\"-\" * 50)\n",
    "        \n",
    "        return result.get(\"final_decision\", \"Contradiction\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"❌ Error in LangChain pipeline: {e}\")\n",
    "        return \"Contradiction\"  # Conservative fallback\n",
    "\n",
    "print(\"✅ LangChain analysis pipeline ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test_example",
   "metadata": {},
   "source": [
    "## Test Example\n",
    "\n",
    "Let's test our LangChain/LangGraph system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a sample statement\n",
    "test_statement = \"there is a 13.2% difference between the results from the two the primary trial cohorts\"\n",
    "test_primary_id = \"NCT00066573\"\n",
    "\n",
    "print(f\"Testing LangChain/LangGraph system with statement:\")\n",
    "print(f\"'{test_statement}'\")\n",
    "print(f\"Primary trial: {test_primary_id}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Run the analysis with verbose output\n",
    "result = langchain_analysis_pipeline(\n",
    "    statement=test_statement,\n",
    "    primary_id=test_primary_id,\n",
    "    section_id=\"Results\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\n🎯 LANGCHAIN RESULT: {result}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation",
   "metadata": {},
   "source": [
    "## Evaluation on Training Data\n",
    "\n",
    "Let's evaluate our LangChain/LangGraph system on training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_data = load_dataset(\"training_data/train.json\")\n",
    "print(f\"Loaded {len(train_data)} training examples\")\n",
    "\n",
    "# Evaluate on a sample (adjust sample_size as needed)\n",
    "sample_size = 20\n",
    "examples = list(train_data.items())[:sample_size]\n",
    "\n",
    "print(f\"\\nEvaluating LangChain/LangGraph system on {len(examples)} examples...\")\n",
    "\n",
    "results = []\n",
    "correct = 0\n",
    "\n",
    "for i, (uuid, example) in enumerate(tqdm(examples, desc=\"LangChain Processing\")):\n",
    "    try:\n",
    "        statement = example.get(\"Statement\")\n",
    "        primary_id = example.get(\"Primary_id\")\n",
    "        secondary_id = example.get(\"Secondary_id\")\n",
    "        section_id = example.get(\"Section_id\")\n",
    "        expected = example.get(\"Label\")\n",
    "        \n",
    "        if not statement or not primary_id:\n",
    "            results.append({\n",
    "                \"uuid\": uuid,\n",
    "                \"expected\": expected,\n",
    "                \"predicted\": \"SKIPPED\",\n",
    "                \"correct\": False\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Get prediction from LangChain/LangGraph system\n",
    "        predicted = langchain_analysis_pipeline(\n",
    "            statement=statement,\n",
    "            primary_id=primary_id,\n",
    "            secondary_id=secondary_id,\n",
    "            section_id=section_id,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Check if correct\n",
    "        is_correct = (predicted.strip() == expected.strip())\n",
    "        if is_correct:\n",
    "            correct += 1\n",
    "            \n",
    "        results.append({\n",
    "            \"uuid\": uuid,\n",
    "            \"statement\": statement[:100] + \"...\" if len(statement) > 100 else statement,\n",
    "            \"expected\": expected,\n",
    "            \"predicted\": predicted,\n",
    "            \"correct\": is_correct\n",
    "        })\n",
    "        \n",
    "        status = \"✅\" if is_correct else \"❌\"\n",
    "        print(f\"Example {i+1:2d}: {expected:12} -> {predicted:12} {status}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing example {i+1}: {e}\")\n",
    "        results.append({\n",
    "            \"uuid\": uuid,\n",
    "            \"expected\": expected,\n",
    "            \"predicted\": \"ERROR\",\n",
    "            \"correct\": False\n",
    "        })\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct / len(examples) if examples else 0\n",
    "print(f\"\\n📊 LangChain/LangGraph Results:\")\n",
    "print(f\"Accuracy: {accuracy:.2%} ({correct}/{len(examples)})\")\n",
    "\n",
    "# Store results for comparison\n",
    "langchain_results = results.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "state_inspection",
   "metadata": {},
   "source": [
    "## State Inspection\n",
    "\n",
    "Let's inspect the stateful capabilities of our LangGraph workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inspect_state",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate state persistence and inspection\n",
    "print(\"🔍 LangGraph State Inspection:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Run a simple analysis and inspect intermediate states\n",
    "test_config = {\"configurable\": {\"thread_id\": \"demo_analysis\"}}\n",
    "test_state = {\n",
    "    \"statement\": \"The primary endpoint was met\",\n",
    "    \"primary_trial_id\": \"NCT00066573\",\n",
    "    \"secondary_trial_id\": None,\n",
    "    \"focus_section\": \"Results\",\n",
    "    \"primary_trial_data\": {},\n",
    "    \"secondary_trial_data\": None,\n",
    "    \"trial_documents\": [],\n",
    "    \"medical_analysis\": None,\n",
    "    \"statistical_analysis\": None,\n",
    "    \"logical_analysis\": None,\n",
    "    \"final_decision\": None,\n",
    "    \"confidence_score\": None,\n",
    "    \"next_action\": None,\n",
    "    \"error_messages\": []\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Stream the workflow execution to see intermediate states\n",
    "    print(\"Streaming workflow execution:\")\n",
    "    for step in clinical_workflow.stream(test_state, test_config):\n",
    "        for node_name, node_output in step.items():\n",
    "            print(f\"\\n📍 Node: {node_name}\")\n",
    "            if node_output.get(\"final_decision\"):\n",
    "                print(f\"   Decision: {node_output['final_decision']}\")\n",
    "                print(f\"   Confidence: {node_output.get('confidence_score', 'N/A')}\")\n",
    "            if node_output.get(\"error_messages\"):\n",
    "                print(f\"   Errors: {len(node_output['error_messages'])}\")\n",
    "            print(f\"   Next: {node_output.get('next_action', 'N/A')}\")\n",
    "    \n",
    "    # Get final state\n",
    "    final_state = clinical_workflow.get_state(test_config)\n",
    "    print(f\"\\n🎯 Final State Summary:\")\n",
    "    print(f\"   Thread ID: {test_config['configurable']['thread_id']}\")\n",
    "    print(f\"   Final Decision: {final_state.values.get('final_decision')}\")\n",
    "    print(f\"   Total Errors: {len(final_state.values.get('error_messages', []))}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error in state inspection: {e}\")\n",
    "\n",
    "print(\"\\n✅ State inspection completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "submission",
   "metadata": {},
   "source": [
    "## Generate Submission File\n",
    "\n",
    "Let's generate a submission file using our LangChain/LangGraph system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate_submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_langchain_submission(test_file=\"test.json\", output_file=\"langchain_submission.json\", sample_size=None):\n",
    "    \"\"\"\n",
    "    Generate submission file using LangChain/LangGraph system.\n",
    "    \n",
    "    Args:\n",
    "        test_file: Path to test data\n",
    "        output_file: Output submission file\n",
    "        sample_size: Number of examples to process (None for all)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load test data\n",
    "    test_data = load_dataset(test_file)\n",
    "    if not test_data:\n",
    "        print(f\"❌ Could not load test data from {test_file}\")\n",
    "        return\n",
    "    \n",
    "    examples = list(test_data.items())\n",
    "    if sample_size:\n",
    "        examples = examples[:sample_size]\n",
    "        \n",
    "    print(f\"🚀 Generating LangChain/LangGraph predictions for {len(examples)} examples...\")\n",
    "    \n",
    "    submission = {}\n",
    "    \n",
    "    for i, (uuid, example) in enumerate(tqdm(examples, desc=\"LangChain Processing\")):\n",
    "        try:\n",
    "            statement = example.get(\"Statement\")\n",
    "            primary_id = example.get(\"Primary_id\")\n",
    "            secondary_id = example.get(\"Secondary_id\")\n",
    "            section_id = example.get(\"Section_id\")\n",
    "            \n",
    "            if not statement or not primary_id:\n",
    "                submission[uuid] = {\"Prediction\": \"Contradiction\"}  # Default fallback\n",
    "                continue\n",
    "                \n",
    "            # Get prediction from LangChain/LangGraph system\n",
    "            prediction = langchain_analysis_pipeline(\n",
    "                statement=statement,\n",
    "                primary_id=primary_id,\n",
    "                secondary_id=secondary_id,\n",
    "                section_id=section_id,\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            submission[uuid] = {\"Prediction\": prediction}\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {uuid}: {e}\")\n",
    "            submission[uuid] = {\"Prediction\": \"Contradiction\"}  # Conservative fallback\n",
    "    \n",
    "    # Save submission file\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(submission, f, indent=2)\n",
    "    \n",
    "    print(f\"✅ LangChain submission saved to {output_file}\")\n",
    "    return submission\n",
    "\n",
    "# Generate submission for a small sample\n",
    "langchain_submission = generate_langchain_submission(\n",
    "    test_file=\"test.json\", \n",
    "    output_file=\"langchain_submission.json\",\n",
    "    sample_size=10  # Adjust as needed\n",
    ")\n",
    "\n",
    "print(f\"Generated predictions for {len(langchain_submission)} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "workflow_visualization",
   "metadata": {},
   "source": [
    "## Workflow Visualization\n",
    "\n",
    "Let's visualize our LangGraph workflow structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize_workflow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display workflow information\n",
    "print(\"🔄 LangGraph Workflow Structure:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "workflow_steps = [\n",
    "    \"1. Data Extraction → Load and structure clinical trial data\",\n",
    "    \"2. Medical Analysis → Expert medical reasoning and assessment\",\n",
    "    \"3. Statistical Analysis → Numerical validation and calculations\",\n",
    "    \"4. Logical Analysis → Reasoning consistency and soundness\",\n",
    "    \"5. Decision Synthesis → Final entailment classification\"\n",
    "]\n",
    "\n",
    "for step in workflow_steps:\n",
    "    print(f\"   {step}\")\n",
    "\n",
    "print(\"\\n📊 State Management Features:\")\n",
    "state_features = [\n",
    "    \"• Persistent state across workflow steps\",\n",
    "    \"• Error tracking and recovery mechanisms\",\n",
    "    \"• Confidence scoring and decision rationale\",\n",
    "    \"• Intermediate result storage and inspection\",\n",
    "    \"• Thread-based conversation management\"\n",
    "]\n",
    "\n",
    "for feature in state_features:\n",
    "    print(f\"   {feature}\")\n",
    "\n",
    "print(\"\\n✅ Workflow visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusion and Insights\n",
    "\n",
    "### LangChain/LangGraph Framework Strengths:\n",
    "1. **Mature ecosystem**: Most established and feature-rich LLM application framework\n",
    "2. **Stateful workflows**: LangGraph enables complex, stateful agent interactions\n",
    "3. **Rich integrations**: Extensive tool ecosystem and service integrations\n",
    "4. **Advanced patterns**: Support for sophisticated reasoning and decision patterns\n",
    "5. **Community support**: Large community, extensive documentation, and real-world examples\n",
    "6. **Production ready**: Battle-tested in numerous enterprise applications\n",
    "\n",
    "### Key Features Demonstrated:\n",
    "- **Graph-based workflow**: Structured, stateful analysis pipeline\n",
    "- **State persistence**: SQLite checkpointer for conversation continuity\n",
    "- **Node specialization**: Dedicated analysis nodes for different domains\n",
    "- **Error handling**: Robust error tracking and recovery mechanisms\n",
    "- **Streaming support**: Real-time workflow execution monitoring\n",
    "- **Configuration management**: Thread-based state management\n",
    "\n",
    "### Architecture Benefits:\n",
    "- **Flexible workflows**: Easy to modify and extend the analysis pipeline\n",
    "- **State management**: Persistent context across complex multi-step processes\n",
    "- **Debugging support**: Clear state inspection and intermediate result tracking\n",
    "- **Scalable design**: Production-ready architecture for enterprise deployment\n",
    "- **Integration ready**: Seamless integration with external tools and services\n",
    "\n",
    "### Optimization Opportunities:\n",
    "1. **Prompt engineering**: Fine-tune prompts for each analysis node\n",
    "2. **Conditional routing**: Add conditional logic for different statement types\n",
    "3. **Parallel processing**: Implement parallel analysis nodes where possible\n",
    "4. **Tool integration**: Leverage LangChain's extensive tool ecosystem\n",
    "5. **Advanced patterns**: Implement self-reflection and iterative improvement\n",
    "\n",
    "### When to Use LangChain/LangGraph:\n",
    "- Complex, multi-step reasoning workflows requiring state management\n",
    "- Applications needing extensive tool and service integrations\n",
    "- Enterprise systems requiring robust, production-ready frameworks\n",
    "- Projects where community support and documentation are crucial\n",
    "- Scenarios requiring sophisticated workflow patterns and customization\n",
    "\n",
    "### Framework Comparison Summary:\n",
    "- **vs AutoGen**: Better for structured workflows, AutoGen better for free-form conversations\n",
    "- **vs Atomic Agents**: More comprehensive but heavier, Atomic better for pure performance\n",
    "- **vs Agno**: Broader ecosystem, Agno better for built-in memory and knowledge\n",
    "\n",
    "### LangChain/LangGraph Unique Advantages:\n",
    "1. **Graph-based reasoning**: Native support for complex, conditional workflows\n",
    "2. **State persistence**: Built-in checkpointing and conversation continuity\n",
    "3. **Ecosystem maturity**: Extensive tools, integrations, and community support\n",
    "4. **Enterprise features**: Production-ready with monitoring, logging, and debugging\n",
    "5. **Flexibility**: Highly customizable workflows and integration patterns\n",
    "\n",
    "LangChain/LangGraph excels in complex, production environments where structured workflows, state management, and extensive integrations are crucial. It's the ideal choice for enterprise clinical NLP applications requiring sophisticated reasoning patterns and robust infrastructure support."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}